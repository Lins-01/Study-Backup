{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n",
    "\n",
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor([0, 2]), len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(10).reshape((2, 5))\n",
    "F.one_hot(X.T, 28).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(vocab_size, num_hiddens, device):\n",
    "    num_inputs = num_outputs = vocab_size\n",
    "\n",
    "    def normal(shape):\n",
    "        return torch.randn(size=shape, device=device) * 0.01\n",
    "\n",
    "    # 隐藏层参数\n",
    "    W_xh = normal((num_inputs, num_hiddens))\n",
    "    W_hh = normal((num_hiddens, num_hiddens))\n",
    "    b_h = torch.zeros(num_hiddens, device=device)\n",
    "    # 输出层参数\n",
    "    W_hq = normal((num_hiddens, num_outputs))\n",
    "    b_q = torch.zeros(num_outputs, device=device)\n",
    "    # 附加梯度\n",
    "    params = [W_xh, W_hh, b_h, W_hq, b_q]\n",
    "    for param in params:\n",
    "        param.requires_grad_(True)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_rnn_state(batch_size, num_hiddens, device):\n",
    "    return (torch.zeros((batch_size, num_hiddens), device=device), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(inputs, state, params):\n",
    "    # inputs的形状：(时间步数量，批量大小，词表大小)\n",
    "    W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    # X的形状：(批量大小，词表大小)\n",
    "    for X in inputs:\n",
    "        H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)\n",
    "        Y = torch.mm(H, W_hq) + b_q\n",
    "        outputs.append(Y)\n",
    "    return torch.cat(outputs, dim=0), (H,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModelScratch: #@save\n",
    "    \"\"\"从零开始实现的循环神经网络模型\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, device,\n",
    "                 get_params, init_state, forward_fn):\n",
    "        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens\n",
    "        self.params = get_params(vocab_size, num_hiddens, device)\n",
    "        self.init_state, self.forward_fn = init_state, forward_fn\n",
    "\n",
    "    def __call__(self, X, state):\n",
    "        X = F.one_hot(X.T, self.vocab_size).type(torch.float32)\n",
    "        return self.forward_fn(X, state, self.params)\n",
    "\n",
    "    def begin_state(self, batch_size, device):\n",
    "        return self.init_state(batch_size, self.num_hiddens, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 28]),\n",
       " 1,\n",
       " torch.Size([2, 512]),\n",
       " tensor([[ 8.5908e-05, -4.1410e-03, -1.2673e-03, -8.6080e-05,  3.2799e-03,\n",
       "          -1.2756e-03,  1.1435e-03,  7.9507e-04, -3.5946e-03,  2.0983e-03,\n",
       "          -1.2371e-03,  3.8638e-04, -4.3222e-03, -4.8007e-04,  2.4422e-03,\n",
       "           1.2990e-03, -1.8758e-03,  6.4456e-04, -4.4322e-04, -2.0868e-03,\n",
       "          -1.2760e-03, -1.3711e-03,  1.1774e-03, -1.1880e-03,  1.4271e-03,\n",
       "           2.0547e-03, -1.7830e-04,  5.4665e-04],\n",
       "         [-6.4587e-04, -5.5983e-04, -9.5121e-04, -5.3750e-04, -3.3886e-03,\n",
       "          -1.2566e-03, -3.3099e-03,  3.0064e-04,  2.4458e-03,  1.5325e-04,\n",
       "          -1.1496e-04, -4.4658e-05,  6.7247e-04, -4.0525e-04,  8.9456e-04,\n",
       "          -2.0999e-03,  3.0081e-03, -1.2796e-03, -7.7973e-04,  3.3528e-04,\n",
       "           1.6639e-03,  5.2455e-03,  8.9568e-04,  3.1508e-03,  7.5633e-04,\n",
       "          -5.2787e-04, -2.3636e-03, -5.6478e-04],\n",
       "         [ 1.3061e-03,  5.3973e-04,  6.9481e-04, -1.1925e-03, -4.2591e-03,\n",
       "          -7.1724e-04, -1.3154e-03,  1.0523e-03,  2.8440e-03, -1.5204e-03,\n",
       "          -7.8879e-04, -3.9857e-03, -2.1509e-03,  2.5553e-03,  4.0912e-03,\n",
       "           3.0129e-04,  2.2095e-03,  1.9007e-03, -4.5960e-04, -1.3844e-03,\n",
       "          -4.7925e-03,  1.4027e-03, -4.8217e-03,  2.0483e-03, -3.0641e-03,\n",
       "           4.0372e-03,  1.6747e-03, -1.8205e-03],\n",
       "         [ 1.7743e-03, -7.0184e-04,  2.1343e-03, -2.1072e-03,  1.9170e-03,\n",
       "          -8.6653e-04, -8.5287e-04, -1.3517e-03, -1.1476e-03,  2.8449e-04,\n",
       "          -7.5945e-04, -5.3885e-04, -1.4942e-03, -2.2393e-03, -4.1326e-03,\n",
       "           4.0784e-04, -3.5007e-04,  1.4383e-05,  1.6018e-04, -2.7008e-03,\n",
       "          -4.9809e-04, -1.3353e-04,  5.5397e-04, -6.5373e-04,  1.4544e-03,\n",
       "           4.2241e-03,  3.2227e-03,  4.1931e-03],\n",
       "         [ 1.7817e-03, -1.5613e-03,  4.3694e-03,  9.1001e-04,  5.8473e-04,\n",
       "           1.8650e-03,  5.3943e-03,  2.9501e-03, -2.8318e-03,  1.0498e-03,\n",
       "           2.7005e-05,  2.0667e-03,  9.8336e-04,  1.8479e-03, -1.2250e-03,\n",
       "           1.3677e-03, -4.9180e-04,  2.9187e-04,  1.6364e-03, -1.2709e-03,\n",
       "           5.6172e-04,  2.0853e-03,  2.6205e-03,  3.2905e-03, -1.6968e-03,\n",
       "          -8.9432e-04, -3.5164e-05,  5.0027e-03],\n",
       "         [ 3.2180e-03, -2.7391e-03,  1.1923e-03,  6.9232e-04,  4.0886e-03,\n",
       "          -9.5063e-04, -2.0503e-04, -1.4212e-03, -1.7013e-03,  2.2533e-03,\n",
       "          -2.2058e-03,  5.2619e-05,  2.7463e-04,  9.9513e-05, -2.3976e-03,\n",
       "           4.6421e-04, -3.8230e-03, -2.2161e-03, -1.6318e-03, -1.9517e-03,\n",
       "           1.3304e-03,  2.0240e-03, -3.0488e-03, -3.0835e-03,  9.9897e-04,\n",
       "           3.2621e-03, -1.6338e-03, -3.8011e-04],\n",
       "         [-8.7891e-04,  2.2089e-03,  1.8033e-03,  2.4698e-03, -1.2325e-03,\n",
       "           3.5535e-03, -3.4230e-03, -2.9473e-03, -1.7956e-03,  1.0290e-03,\n",
       "           2.2324e-03, -1.2800e-03,  3.7675e-03,  4.2027e-03, -1.9806e-03,\n",
       "          -1.0297e-03,  5.0944e-04, -7.5326e-04, -1.4843e-04,  8.6271e-04,\n",
       "          -2.0769e-03,  2.9623e-03,  7.7744e-04,  3.6044e-04, -1.4474e-03,\n",
       "          -5.6534e-04,  5.5335e-03,  3.0510e-03],\n",
       "         [-2.1428e-07,  2.8574e-04,  1.8149e-03, -4.0724e-03, -3.2742e-03,\n",
       "          -1.2314e-03, -5.8692e-03, -1.4152e-03, -2.0172e-03,  3.6759e-03,\n",
       "          -2.4397e-03,  4.3512e-04, -1.9312e-03,  3.7040e-04,  3.2963e-03,\n",
       "           2.6830e-03,  4.7130e-04,  1.7779e-03, -5.6279e-03, -1.2759e-03,\n",
       "          -7.5847e-04,  1.8850e-03, -6.8378e-03,  4.5552e-05, -1.2756e-03,\n",
       "           9.5386e-05, -1.0937e-03, -1.7773e-03],\n",
       "         [ 1.0510e-03,  2.3725e-03,  3.7703e-03, -3.8653e-04,  2.9598e-03,\n",
       "          -1.5741e-03,  1.0363e-03, -2.1136e-03, -1.2830e-03,  2.8937e-04,\n",
       "           1.6859e-03, -3.6762e-03,  3.9225e-04, -1.7553e-03, -2.8259e-03,\n",
       "           5.1591e-04,  1.0011e-03,  3.7040e-04, -1.0721e-03,  1.2118e-03,\n",
       "          -5.8871e-04, -4.3241e-03,  1.5780e-03,  2.3623e-03,  7.3248e-03,\n",
       "          -2.2665e-03, -3.9968e-03, -1.4346e-03],\n",
       "         [ 4.1957e-03,  1.4075e-03, -8.2923e-04, -1.2035e-03, -1.8568e-03,\n",
       "          -1.0733e-03,  9.4202e-04, -2.0711e-03,  4.0851e-03,  2.7962e-03,\n",
       "           4.2162e-03, -2.2812e-04,  1.9036e-03, -4.0936e-03,  5.6053e-04,\n",
       "          -3.9218e-04,  7.7233e-04,  1.3345e-03,  1.5462e-03,  3.1542e-04,\n",
       "           1.4451e-03,  5.1372e-04, -1.6244e-03, -4.5365e-04, -2.2694e-03,\n",
       "          -8.2866e-04, -2.9031e-03, -2.6275e-04]], grad_fn=<CatBackward0>),\n",
       " tensor([[0, 1, 2, 3, 4],\n",
       "         [5, 6, 7, 8, 9]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hiddens = 512\n",
    "net = RNNModelScratch(len(vocab), num_hiddens, d2l.try_gpu(), get_params,\n",
    "                      init_rnn_state, rnn)\n",
    "state = net.begin_state(X.shape[0], d2l.try_gpu())\n",
    "Y, new_state = net(X.to(d2l.try_gpu()), state)\n",
    "# 这里直接打印的X还没有经过one-hot\n",
    "Y.shape, len(new_state), new_state[0].shape,Y,X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l_pytorch",
   "language": "python",
   "name": "d2l_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
