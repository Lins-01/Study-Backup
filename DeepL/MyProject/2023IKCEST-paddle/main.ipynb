{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2023IKCEST第五届“一带一路”国际大数据竞赛\n",
    "# 一、背景介绍\n",
    "\n",
    "本届大数据竞赛在中国工程院、教育部高等学校大学计算机课程教学指导委员会及丝绸之路大学联盟的指导下由联合国教科文组织国际工程科技知识中心（IKCEST）、中国工程科技知识中心（CKCEST）、百度公司及西安交通大学共同主办，旨在放眼“一带一路”倡议沿线国家，通过竞赛方式挖掘全球大数据人工智能尖端人才，实现政府—产业—高校合力推动大数据产业研究、应用、发展的目标，进一步夯实赛事的理论基础与实践基础，加快拔尖AI创新人才培养。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、赛题介绍\n",
    "随着新媒体时代信息媒介的多元化发展，各种内容大量活跃在媒体内中，与此同时各类虚假信息也充斥着社交媒体，影响着公众的判断和决策。如何在大量的文本、图像等多模态信息中，通过大数据与人工智能技术，纠正和消除虚假错误信息，对于网络舆情及社会治理有着重大意义。\n",
    "\n",
    "本次赛题要求选手基于官方指定数据集，通过建模同一事实跨模态数据之间的关系 （主要是文本和图像），实现对任一模态信息能够进行虚假和真实性的检测。鼓励参赛选手通过大模型解决问题，进行技术探索。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:10:32.137835Z",
     "iopub.status.busy": "2023-07-26T11:10:32.137090Z",
     "iopub.status.idle": "2023-07-26T11:10:35.711652Z",
     "shell.execute_reply": "2023-07-26T11:10:35.710258Z",
     "shell.execute_reply.started": "2023-07-26T11:10:32.137794Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: paddlenlp==2.5.2 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (2.5.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (2.13.1)\n",
      "Requirement already satisfied: multiprocess<=0.70.12.2 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (0.70.12.2)\n",
      "Requirement already satisfied: fastapi in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (0.100.0)\n",
      "Requirement already satisfied: rich in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (13.4.2)\n",
      "Requirement already satisfied: paddle2onnx in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (1.0.6)\n",
      "Requirement already satisfied: typer in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (0.9.0)\n",
      "Requirement already satisfied: visualdl in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (2.4.2)\n",
      "Requirement already satisfied: sentencepiece in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (0.1.99)\n",
      "Requirement already satisfied: seqeval in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (1.2.2)\n",
      "Requirement already satisfied: dill<0.3.5 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (0.3.4)\n",
      "Requirement already satisfied: colorama in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (0.4.6)\n",
      "Requirement already satisfied: jieba in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (0.42.1)\n",
      "Requirement already satisfied: tqdm in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (4.65.0)\n",
      "Requirement already satisfied: uvicorn in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (0.22.0)\n",
      "Requirement already satisfied: colorlog in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (6.7.0)\n",
      "Requirement already satisfied: Flask-Babel<3.0.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (2.0.0)\n",
      "Requirement already satisfied: paddlefsl in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (1.1.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.11.1 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (0.16.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from datasets>=2.0.0->paddlenlp==2.5.2) (12.0.1)\n",
      "Requirement already satisfied: packaging in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from datasets>=2.0.0->paddlenlp==2.5.2) (23.1)\n",
      "Requirement already satisfied: xxhash in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from datasets>=2.0.0->paddlenlp==2.5.2) (3.2.0)\n",
      "Requirement already satisfied: aiohttp in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from datasets>=2.0.0->paddlenlp==2.5.2) (3.8.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from datasets>=2.0.0->paddlenlp==2.5.2) (6.0.1)\n",
      "Requirement already satisfied: importlib-metadata in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from datasets>=2.0.0->paddlenlp==2.5.2) (6.7.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from datasets>=2.0.0->paddlenlp==2.5.2) (1.21.6)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from datasets>=2.0.0->paddlenlp==2.5.2) (2023.1.0)\n",
      "Requirement already satisfied: pandas in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from datasets>=2.0.0->paddlenlp==2.5.2) (1.3.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from datasets>=2.0.0->paddlenlp==2.5.2) (2.31.0)\n",
      "Requirement already satisfied: Flask in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from Flask-Babel<3.0.0->paddlenlp==2.5.2) (2.2.5)\n",
      "Requirement already satisfied: pytz in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from Flask-Babel<3.0.0->paddlenlp==2.5.2) (2023.3)\n",
      "Requirement already satisfied: Babel>=2.3 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from Flask-Babel<3.0.0->paddlenlp==2.5.2) (2.12.1)\n",
      "Requirement already satisfied: Jinja2>=2.5 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from Flask-Babel<3.0.0->paddlenlp==2.5.2) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from huggingface-hub>=0.11.1->paddlenlp==2.5.2) (4.7.1)\n",
      "Requirement already satisfied: filelock in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from huggingface-hub>=0.11.1->paddlenlp==2.5.2) (3.12.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from fastapi->paddlenlp==2.5.2) (2.1.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from fastapi->paddlenlp==2.5.2) (0.27.0)\n",
      "Requirement already satisfied: six in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddle2onnx->paddlenlp==2.5.2) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from rich->paddlenlp==2.5.2) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from rich->paddlenlp==2.5.2) (2.15.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from seqeval->paddlenlp==2.5.2) (1.0.2)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from typer->paddlenlp==2.5.2) (8.1.6)\n",
      "Requirement already satisfied: h11>=0.8 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from uvicorn->paddlenlp==2.5.2) (0.12.0)\n",
      "Requirement already satisfied: bce-python-sdk in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from visualdl->paddlenlp==2.5.2) (0.8.87)\n",
      "Requirement already satisfied: protobuf>=3.11.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from visualdl->paddlenlp==2.5.2) (3.20.0)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from visualdl->paddlenlp==2.5.2) (9.2.0)\n",
      "Requirement already satisfied: matplotlib in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from visualdl->paddlenlp==2.5.2) (3.5.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from Flask->Flask-Babel<3.0.0->paddlenlp==2.5.2) (2.1.2)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from Flask->Flask-Babel<3.0.0->paddlenlp==2.5.2) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.5.2) (3.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.5.2) (23.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.5.2) (1.9.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.5.2) (6.0.4)\n",
      "Requirement already satisfied: asynctest==0.13.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.5.2) (0.13.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.5.2) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.5.2) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.5.2) (1.3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from importlib-metadata->datasets>=2.0.0->paddlenlp==2.5.2) (3.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from Jinja2>=2.5->Flask-Babel<3.0.0->paddlenlp==2.5.2) (2.1.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->paddlenlp==2.5.2) (0.1.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->fastapi->paddlenlp==2.5.2) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.4.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->fastapi->paddlenlp==2.5.2) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp==2.5.2) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp==2.5.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp==2.5.2) (3.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp==2.5.2) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp==2.5.2) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp==2.5.2) (1.3.1)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from starlette<0.28.0,>=0.27.0->fastapi->paddlenlp==2.5.2) (3.7.1)\n",
      "Requirement already satisfied: future>=0.6.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from bce-python-sdk->visualdl->paddlenlp==2.5.2) (0.18.3)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from bce-python-sdk->visualdl->paddlenlp==2.5.2) (3.18.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from matplotlib->visualdl->paddlenlp==2.5.2) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from matplotlib->visualdl->paddlenlp==2.5.2) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from matplotlib->visualdl->paddlenlp==2.5.2) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from matplotlib->visualdl->paddlenlp==2.5.2) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from matplotlib->visualdl->paddlenlp==2.5.2) (3.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi->paddlenlp==2.5.2) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi->paddlenlp==2.5.2) (1.1.2)\n"
     ]
    }
   ],
   "source": [
    "#环境安装\n",
    "!pip install paddlenlp==2.5.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、数据集介绍\n",
    "本次比赛提供从国内外主流社交媒体平台上爬取的含有不同领域声明的数据集。\n",
    "\n",
    "初赛：训练集与验证集： 提供中文训练集5694条以及英文数据4893条，同时公开英文验证集611条与中文验证集711条供选手优化模型。\n",
    "\n",
    "初赛评测数据： 提供文娱、经济、健康领域的测试数据，这些领域的数据较容易区分。英文与中文数据集的测试集各600条。参赛队伍上传的结果文本的每一行就是对应的分类结果，该数据不公布，用于评测。\n",
    "\n",
    "\n",
    "| 0 | 1 | 2 |\n",
    "| -------- | -------- | -------- |\n",
    "| non-rumor | rumor  | unverified |\n",
    "\n",
    "\n",
    "\n",
    "[复赛数据后续见官网通知](https://aistudio.baidu.com/aistudio/competition/detail/1030/0/task-definition)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四、数据预处理\n",
    "**数据集过大，右键选择解压/home/aistudio/data/data229919/data.zip数据集，耐心等待30分钟，直到出现以下文件夹和文件,解压之后硬盘达到约80g（压缩包27g、解压文件之后50g，可以将项目挂载的数据集取消，空余出27g）**\n",
    "* test\n",
    "* train\n",
    "* val\n",
    "* dataset_items_test.json\n",
    "* dataset_items_train.json\n",
    "* dataset_items_val.json\n",
    "\n",
    "此处将数据集已经放置在queries_dataset_merge文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-26T11:10:35.715139Z",
     "iopub.status.busy": "2023-07-26T11:10:35.714521Z",
     "iopub.status.idle": "2023-07-26T11:10:35.721636Z",
     "shell.execute_reply": "2023-07-26T11:10:35.720702Z",
     "shell.execute_reply.started": "2023-07-26T11:10:35.715100Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import time\n",
    "import os \n",
    "import copy\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm \n",
    "\n",
    "import paddle\n",
    "from paddlenlp.datasets import load_dataset\n",
    "import paddle.nn.functional as F\n",
    "import paddle.nn as nn\n",
    "import paddlenlp as ppnlp\n",
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:10:35.723060Z",
     "iopub.status.busy": "2023-07-26T11:10:35.722761Z",
     "iopub.status.idle": "2023-07-26T11:10:35.806019Z",
     "shell.execute_reply": "2023-07-26T11:10:35.804860Z",
     "shell.execute_reply.started": "2023-07-26T11:10:35.723034Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#读取数据\n",
    "import json\n",
    "data_items_train = json.load(open(\"E:/Document/CodeSpace/Data_set/Paddle2023IKCEST/queries_dataset_merge/dataset_items_train.json\"))\n",
    "data_items_val = json.load(open(\"E:/Document/CodeSpace/Data_set/Paddle2023IKCEST/queries_dataset_merge/dataset_items_val.json\"))\n",
    "data_items_test = json.load(open(\"E:/Document/CodeSpace/Data_set/Paddle2023IKCEST/queries_dataset_merge/dataset_items_test.json\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据中的每一个样本：图像img、文本caption、对应的img_html_news、inverse_search为支持图像img和文本caption的证据材料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:10:35.808211Z",
     "iopub.status.busy": "2023-07-26T11:10:35.807864Z",
     "iopub.status.idle": "2023-07-26T11:10:35.841452Z",
     "shell.execute_reply": "2023-07-26T11:10:35.840479Z",
     "shell.execute_reply.started": "2023-07-26T11:10:35.808180Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddle.vision import transforms as T\n",
    "from paddle.io import Dataset\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "from PIL import Image\n",
    "import os \n",
    "import imghdr\n",
    "\n",
    "def process_string(input_str):\n",
    "    input_str = input_str.replace('&#39;', ' ')\n",
    "    input_str = input_str.replace('<b>','')\n",
    "    input_str = input_str.replace('</b>','')\n",
    "    #input_str = unidecode(input_str)  \n",
    "    return input_str\n",
    "    \n",
    "class NewsContextDatasetEmbs(Dataset):\n",
    "    def __init__(self, context_data_items_dict, queries_root_dir, split):\n",
    "        self.context_data_items_dict = context_data_items_dict\n",
    "        self.queries_root_dir = queries_root_dir\n",
    "        self.idx_to_keys = list(context_data_items_dict.keys())\n",
    "        self.transform =T.Compose([\n",
    "                        T.Resize(256),\n",
    "                        T.CenterCrop(224),\n",
    "                        T.ToTensor(),\n",
    "                        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                    ])\n",
    "        self.split=split\n",
    "    def __len__(self):\n",
    "        return len(self.context_data_items_dict)   \n",
    "\n",
    "\n",
    "    def load_img_pil(self,image_path):\n",
    "        if imghdr.what(image_path) == 'gif': \n",
    "            try:\n",
    "                with open(image_path, 'rb') as f:\n",
    "                    img = Image.open(f)\n",
    "                    return img.convert('RGB')\n",
    "            except:\n",
    "                return None \n",
    "        with open(image_path, 'rb') as f:\n",
    "            img = Image.open(f)\n",
    "            return img.convert('RGB')\n",
    "    def load_imgs_direct_search(self,item_folder_path,direct_dict):   \n",
    "        list_imgs_tensors = []\n",
    "        count = 0   \n",
    "        keys_to_check = ['images_with_captions','images_with_no_captions','images_with_caption_matched_tags']\n",
    "        for key1 in keys_to_check:\n",
    "            if key1 in direct_dict.keys():\n",
    "                for page in direct_dict[key1]:\n",
    "                    image_path = os.path.join(item_folder_path,page['image_path'].split('/')[-1])\n",
    "                    try:\n",
    "                        pil_img = self.load_img_pil(image_path)\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        print(image_path)\n",
    "                    if pil_img == None: continue\n",
    "                    transform_img = self.transform(pil_img)\n",
    "                    count = count + 1 \n",
    "                    list_imgs_tensors.append(transform_img)\n",
    "        stacked_tensors = paddle.stack(list_imgs_tensors, axis=0)\n",
    "        return stacked_tensors\n",
    "    def load_captions(self,inv_dict):\n",
    "        captions = ['']\n",
    "        pages_with_captions_keys = ['all_fully_matched_captions','all_partially_matched_captions']\n",
    "        for key1 in pages_with_captions_keys:\n",
    "            if key1 in inv_dict.keys():\n",
    "                for page in inv_dict[key1]:\n",
    "                    if 'title' in page.keys():\n",
    "                        item = page['title']\n",
    "                        item = process_string(item)\n",
    "                        captions.append(item)\n",
    "                    \n",
    "                    if 'caption' in page.keys():\n",
    "                        sub_captions_list = []\n",
    "                        unfiltered_captions = []\n",
    "                        for key2 in page['caption']:\n",
    "                            sub_caption = page['caption'][key2]\n",
    "                            sub_caption_filter = process_string(sub_caption)\n",
    "                            if sub_caption in unfiltered_captions: continue \n",
    "                            sub_captions_list.append(sub_caption_filter) \n",
    "                            unfiltered_captions.append(sub_caption) \n",
    "                        captions = captions + sub_captions_list \n",
    "                    \n",
    "        pages_with_title_only_keys = ['partially_matched_no_text','fully_matched_no_text']\n",
    "        for key1 in pages_with_title_only_keys:\n",
    "            if key1 in inv_dict.keys():\n",
    "                for page in inv_dict[key1]:\n",
    "                    if 'title' in page.keys():\n",
    "                        title = process_string(page['title'])\n",
    "                        captions.append(title)\n",
    "        return captions\n",
    "\n",
    "    def load_captions_weibo(self,direct_dict):\n",
    "        captions = ['']\n",
    "        keys = ['images_with_captions','images_with_no_captions','images_with_caption_matched_tags']\n",
    "        for key1 in keys:\n",
    "            if key1 in direct_dict.keys():\n",
    "                for page in direct_dict[key1]:\n",
    "                    if 'page_title' in page.keys():\n",
    "                        item = page['page_title']\n",
    "                        item = process_string(item)\n",
    "                        captions.append(item)\n",
    "                    if 'caption' in page.keys():\n",
    "                        sub_captions_list = []\n",
    "                        unfiltered_captions = []\n",
    "                        for key2 in page['caption']:\n",
    "                            sub_caption = page['caption'][key2]\n",
    "                            sub_caption_filter = process_string(sub_caption)\n",
    "                            if sub_caption in unfiltered_captions: continue \n",
    "                            sub_captions_list.append(sub_caption_filter) \n",
    "                            unfiltered_captions.append(sub_caption) \n",
    "                        captions = captions + sub_captions_list \n",
    "        #print(captions)\n",
    "        return captions\n",
    "        #加载img文件夹\n",
    "    def load_queries(self,key):\n",
    "        caption = self.context_data_items_dict[key]['caption']\n",
    "        image_path = os.path.join(self.queries_root_dir,self.context_data_items_dict[key]['image_path'])\n",
    "        pil_img = self.load_img_pil(image_path)\n",
    "        transform_img = self.transform(pil_img)\n",
    "        return transform_img, caption\n",
    "    def __getitem__(self, idx):\n",
    "        #print(idx)\n",
    "        #print(self.context_data_items_dict)      \n",
    "        #idx = idx.tolist()               \n",
    "        key = self.idx_to_keys[idx]\n",
    "        #print(key)\n",
    "        item=self.context_data_items_dict.get(str(key))\n",
    "        #print(item)\n",
    "        # 如果为test没有label属性\n",
    "        #print(self.split)\n",
    "        if self.split=='train' or self.split=='val':\n",
    "            label = paddle.to_tensor(int(item['label']))\n",
    "            direct_path_item = os.path.join(self.queries_root_dir,item['direct_path'])\n",
    "            inverse_path_item = os.path.join(self.queries_root_dir,item['inv_path'])\n",
    "            inv_ann_dict = json.load(open(os.path.join(inverse_path_item, 'inverse_annotation.json')))\n",
    "            direct_dict = json.load(open(os.path.join(direct_path_item, 'direct_annotation.json')))\n",
    "            captions= self.load_captions(inv_ann_dict)\n",
    "            captions += self.load_captions_weibo(direct_dict)\n",
    "            imgs = self.load_imgs_direct_search(direct_path_item,direct_dict)     \n",
    "            qImg,qCap =  self.load_queries(key)\n",
    "            sample = {'label': label, 'caption': captions,'imgs': imgs,  'qImg': qImg, 'qCap': qCap}\n",
    "        else:\n",
    "            direct_path_item = os.path.join(self.queries_root_dir,item['direct_path'])\n",
    "            inverse_path_item = os.path.join(self.queries_root_dir,item['inv_path'])\n",
    "            inv_ann_dict = json.load(open(os.path.join(inverse_path_item, 'inverse_annotation.json')))\n",
    "            direct_dict = json.load(open(os.path.join(direct_path_item, 'direct_annotation.json')))\n",
    "            captions= self.load_captions(inv_ann_dict)\n",
    "            captions += self.load_captions_weibo(direct_dict)\n",
    "            imgs = self.load_imgs_direct_search(direct_path_item,direct_dict)     \n",
    "            qImg,qCap =  self.load_queries(key)\n",
    "            sample = {'caption': captions,'imgs': imgs,  'qImg': qImg, 'qCap': qCap}\n",
    "        #print(sample)\n",
    "        #print(len(captions)) \n",
    "        #print(type(imgs))\n",
    "        #print(imgs.size)\n",
    "        #print(imgs.shape)  \n",
    "        return sample,  len(captions), imgs.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:10:35.844701Z",
     "iopub.status.busy": "2023-07-26T11:10:35.844245Z",
     "iopub.status.idle": "2023-07-26T11:10:35.849617Z",
     "shell.execute_reply": "2023-07-26T11:10:35.848733Z",
     "shell.execute_reply.started": "2023-07-26T11:10:35.844671Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### load Datasets ####\n",
    "train_dataset = NewsContextDatasetEmbs(data_items_train, 'E:/Document/CodeSpace/Data_set/Paddle2023IKCEST/queries_dataset_merge','train')\n",
    "val_dataset = NewsContextDatasetEmbs(data_items_val,'E:/Document/CodeSpace/Data_set/Paddle2023IKCEST/queries_dataset_merge','val')\n",
    "test_dataset = NewsContextDatasetEmbs(data_items_test,'E:/Document/CodeSpace/Data_set/Paddle2023IKCEST/queries_dataset_merge','test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:10:35.851023Z",
     "iopub.status.busy": "2023-07-26T11:10:35.850724Z",
     "iopub.status.idle": "2023-07-26T11:10:36.138303Z",
     "shell.execute_reply": "2023-07-26T11:10:36.137122Z",
     "shell.execute_reply.started": "2023-07-26T11:10:35.850996Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'caption': ['', '', 'Boston Orange  波士頓菊子: 朱学渊  - 為中國史學的實證化而努力', '新华每日电讯-微报纸-2022年01月28日', '新华每日电讯-微报纸-2021年11月19日'], 'imgs': Tensor(shape=[3, 3, 224, 224], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[[[ 1.71804118,  1.47829461,  1.51254416, ..., -1.07329392,\n",
      "           -1.03904438, -1.05616915],\n",
      "          [ 1.39267087,  1.37554610,  1.58104312, ..., -1.03904438,\n",
      "           -1.05616915, -1.07329392],\n",
      "          [ 1.42692029,  1.47829461,  1.66666687, ..., -1.00479496,\n",
      "           -1.02191973, -1.02191973],\n",
      "          ...,\n",
      "          [-1.72403467, -1.74115944, -1.77540886, ...,  0.57068247,\n",
      "            0.50218344,  0.38231018],\n",
      "          [-1.74115944, -1.65553570, -1.63841093, ...,  0.51930821,\n",
      "            0.43368444,  0.21106265],\n",
      "          [-1.75828421, -1.75828421, -1.70690989, ...,  0.51930821,\n",
      "            0.41655967,  0.12543888]],\n",
      "\n",
      "         [[ 1.58823562,  1.36064458,  1.37815154, ..., -1.09033608,\n",
      "           -1.09033608, -1.12535000],\n",
      "          [ 1.22058833,  1.23809528,  1.44817960, ..., -1.09033608,\n",
      "           -1.10784304, -1.12535000],\n",
      "          [ 1.20308125,  1.30812323,  1.53571451, ..., -1.05532205,\n",
      "           -1.07282901, -1.09033608],\n",
      "          ...,\n",
      "          [-1.65056014, -1.66806722, -1.68557417, ...,  1.02801120,\n",
      "            0.87044823,  0.62535024],\n",
      "          [-1.68557417, -1.58053207, -1.56302512, ...,  0.97549027,\n",
      "            0.80042022,  0.45028022],\n",
      "          [-1.72058821, -1.68557417, -1.63305318, ...,  0.97549027,\n",
      "            0.78291327,  0.36274520]],\n",
      "\n",
      "         [[ 1.35023987,  1.12366033,  1.14108944, ..., -0.77612191,\n",
      "           -0.75869268, -0.79355109],\n",
      "          [ 1.00165594,  1.00165594,  1.21080625, ..., -0.77612191,\n",
      "           -0.79355109, -0.81098026],\n",
      "          [ 1.00165594,  1.08880186,  1.29795229, ..., -0.74126351,\n",
      "           -0.75869268, -0.77612191],\n",
      "          ...,\n",
      "          [-1.49071896, -1.49071896, -1.52557731, ...,  1.10623109,\n",
      "            0.96679759,  0.74021804],\n",
      "          [-1.50814819, -1.42100215, -1.40357304, ...,  1.05394351,\n",
      "            0.89708078,  0.60078448],\n",
      "          [-1.54300654, -1.52557731, -1.47328973, ...,  1.03651428,\n",
      "            0.87965161,  0.51363856]]],\n",
      "\n",
      "\n",
      "        [[[ 2.24890828,  2.24890828,  2.24890828, ...,  2.19753432,\n",
      "            2.24890828,  2.24890828],\n",
      "          [ 2.24890828,  2.24890828,  2.24890828, ...,  2.21465898,\n",
      "            2.24890828,  2.24890828],\n",
      "          [ 2.24890828,  2.24890828,  2.24890828, ...,  2.19753432,\n",
      "            2.24890828,  2.24890828],\n",
      "          ...,\n",
      "          [-1.39866436, -1.39866436, -1.39866436, ...,  1.94066298,\n",
      "            1.68379164,  1.75229061],\n",
      "          [ 1.28992236,  1.28992236,  1.28992236, ...,  1.78654015,\n",
      "            2.14615989,  1.83791447],\n",
      "          [ 2.19753432,  2.19753432,  2.19753432, ...,  1.52966881,\n",
      "            1.76941538,  1.59816790]],\n",
      "\n",
      "         [[ 2.42857146,  2.42857146,  2.42857146, ...,  2.37605071,\n",
      "            2.42857146,  2.42857146],\n",
      "          [ 2.42857146,  2.42857146,  2.42857146, ...,  2.39355755,\n",
      "            2.42857146,  2.42857146],\n",
      "          [ 2.42857146,  2.42857146,  2.42857146, ...,  2.37605071,\n",
      "            2.42857146,  2.42857146],\n",
      "          ...,\n",
      "          [ 0.03011219,  0.03011219,  0.03011219, ...,  2.11344552,\n",
      "            1.85084057,  1.92086864],\n",
      "          [ 1.78081262,  1.78081262,  1.78081262, ...,  1.95588255,\n",
      "            2.32352948,  2.00840354],\n",
      "          [ 2.41106486,  2.41106486,  2.41106486, ...,  1.69327760,\n",
      "            1.93837559,  1.76330554]],\n",
      "\n",
      "         [[ 2.64000010,  2.64000010,  2.64000010, ...,  2.58771276,\n",
      "            2.64000010,  2.64000010],\n",
      "          [ 2.64000010,  2.64000010,  2.64000010, ...,  2.60514212,\n",
      "            2.64000010,  2.64000010],\n",
      "          [ 2.64000010,  2.64000010,  2.64000010, ...,  2.58771276,\n",
      "            2.64000010,  2.64000010],\n",
      "          ...,\n",
      "          [ 1.31538141,  1.29795229,  1.33281064, ...,  2.32627511,\n",
      "            2.06483698,  2.13455367],\n",
      "          [ 2.23912883,  2.23912883,  2.23912883, ...,  2.16941214,\n",
      "            2.53542542,  2.22169971],\n",
      "          [ 2.55285430,  2.55285430,  2.55285430, ...,  1.90797424,\n",
      "            2.15198302,  1.97769105]]],\n",
      "\n",
      "\n",
      "        [[[ 2.24890828,  2.24890828,  2.24890828, ...,  1.47829461,\n",
      "            1.85503912,  1.63241732],\n",
      "          [ 2.24890828,  2.24890828,  2.24890828, ...,  1.97491241,\n",
      "            2.00916195,  2.07766104],\n",
      "          [ 2.24890828,  2.24890828,  2.24890828, ...,  1.54679358,\n",
      "            1.47829461,  1.71804118],\n",
      "          ...,\n",
      "          [ 1.75229061,  1.82078969,  1.75229061, ...,  2.23178363,\n",
      "            2.23178363,  2.23178363],\n",
      "          [ 2.14615989,  2.02628660,  2.00916195, ...,  1.85503912,\n",
      "            1.82078969,  1.82078969],\n",
      "          [ 1.95778763,  1.61529267,  1.64954209, ...,  1.37554610,\n",
      "            1.42692029,  1.39267087]],\n",
      "\n",
      "         [[ 2.42857146,  2.42857146,  2.42857146, ...,  1.64075661,\n",
      "            2.02591062,  1.79831958],\n",
      "          [ 2.42857146,  2.42857146,  2.42857146, ...,  2.14845967,\n",
      "            2.18347359,  2.25350142],\n",
      "          [ 2.42857146,  2.42857146,  2.42857146, ...,  1.71078455,\n",
      "            1.64075661,  1.88585460],\n",
      "          ...,\n",
      "          [ 1.92086864,  1.99089658,  1.92086864, ...,  2.41106486,\n",
      "            2.41106486,  2.41106486],\n",
      "          [ 2.32352948,  2.20098066,  2.18347359, ...,  2.02591062,\n",
      "            1.99089658,  1.99089658],\n",
      "          [ 2.13095260,  1.78081262,  1.81582654, ...,  1.53571451,\n",
      "            1.58823562,  1.55322158]],\n",
      "\n",
      "         [[ 2.64000010,  2.64000010,  2.64000010, ...,  1.85568666,\n",
      "            2.23912883,  2.01254940],\n",
      "          [ 2.64000010,  2.64000010,  2.64000010, ...,  2.36113334,\n",
      "            2.39599180,  2.46570849],\n",
      "          [ 2.64000010,  2.64000010,  2.64000010, ...,  1.92540348,\n",
      "            1.85568666,  2.09969544],\n",
      "          ...,\n",
      "          [ 2.13455367,  2.20427060,  2.13455367, ...,  2.62257099,\n",
      "            2.62257099,  2.62257099],\n",
      "          [ 2.53542542,  2.41342068,  2.39599180, ...,  2.23912883,\n",
      "            2.20427060,  2.20427060],\n",
      "          [ 2.34370399,  1.99512029,  2.02997851, ...,  1.75111151,\n",
      "            1.80339909,  1.76854074]]]]), 'qImg': Tensor(shape=[3, 224, 224], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[[ 2.23178363,  1.68379164,  1.85503912, ...,  2.24890828,\n",
      "           2.24890828,  2.24890828],\n",
      "         [ 2.11191034,  1.66666687,  1.88928866, ...,  2.24890828,\n",
      "           2.24890828,  2.24890828],\n",
      "         [ 1.94066298,  1.68379164,  1.87216389, ...,  2.24890828,\n",
      "           2.24890828,  2.24890828],\n",
      "         ...,\n",
      "         [ 0.36518541,  1.99203718,  0.09118938, ...,  0.43368444,\n",
      "           1.10154974,  0.67343098],\n",
      "         [ 0.36518541,  1.80366492,  0.02269037, ...,  1.63241732,\n",
      "           1.76941538, -0.02868389],\n",
      "         [ 0.29668641,  0.63918144,  0.38231018, ...,  0.58780718,\n",
      "           1.49541938, -0.26843041]],\n",
      "\n",
      "        [[ 2.09593868, -0.47759098, -1.96568620, ...,  2.42857146,\n",
      "           2.42857146,  2.42857146],\n",
      "         [ 1.58823562, -1.33543408, -1.98319328, ...,  2.42857146,\n",
      "           2.42857146,  2.42857146],\n",
      "         [ 0.69537824, -1.77310920, -1.98319328, ...,  2.42857146,\n",
      "           2.42857146,  2.42857146],\n",
      "         ...,\n",
      "         [ 0.50280124,  2.16596651,  0.22268920, ...,  0.57282925,\n",
      "           1.25560224,  0.81792724],\n",
      "         [ 0.50280124,  1.97338963,  0.15266119, ...,  1.79831958,\n",
      "           1.93837559,  0.10014019],\n",
      "         [ 0.43277320,  0.78291327,  0.52030820, ...,  0.73039222,\n",
      "           1.65826356, -0.14495783]],\n",
      "\n",
      "        [[ 2.44827914, -0.06152484, -1.40357304, ...,  2.64000010,\n",
      "           2.64000010,  2.64000010],\n",
      "         [ 2.02997851, -0.88069707, -1.47328973, ...,  2.64000010,\n",
      "           2.64000010,  2.64000010],\n",
      "         [ 1.10623109, -1.29899776, -1.47328973, ...,  2.64000010,\n",
      "           2.64000010,  2.64000010],\n",
      "         ...,\n",
      "         [ 0.72278887,  2.37856245,  0.44392177, ...,  0.79250562,\n",
      "           1.47224414,  1.03651428],\n",
      "         [ 0.72278887,  2.18684125,  0.37420499, ...,  2.01254940,\n",
      "           2.15198302,  0.32191741],\n",
      "         [ 0.65307206,  1.00165594,  0.74021804, ...,  0.94936836,\n",
      "           1.87311590,  0.07790870]]]), 'qCap': '看到有人说 这老头说了句话 不是我退休了 要是没退休 你早就在牢里了 说是某地政法系统的前领导 正局级干部退休的 我想问这种人敢说出这种话 在职间到底'}, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "# 打印数据\n",
    "for step, batch in enumerate(test_dataset, start=1):\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:10:36.140472Z",
     "iopub.status.busy": "2023-07-26T11:10:36.139797Z",
     "iopub.status.idle": "2023-07-26T11:10:36.159168Z",
     "shell.execute_reply": "2023-07-26T11:10:36.158224Z",
     "shell.execute_reply.started": "2023-07-26T11:10:36.140436Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddle \n",
    "def collate_context_bert_train(batch):\n",
    "    #print(batch)\n",
    "    samples = [item[0] for item in batch]\n",
    "    max_captions_len = max([item[1] for item in batch])\n",
    "    max_images_len = max([item[2] for item in batch])\n",
    "    qCap_batch = []\n",
    "    qImg_batch = []\n",
    "    img_batch = []\n",
    "    cap_batch = []\n",
    "    labels = [] \n",
    "    for j in range(0,len(samples)):  \n",
    "        sample = samples[j]    \n",
    "        labels.append(sample['label'])\n",
    "        captions = sample['caption']\n",
    "        cap_len = len(captions)\n",
    "        for i in range(0,max_captions_len-cap_len):\n",
    "            captions.append(\"\")\n",
    "        if len(sample['imgs'].shape) > 2:\n",
    "            padding_size = (max_images_len-sample['imgs'].shape[0], sample['imgs'].shape[1], sample['imgs'].shape[2], sample['imgs'].shape[3])\n",
    "        else:\n",
    "            padding_size = (max_images_len-sample['imgs'].shape[0],sample['imgs'].shape[1])\n",
    "        padded_mem_img = paddle.concat((sample['imgs'], paddle.zeros(padding_size)),axis=0)\n",
    "        #print(1)\n",
    "        img_batch.append(padded_mem_img)#pad证据图片\n",
    "        cap_batch.append(captions)\n",
    "        qImg_batch.append(sample['qImg'])#[3, 224, 224]\n",
    "        qCap_batch.append(sample['qCap'])     \n",
    "    #print(labels)   \n",
    "    #print(img_batch)\n",
    "    img_batch = paddle.stack(img_batch, axis=0)\n",
    "    qImg_batch = paddle.stack(qImg_batch, axis=0)\n",
    "    labels = paddle.stack(labels, axis=0) \n",
    "    #print(3)  \n",
    "    return labels, cap_batch, img_batch, qCap_batch, qImg_batch\n",
    "\n",
    "def collate_context_bert_test(batch):\n",
    "    samples = [item[0] for item in batch]\n",
    "    max_captions_len = max([item[1] for item in batch])\n",
    "    max_images_len = max([item[2] for item in batch])\n",
    "    qCap_batch = []\n",
    "    qImg_batch = []\n",
    "    img_batch = []\n",
    "    cap_batch = []\n",
    "    for j in range(0,len(samples)):  \n",
    "        sample = samples[j]    \n",
    "        captions = sample['caption']\n",
    "        cap_len = len(captions)\n",
    "        for i in range(0,max_captions_len-cap_len):\n",
    "            captions.append(\"\")\n",
    "        if len(sample['imgs'].shape) > 2:\n",
    "            padding_size = (max_images_len-sample['imgs'].shape[0],sample['imgs'].shape[1],sample['imgs'].shape[2],sample['imgs'].shape[3])\n",
    "        else:\n",
    "            padding_size = (max_images_len-sample['imgs'].shape[0],sample['imgs'].shape[1])\n",
    "        padded_mem_img = paddle.concat((sample['imgs'], paddle.zeros(padding_size)),axis=0)\n",
    "        img_batch.append(padded_mem_img)\n",
    "        cap_batch.append(captions)\n",
    "        qImg_batch.append(sample['qImg'])\n",
    "        qCap_batch.append(sample['qCap'])        \n",
    "    img_batch = paddle.stack(img_batch, axis=0)\n",
    "    qImg_batch = paddle.stack(qImg_batch, axis=0)\n",
    "    return cap_batch, img_batch, qCap_batch, qImg_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:10:36.160770Z",
     "iopub.status.busy": "2023-07-26T11:10:36.160362Z",
     "iopub.status.idle": "2023-07-26T11:10:36.167522Z",
     "shell.execute_reply": "2023-07-26T11:10:36.166543Z",
     "shell.execute_reply.started": "2023-07-26T11:10:36.160742Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load DataLoader\n",
    "from paddle.io import DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn = collate_context_bert_train, return_list=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn = collate_context_bert_train,  return_list=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=False, collate_fn = collate_context_bert_test, return_list=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:10:36.168934Z",
     "iopub.status.busy": "2023-07-26T11:10:36.168616Z",
     "iopub.status.idle": "2023-07-26T11:10:37.878559Z",
     "shell.execute_reply": "2023-07-26T11:10:37.877474Z",
     "shell.execute_reply.started": "2023-07-26T11:10:36.168893Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tensor(shape=[4], dtype=int64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [0, 2, 1, 1]), [['', \"Peru's Castillo impeached and arrested, Boluarte sworn in as new president | CNN\", 'Fuente con acceso al caso', 'Castillo was detained in Lima Prefecture on Wednesday.', 'Peru President Pedro Castillo impeached by lawmakers - CNN', 'Former Peruvian President Pedro Castillo being detained in Lima Prefecture. (Fuente con acceso al caso)', 'Former Peruvian President Pedro Castillo being detained in Lima Prefecture.', \"Who is Dina Boluarte, Peru's first female president? | CNN\", 'Fuente con acceso al caso', 'Peruvian President Pedro Castillo being detained.', '', \"Peru's Castillo impeached and arrested, Boluarte sworn in as new president | CNN\", 'Fuente con acceso al caso', 'Castillo was detained in Lima Prefecture on Wednesday.', \"Peru's President Pedro Castillo replaced by Dina Boluarte after impeachment - BBC News\", 'Dina Boluarte said she would govern until 2026', \"Dina Boluarte greets members of the Congress after being sworn in as Peru's new leader after Congress removes President Pedro Castillo in Lima, Peru on 7 December 2022\", \"Peru's Castillo impeached and arrested, Boluarte sworn in as new president | CNN\", 'Fuente con acceso al caso', 'Castillo was detained in Lima Prefecture on Wednesday.', \"Peru's Castillo impeached and arrested, Boluarte sworn in as new president | CNN\", 'Fuente con acceso al caso', 'Castillo was detained in Lima Prefecture on Wednesday.', \"Peru's Castillo impeached and arrested, Boluarte sworn in as new president | CNN\"], ['', '', 'Goodnight Mommy (2022) - IMDb', 'Naomi Watts, Nicholas Crovetti, and Cameron Crovetti in Goodnight Mommy (2022)', 'Goodnight Racism by Ibram X. Kendi: 9780593110515 | PenguinRandomHouse.com: Books', 'Goodnight Racism by Ibram X. Kendi', 'Goodnight, Sleepy Princess | Book by IglooBooks, Claudia Ranucci | Official Publisher Page | Simon & Schuster', 'Goodnight Already!: John, Jory, Davies, Benji: 9780062286208 ...', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', 'Full Details and Analysis: Tax Cuts and Jobs Act - Tax Foundation', 'Tax Cuts and Jobs Act Annual Rate of Economic Growth', 'Full Details and Analysis: Tax Cuts and Jobs Act - Tax Foundation', 'Tax Cuts and Jobs Act Revenue Projections', 'Details and Analysis of the 2017 Tax Cuts and Jobs Act - Tax Foundation', 'Adobe Stock, Adam Parent', 'Complete Analysis of the Tax Cuts and Jobs Act | Tax | Thomson Reuters', 'Complete Analysis of the Tax Cuts and Jobs Act', 'Analysis of the Tax Cuts and Jobs Act | Tax Policy Center', 'Analysis of the Tax Cuts and Jobs Act | Tax Policy Center', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '白菜滞销，满满一车500斤，才卖30元，被老婆指责，农民崩溃大哭。_哔哩哔哩_bilibili', '', '河南白菜500斤才卖30块_河南白菜500斤才卖30块一斤_1500斤白菜卖了15元 - 抖音', '系摆拍！发布者称大叔因500斤白菜卖30元痛哭视频是摆拍，目前已删除。 #摆拍  #河南  #白菜  #秋收', '摆拍“菜贱伤农”苦情戏，白白消耗公众爱心，同样是罪恶 - 知乎', '（图片截取自抖音号：红星新闻）', '河南白菜500斤才卖30块_河南白菜500斤才卖30块一斤_1500斤白菜卖了15元 - 抖音', '河南商丘一菜农因五百斤白菜卖30元痛哭？当事人承认系摆拍。', '孙子集体回家为爷爷庆生，隔天又要返程#监控下的一幕#感动#感动- 抖音', '摆拍“菜贱伤农”苦情戏，白白消耗公众爱心，同样是罪恶 - 知乎', '（图片截取自抖音号：红星新闻）', '', '', '', '', '', '', '', '', '', '', '', '']], Tensor(shape=[4, 6, 3, 224, 224], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[[[[-0.18280666, -0.19993141, -0.21705617, ..., -1.02191973,\n",
      "            -1.02191973, -1.03904438],\n",
      "           [-0.21705617, -0.21705617, -0.21705617, ..., -1.03904438,\n",
      "            -1.03904438, -1.03904438],\n",
      "           [-0.25130567, -0.25130567, -0.23418093, ..., -1.03904438,\n",
      "            -1.03904438, -1.03904438],\n",
      "           ...,\n",
      "           [-1.77540886, -1.77540886, -1.77540886, ..., -1.75828421,\n",
      "            -1.75828421, -1.75828421],\n",
      "           [-1.75828421, -1.75828421, -1.75828421, ..., -1.75828421,\n",
      "            -1.75828421, -1.75828421],\n",
      "           [-1.77540886, -1.79253364, -1.79253364, ..., -1.77540886,\n",
      "            -1.77540886, -1.77540886]],\n",
      "\n",
      "          [[-0.26750684, -0.26750684, -0.24999984, ..., -0.74019599,\n",
      "            -0.75770301, -0.77521002],\n",
      "           [-0.26750684, -0.26750684, -0.24999984, ..., -0.75770301,\n",
      "            -0.77521002, -0.77521002],\n",
      "           [-0.28501382, -0.28501382, -0.26750684, ..., -0.75770301,\n",
      "            -0.77521002, -0.77521002],\n",
      "           ...,\n",
      "           [-1.58053207, -1.58053207, -1.58053207, ..., -1.52801108,\n",
      "            -1.52801108, -1.52801108],\n",
      "           [-1.56302512, -1.56302512, -1.56302512, ..., -1.52801108,\n",
      "            -1.52801108, -1.52801108],\n",
      "           [-1.56302512, -1.54551804, -1.54551804, ..., -1.52801108,\n",
      "            -1.51050401, -1.51050401]],\n",
      "\n",
      "          [[-0.20095852, -0.18352933, -0.14867094, ..., -0.46239641,\n",
      "            -0.44496724, -0.46239641],\n",
      "           [-0.20095852, -0.18352933, -0.14867094, ..., -0.46239641,\n",
      "            -0.46239641, -0.46239641],\n",
      "           [-0.18352933, -0.18352933, -0.16610013, ..., -0.46239641,\n",
      "            -0.46239641, -0.46239641],\n",
      "           ...,\n",
      "           [-1.35128534, -1.35128534, -1.35128534, ..., -1.24671006,\n",
      "            -1.24671006, -1.24671006],\n",
      "           [-1.33385611, -1.33385611, -1.33385611, ..., -1.24671006,\n",
      "            -1.24671006, -1.24671006],\n",
      "           [-1.33385611, -1.33385611, -1.33385611, ..., -1.26413929,\n",
      "            -1.24671006, -1.24671006]]],\n",
      "\n",
      "\n",
      "         [[[ 0.10831413,  0.19393790,  0.21106265, ...,  1.80366492,\n",
      "             1.82078969,  1.83791447],\n",
      "           [ 0.12543888,  0.21106265,  0.24531215, ...,  1.82078969,\n",
      "             1.83791447,  1.85503912],\n",
      "           [ 0.14256364,  0.22818740,  0.24531215, ...,  1.83791447,\n",
      "             1.85503912,  1.85503912],\n",
      "           ...,\n",
      "           [-0.64517510, -0.55955136, -0.50817710, ..., -1.65553570,\n",
      "            -1.65553570, -1.65553570],\n",
      "           [-0.81642264, -0.69654936, -0.61092561, ..., -1.65553570,\n",
      "            -1.65553570, -1.62128615],\n",
      "           [-0.98767018, -0.86779690, -0.76504838, ..., -1.67266035,\n",
      "            -1.65553570, -1.65553570]],\n",
      "\n",
      "          [[-0.75770301, -0.72268897, -0.75770301, ...,  1.97338963,\n",
      "             1.99089658,  2.00840354],\n",
      "           [-0.74019599, -0.70518202, -0.72268897, ...,  1.99089658,\n",
      "             2.00840354,  2.02591062],\n",
      "           [-0.72268897, -0.68767500, -0.70518202, ...,  2.00840354,\n",
      "             2.02591062,  2.02591062],\n",
      "           ...,\n",
      "           [-1.30042005, -1.21288502, -1.17787099, ..., -1.89565825,\n",
      "            -1.93067217, -1.93067217],\n",
      "           [-1.49299705, -1.37044799, -1.30042005, ..., -1.89565825,\n",
      "            -1.91316521, -1.91316521],\n",
      "           [-1.65056014, -1.54551804, -1.44047606, ..., -1.87815118,\n",
      "            -1.89565825, -1.89565825]],\n",
      "\n",
      "          [[-1.05498910, -1.00270152, -1.00270152, ...,  2.39599180,\n",
      "             2.41342068,  2.43085027],\n",
      "           [-1.03755987, -0.98527229, -0.98527229, ...,  2.41342068,\n",
      "             2.43085027,  2.44827914],\n",
      "           [-1.02013063, -0.96784306, -0.96784306, ...,  2.43085027,\n",
      "             2.44827914,  2.44827914],\n",
      "           ...,\n",
      "           [-1.52557731, -1.40357304, -1.33385611, ..., -1.73472762,\n",
      "            -1.75215685, -1.75215685],\n",
      "           [-1.66501093, -1.54300654, -1.45586061, ..., -1.75215685,\n",
      "            -1.75215685, -1.75215685],\n",
      "           [-1.76958609, -1.68244004, -1.59529412, ..., -1.76958609,\n",
      "            -1.76958609, -1.76958609]]],\n",
      "\n",
      "\n",
      "         [[[-0.19993141, -0.21705617, -0.21705617, ..., -1.02191973,\n",
      "            -1.02191973, -1.03904438],\n",
      "           [-0.23418093, -0.23418093, -0.21705617, ..., -1.02191973,\n",
      "            -1.03904438, -1.03904438],\n",
      "           [-0.26843041, -0.25130567, -0.23418093, ..., -1.02191973,\n",
      "            -1.03904438, -1.05616915],\n",
      "           ...,\n",
      "           [-1.77540886, -1.77540886, -1.77540886, ..., -1.75828421,\n",
      "            -1.75828421, -1.74115944],\n",
      "           [-1.75828421, -1.75828421, -1.77540886, ..., -1.75828421,\n",
      "            -1.77540886, -1.75828421],\n",
      "           [-1.75828421, -1.75828421, -1.79253364, ..., -1.79253364,\n",
      "            -1.75828421, -1.75828421]],\n",
      "\n",
      "          [[-0.24999984, -0.24999984, -0.24999984, ..., -0.75770301,\n",
      "            -0.75770301, -0.77521002],\n",
      "           [-0.26750684, -0.26750684, -0.24999984, ..., -0.75770301,\n",
      "            -0.77521002, -0.77521002],\n",
      "           [-0.30252084, -0.28501382, -0.26750684, ..., -0.75770301,\n",
      "            -0.77521002, -0.79271698],\n",
      "           ...,\n",
      "           [-1.58053207, -1.58053207, -1.58053207, ..., -1.52801108,\n",
      "            -1.52801108, -1.51050401],\n",
      "           [-1.56302512, -1.56302512, -1.56302512, ..., -1.52801108,\n",
      "            -1.54551804, -1.52801108],\n",
      "           [-1.56302512, -1.56302512, -1.54551804, ..., -1.56302512,\n",
      "            -1.52801108, -1.52801108]],\n",
      "\n",
      "          [[-0.18352933, -0.18352933, -0.16610013, ..., -0.44496724,\n",
      "            -0.44496724, -0.46239641],\n",
      "           [-0.16610013, -0.16610013, -0.16610013, ..., -0.44496724,\n",
      "            -0.46239641, -0.46239641],\n",
      "           [-0.20095852, -0.18352933, -0.16610013, ..., -0.44496724,\n",
      "            -0.46239641, -0.47982562],\n",
      "           ...,\n",
      "           [-1.35128534, -1.35128534, -1.35128534, ..., -1.24671006,\n",
      "            -1.24671006, -1.22928095],\n",
      "           [-1.33385611, -1.33385611, -1.33385611, ..., -1.24671006,\n",
      "            -1.26413929, -1.24671006],\n",
      "           [-1.33385611, -1.33385611, -1.33385611, ..., -1.29899776,\n",
      "            -1.26413929, -1.26413929]]],\n",
      "\n",
      "\n",
      "         [[[-0.18280666, -0.18280666, -0.19993141, ..., -1.02191973,\n",
      "            -1.02191973, -1.02191973],\n",
      "           [-0.23418093, -0.21705617, -0.21705617, ..., -1.02191973,\n",
      "            -1.03904438, -1.03904438],\n",
      "           [-0.25130567, -0.25130567, -0.23418093, ..., -1.02191973,\n",
      "            -1.03904438, -1.03904438],\n",
      "           ...,\n",
      "           [-1.77540886, -1.77540886, -1.77540886, ..., -1.75828421,\n",
      "            -1.75828421, -1.75828421],\n",
      "           [-1.75828421, -1.75828421, -1.75828421, ..., -1.77540886,\n",
      "            -1.75828421, -1.75828421],\n",
      "           [-1.75828421, -1.77540886, -1.79253364, ..., -1.79253364,\n",
      "            -1.77540886, -1.77540886]],\n",
      "\n",
      "          [[-0.26750684, -0.26750684, -0.24999984, ..., -0.74019599,\n",
      "            -0.75770301, -0.75770301],\n",
      "           [-0.26750684, -0.26750684, -0.24999984, ..., -0.74019599,\n",
      "            -0.77521002, -0.77521002],\n",
      "           [-0.30252084, -0.28501382, -0.26750684, ..., -0.74019599,\n",
      "            -0.77521002, -0.77521002],\n",
      "           ...,\n",
      "           [-1.58053207, -1.58053207, -1.58053207, ..., -1.52801108,\n",
      "            -1.52801108, -1.52801108],\n",
      "           [-1.56302512, -1.56302512, -1.56302512, ..., -1.54551804,\n",
      "            -1.52801108, -1.52801108],\n",
      "           [-1.56302512, -1.54551804, -1.54551804, ..., -1.54551804,\n",
      "            -1.51050401, -1.51050401]],\n",
      "\n",
      "          [[-0.20095852, -0.20095852, -0.16610013, ..., -0.46239641,\n",
      "            -0.44496724, -0.44496724],\n",
      "           [-0.20095852, -0.20095852, -0.16610013, ..., -0.47982562,\n",
      "            -0.46239641, -0.46239641],\n",
      "           [-0.20095852, -0.18352933, -0.16610013, ..., -0.47982562,\n",
      "            -0.46239641, -0.46239641],\n",
      "           ...,\n",
      "           [-1.35128534, -1.35128534, -1.35128534, ..., -1.24671006,\n",
      "            -1.24671006, -1.24671006],\n",
      "           [-1.33385611, -1.33385611, -1.33385611, ..., -1.26413929,\n",
      "            -1.24671006, -1.24671006],\n",
      "           [-1.33385611, -1.33385611, -1.33385611, ..., -1.28156853,\n",
      "            -1.24671006, -1.24671006]]],\n",
      "\n",
      "\n",
      "         [[[-0.21705617, -0.21705617, -0.19993141, ..., -1.00479496,\n",
      "            -1.02191973, -1.02191973],\n",
      "           [-0.21705617, -0.21705617, -0.21705617, ..., -1.02191973,\n",
      "            -1.03904438, -1.03904438],\n",
      "           [-0.25130567, -0.25130567, -0.25130567, ..., -1.02191973,\n",
      "            -1.03904438, -1.03904438],\n",
      "           ...,\n",
      "           [-1.77540886, -1.77540886, -1.77540886, ..., -1.77540886,\n",
      "            -1.75828421, -1.75828421],\n",
      "           [-1.75828421, -1.75828421, -1.75828421, ..., -1.77540886,\n",
      "            -1.75828421, -1.75828421],\n",
      "           [-1.75828421, -1.75828421, -1.75828421, ..., -1.77540886,\n",
      "            -1.75828421, -1.75828421]],\n",
      "\n",
      "          [[-0.26750684, -0.26750684, -0.24999984, ..., -0.74019599,\n",
      "            -0.75770301, -0.75770301],\n",
      "           [-0.26750684, -0.26750684, -0.26750684, ..., -0.75770301,\n",
      "            -0.77521002, -0.77521002],\n",
      "           [-0.30252084, -0.28501382, -0.28501382, ..., -0.75770301,\n",
      "            -0.77521002, -0.77521002],\n",
      "           ...,\n",
      "           [-1.58053207, -1.58053207, -1.58053207, ..., -1.54551804,\n",
      "            -1.52801108, -1.52801108],\n",
      "           [-1.56302512, -1.56302512, -1.56302512, ..., -1.54551804,\n",
      "            -1.52801108, -1.52801108],\n",
      "           [-1.56302512, -1.56302512, -1.56302512, ..., -1.54551804,\n",
      "            -1.52801108, -1.52801108]],\n",
      "\n",
      "          [[-0.20095852, -0.20095852, -0.18352933, ..., -0.42753804,\n",
      "            -0.44496724, -0.44496724],\n",
      "           [-0.20095852, -0.20095852, -0.20095852, ..., -0.44496724,\n",
      "            -0.46239641, -0.46239641],\n",
      "           [-0.20095852, -0.20095852, -0.18352933, ..., -0.44496724,\n",
      "            -0.46239641, -0.46239641],\n",
      "           ...,\n",
      "           [-1.35128534, -1.35128534, -1.35128534, ..., -1.28156853,\n",
      "            -1.26413929, -1.24671006],\n",
      "           [-1.33385611, -1.33385611, -1.33385611, ..., -1.28156853,\n",
      "            -1.26413929, -1.26413929],\n",
      "           [-1.33385611, -1.33385611, -1.33385611, ..., -1.28156853,\n",
      "            -1.26413929, -1.26413929]]],\n",
      "\n",
      "\n",
      "         [[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.62128615, -1.63841093, -1.63841093, ..., -1.53566241,\n",
      "            -1.51853764, -1.48428810],\n",
      "           [-1.60416138, -1.62128615, -1.62128615, ..., -1.55278718,\n",
      "            -1.53566241, -1.50141287],\n",
      "           [-1.60416138, -1.62128615, -1.62128615, ..., -1.56991184,\n",
      "            -1.55278718, -1.51853764],\n",
      "           ...,\n",
      "           [-1.58703661, -1.58703661, -1.58703661, ..., -1.70690989,\n",
      "            -1.72403467, -1.72403467],\n",
      "           [-1.58703661, -1.58703661, -1.58703661, ..., -1.72403467,\n",
      "            -1.72403467, -1.74115944],\n",
      "           [-1.58703661, -1.58703661, -1.58703661, ..., -1.70690989,\n",
      "            -1.72403467, -1.72403467]],\n",
      "\n",
      "          [[-1.52801108, -1.54551804, -1.56302512, ..., -1.35294104,\n",
      "            -1.31792700, -1.26540601],\n",
      "           [-1.51050401, -1.52801108, -1.54551804, ..., -1.37044799,\n",
      "            -1.33543408, -1.28291309],\n",
      "           [-1.49299705, -1.52801108, -1.54551804, ..., -1.37044799,\n",
      "            -1.31792700, -1.28291309],\n",
      "           ...,\n",
      "           [-1.73809516, -1.73809516, -1.73809516, ..., -1.79061615,\n",
      "            -1.79061615, -1.79061615],\n",
      "           [-1.75560224, -1.73809516, -1.73809516, ..., -1.79061615,\n",
      "            -1.79061615, -1.79061615],\n",
      "           [-1.73809516, -1.73809516, -1.73809516, ..., -1.79061615,\n",
      "            -1.79061615, -1.79061615]],\n",
      "\n",
      "          [[-1.28156853, -1.29899776, -1.29899776, ..., -1.07241821,\n",
      "            -1.03755987, -1.00270152],\n",
      "           [-1.24671006, -1.28156853, -1.29899776, ..., -1.08984745,\n",
      "            -1.05498910, -1.00270152],\n",
      "           [-1.24671006, -1.28156853, -1.28156853, ..., -1.08984745,\n",
      "            -1.05498910, -1.02013063],\n",
      "           ...,\n",
      "           [-1.24671006, -1.22928095, -1.24671006, ..., -1.38614368,\n",
      "            -1.40357304, -1.42100215],\n",
      "           [-1.24671006, -1.24671006, -1.24671006, ..., -1.40357304,\n",
      "            -1.42100215, -1.42100215],\n",
      "           [-1.24671006, -1.24671006, -1.26413929, ..., -1.42100215,\n",
      "            -1.42100215, -1.42100215]]],\n",
      "\n",
      "\n",
      "         [[[-1.68978512, -1.72403467, -1.70690989, ...,  0.05693987,\n",
      "            -0.38830370, -0.52530187],\n",
      "           [-1.74115944, -1.72403467, -1.70690989, ..., -0.01155914,\n",
      "            -0.50817710, -0.57667613],\n",
      "           [-1.72403467, -1.70690989, -1.70690989, ..., -0.28555518,\n",
      "            -0.64517510, -0.69654936],\n",
      "           ...,\n",
      "           [ 0.09118938,  0.09118938,  0.14256364, ..., -1.24454141,\n",
      "            -1.10754347, -0.86779690],\n",
      "           [ 0.12543888,  0.15968838,  0.14256364, ..., -1.24454141,\n",
      "            -1.09041870, -0.85067213],\n",
      "           [ 0.09118938,  0.24531215,  0.45080918, ..., -1.22741675,\n",
      "            -1.05616915, -0.81642264]],\n",
      "\n",
      "          [[-1.49299705, -1.52801108, -1.51050401, ..., -0.35504183,\n",
      "            -0.82773101, -1.03781497],\n",
      "           [-1.54551804, -1.52801108, -1.51050401, ..., -0.42506999,\n",
      "            -0.96778703, -1.09033608],\n",
      "           [-1.52801108, -1.51050401, -1.51050401, ..., -0.75770301,\n",
      "            -1.05532205, -1.12535000],\n",
      "           ...,\n",
      "           [ 0.46778721,  0.46778721,  0.48529422, ..., -1.82563019,\n",
      "            -1.82563019, -1.84313726],\n",
      "           [ 0.59033620,  0.59033620,  0.52030820, ..., -1.82563019,\n",
      "            -1.82563019, -1.84313726],\n",
      "           [ 0.62535024,  0.76540625,  0.88795525, ..., -1.84313726,\n",
      "            -1.80812323, -1.82563019]],\n",
      "\n",
      "          [[-1.03755987, -1.07241821, -1.05498910, ..., -1.08984745,\n",
      "            -1.50814819, -1.68244004],\n",
      "           [-1.07241821, -1.08984745, -1.03755987, ..., -1.15956414,\n",
      "            -1.64758170, -1.71729851],\n",
      "           [-1.05498910, -1.05498910, -1.03755987, ..., -1.36871445,\n",
      "            -1.69986928, -1.76958609],\n",
      "           ...,\n",
      "           [ 0.89708078,  0.87965161,  0.93193918, ..., -1.78701520,\n",
      "            -1.80444443, -1.76958609],\n",
      "           [ 1.17594790,  1.12366033,  1.05394351, ..., -1.78701520,\n",
      "            -1.80444443, -1.76958609],\n",
      "           [ 1.36766899,  1.45481503,  1.54196119, ..., -1.78701520,\n",
      "            -1.78701520, -1.75215685]]],\n",
      "\n",
      "\n",
      "         [[[ 1.08442509,  0.79330426,  0.75905472, ...,  1.97491241,\n",
      "             1.42692029,  1.25567281],\n",
      "           [ 0.75905472,  0.75905472,  0.79330426, ...,  1.35842133,\n",
      "             1.17004907,  1.20429862],\n",
      "           [ 0.72480524,  0.75905472,  0.81042898, ...,  1.46116984,\n",
      "             1.32417178,  1.22142327],\n",
      "           ...,\n",
      "           [ 1.10154974,  0.98167652,  0.84467852, ...,  0.62205672,\n",
      "             0.55355769,  0.39943492],\n",
      "           [ 1.75229061,  1.64954209,  1.46116984, ...,  0.67343098,\n",
      "             0.63918144,  0.58780718],\n",
      "           [ 1.95778763,  1.87216389,  1.52966881, ...,  0.63918144,\n",
      "             0.69055575,  0.67343098]],\n",
      "\n",
      "          [[ 0.97549027,  0.71288526,  0.69537824, ...,  1.83333361,\n",
      "             0.24019620, -0.44257697],\n",
      "           [ 0.66036421,  0.69537824,  0.71288526, ...,  0.43277320,\n",
      "            -0.30252084, -0.37254897],\n",
      "           [ 0.66036421,  0.69537824,  0.74789923, ..., -0.00490182,\n",
      "            -0.26750684, -0.39005598],\n",
      "           ...,\n",
      "           [ 0.62535024,  0.55532223,  0.41526622, ...,  0.90546227,\n",
      "             1.08053231,  1.06302524],\n",
      "           [ 1.30812323,  1.20308125,  1.06302524, ...,  1.04551828,\n",
      "             1.06302524,  1.06302524],\n",
      "           [ 1.51820755,  1.44817960,  1.25560224, ...,  1.09803927,\n",
      "             1.08053231,  1.02801120]],\n",
      "\n",
      "          [[ 1.19337702,  1.00165594,  1.03651428, ...,  1.48967338,\n",
      "             0.74021804,  0.44392177],\n",
      "           [ 0.96679759,  0.94936836,  1.01908517, ...,  0.75764722,\n",
      "             0.46135095,  0.47878015],\n",
      "           [ 0.94936836,  1.00165594,  1.01908517, ...,  0.68793046,\n",
      "             0.53106773,  0.49620935],\n",
      "           ...,\n",
      "           [ 0.93193918,  0.87965161,  0.96679759, ...,  1.47224414,\n",
      "             1.96026182,  2.06483698],\n",
      "           [ 0.91451001,  0.87965161,  0.98422676, ...,  1.94283271,\n",
      "             2.01254940,  2.01254940],\n",
      "           [ 0.91451001,  0.94936836,  1.05394351, ...,  2.15198302,\n",
      "             2.02997851,  1.94283271]]],\n",
      "\n",
      "\n",
      "         [[[-0.83354741, -0.83354741, -0.83354741, ..., -0.83354741,\n",
      "            -0.83354741, -0.83354741],\n",
      "           [-0.81642264, -0.81642264, -0.81642264, ..., -0.83354741,\n",
      "            -0.83354741, -0.81642264],\n",
      "           [-0.81642264, -0.81642264, -0.81642264, ..., -0.83354741,\n",
      "            -0.83354741, -0.81642264],\n",
      "           ...,\n",
      "           [-0.83354741, -0.83354741, -0.83354741, ..., -0.83354741,\n",
      "            -0.83354741, -0.83354741],\n",
      "           [-0.83354741, -0.83354741, -0.83354741, ..., -0.83354741,\n",
      "            -0.83354741, -0.83354741],\n",
      "           [-0.83354741, -0.83354741, -0.83354741, ..., -0.83354741,\n",
      "            -0.83354741, -0.83354741]],\n",
      "\n",
      "          [[ 1.08053231,  1.08053231,  1.08053231, ...,  1.08053231,\n",
      "             1.08053231,  1.08053231],\n",
      "           [ 1.06302524,  1.06302524,  1.06302524, ...,  1.08053231,\n",
      "             1.08053231,  1.06302524],\n",
      "           [ 1.06302524,  1.06302524,  1.06302524, ...,  1.08053231,\n",
      "             1.08053231,  1.06302524],\n",
      "           ...,\n",
      "           [ 1.08053231,  1.08053231,  1.08053231, ...,  1.08053231,\n",
      "             1.08053231,  1.08053231],\n",
      "           [ 1.08053231,  1.08053231,  1.08053231, ...,  1.08053231,\n",
      "             1.08053231,  1.08053231],\n",
      "           [ 1.08053231,  1.08053231,  1.08053231, ...,  1.08053231,\n",
      "             1.08053231,  1.08053231]],\n",
      "\n",
      "          [[ 1.59424877,  1.59424877,  1.59424877, ...,  1.59424877,\n",
      "             1.59424877,  1.59424877],\n",
      "           [ 1.59424877,  1.59424877,  1.59424877, ...,  1.59424877,\n",
      "             1.59424877,  1.59424877],\n",
      "           [ 1.59424877,  1.59424877,  1.59424877, ...,  1.59424877,\n",
      "             1.59424877,  1.59424877],\n",
      "           ...,\n",
      "           [ 1.59424877,  1.59424877,  1.59424877, ...,  1.59424877,\n",
      "             1.59424877,  1.59424877],\n",
      "           [ 1.59424877,  1.59424877,  1.59424877, ...,  1.59424877,\n",
      "             1.59424877,  1.59424877],\n",
      "           [ 1.59424877,  1.59424877,  1.59424877, ...,  1.59424877,\n",
      "             1.59424877,  1.59424877]]],\n",
      "\n",
      "\n",
      "         [[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]]],\n",
      "\n",
      "\n",
      "         [[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.00479496,  0.86180323,  2.23178363, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828],\n",
      "           [-0.79929787,  0.94742703,  2.21465898, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828],\n",
      "           [ 1.56391835,  1.92353821,  2.21465898, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828],\n",
      "           ...,\n",
      "           [ 1.32417178,  1.40979564,  1.63241732, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828],\n",
      "           [ 2.14615989,  2.06053615,  2.14615989, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828],\n",
      "           [ 2.19753432,  2.21465898,  2.21465898, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828]],\n",
      "\n",
      "          [[-0.89775902,  1.01050425,  2.41106486, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146],\n",
      "           [-0.68767500,  1.09803927,  2.39355755, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146],\n",
      "           [ 1.72829151,  2.09593868,  2.39355755, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146],\n",
      "           ...,\n",
      "           [ 1.48319352,  1.57072854,  1.79831958, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146],\n",
      "           [ 2.32352948,  2.23599482,  2.32352948, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146],\n",
      "           [ 2.39355755,  2.39355755,  2.41106486, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146]],\n",
      "\n",
      "          [[-0.67154676,  1.22823548,  2.62257099, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010],\n",
      "           [-0.46239641,  1.31538141,  2.60514212, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010],\n",
      "           [ 1.94283271,  2.30884552,  2.60514212, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010],\n",
      "           ...,\n",
      "           [ 1.69882393,  1.78596997,  2.01254940, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010],\n",
      "           [ 2.53542542,  2.44827914,  2.53542542, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010],\n",
      "           [ 2.60514212,  2.60514212,  2.62257099, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010]]],\n",
      "\n",
      "\n",
      "         [[[ 2.18040943,  2.21465898,  2.19753432, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828],\n",
      "           [ 2.24890828,  2.24890828,  2.24890828, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828],\n",
      "           [ 2.24890828,  2.24890828,  2.24890828, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828],\n",
      "           ...,\n",
      "           [ 2.14615989,  2.21465898,  1.40979564, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828],\n",
      "           [ 2.14615989,  2.21465898,  1.99203718, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828],\n",
      "           [ 2.23178363,  2.24890828,  2.24890828, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828]],\n",
      "\n",
      "          [[ 2.35854340,  2.39355755,  2.37605071, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146],\n",
      "           [ 2.42857146,  2.42857146,  2.42857146, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146],\n",
      "           [ 2.42857146,  2.42857146,  2.42857146, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146],\n",
      "           ...,\n",
      "           [ 2.32352948,  2.39355755,  1.57072854, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146],\n",
      "           [ 2.32352948,  2.39355755,  2.16596651, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146],\n",
      "           [ 2.41106486,  2.42857146,  2.42857146, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146]],\n",
      "\n",
      "          [[ 2.57028365,  2.60514212,  2.58771276, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010],\n",
      "           [ 2.64000010,  2.64000010,  2.64000010, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010],\n",
      "           [ 2.64000010,  2.64000010,  2.64000010, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010],\n",
      "           ...,\n",
      "           [ 2.53542542,  2.60514212,  1.78596997, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010],\n",
      "           [ 2.53542542,  2.60514212,  2.37856245, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010],\n",
      "           [ 2.62257099,  2.64000010,  2.64000010, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010]]],\n",
      "\n",
      "\n",
      "         [[[-1.80965841, -1.82678318, -1.80965841, ..., -1.74115944,\n",
      "            -1.74115944, -1.75828421],\n",
      "           [-1.80965841, -1.80965841, -1.80965841, ..., -1.75828421,\n",
      "            -1.74115944, -1.74115944],\n",
      "           [-1.80965841, -1.80965841, -1.79253364, ..., -1.74115944,\n",
      "            -1.74115944, -1.74115944],\n",
      "           ...,\n",
      "           [-1.63841093, -1.62128615, -1.60416138, ..., -1.67266035,\n",
      "            -1.65553570, -1.63841093],\n",
      "           [-1.62128615, -1.62128615, -1.60416138, ..., -1.62128615,\n",
      "            -1.62128615, -1.62128615],\n",
      "           [-1.62128615, -1.62128615, -1.58703661, ..., -1.60416138,\n",
      "            -1.60416138, -1.60416138]],\n",
      "\n",
      "          [[-1.44047606, -1.42296910, -1.44047606, ..., -1.24789906,\n",
      "            -1.24789906, -1.23039198],\n",
      "           [-1.44047606, -1.44047606, -1.42296910, ..., -1.23039198,\n",
      "            -1.23039198, -1.21288502],\n",
      "           [-1.42296910, -1.44047606, -1.42296910, ..., -1.21288502,\n",
      "            -1.23039198, -1.23039198],\n",
      "           ...,\n",
      "           [-1.61554611, -1.59803903, -1.58053207, ..., -1.61554611,\n",
      "            -1.61554611, -1.59803903],\n",
      "           [-1.59803903, -1.59803903, -1.59803903, ..., -1.58053207,\n",
      "            -1.58053207, -1.58053207],\n",
      "           [-1.59803903, -1.61554611, -1.59803903, ..., -1.58053207,\n",
      "            -1.58053207, -1.58053207]],\n",
      "\n",
      "          [[-0.25324610, -0.25324610, -0.25324610, ...,  0.14762548,\n",
      "             0.14762548,  0.13019629],\n",
      "           [-0.25324610, -0.25324610, -0.25324610, ...,  0.14762548,\n",
      "             0.14762548,  0.14762548],\n",
      "           [-0.21838771, -0.23581691, -0.25324610, ...,  0.16505466,\n",
      "             0.16505466,  0.16505466],\n",
      "           ...,\n",
      "           [-1.36871445, -1.36871445, -1.35128534, ..., -1.36871445,\n",
      "            -1.36871445, -1.35128534],\n",
      "           [-1.36871445, -1.36871445, -1.35128534, ..., -1.31642687,\n",
      "            -1.31642687, -1.29899776],\n",
      "           [-1.36871445, -1.36871445, -1.35128534, ..., -1.33385611,\n",
      "            -1.29899776, -1.31642687]]],\n",
      "\n",
      "\n",
      "         [[[-1.74115944, -2.11790395, -2.11790395, ..., -2.01515555,\n",
      "            -2.04940486, -2.06652975],\n",
      "           [-1.74115944, -2.11790395, -2.11790395, ..., -2.08365440,\n",
      "            -2.08365440, -2.10077929],\n",
      "           [-1.74115944, -2.11790395, -2.11790395, ..., -2.11790395,\n",
      "            -2.11790395, -2.10077929],\n",
      "           ...,\n",
      "           [-1.70690989, -2.11790395, -2.11790395, ..., -2.11790395,\n",
      "            -2.11790395, -2.11790395],\n",
      "           [-1.70690989, -2.11790395, -2.11790395, ..., -2.11790395,\n",
      "            -2.11790395, -2.11790395],\n",
      "           [-1.70690989, -2.11790395, -2.11790395, ..., -2.11790395,\n",
      "            -2.11790395, -2.11790395]],\n",
      "\n",
      "          [[ 0.29271722,  0.17016819,  0.27521020, ...,  0.32773119,\n",
      "             0.22268920,  0.25770321],\n",
      "           [ 0.31022421,  0.18767519,  0.27521020, ...,  0.22268920,\n",
      "             0.24019620,  0.27521020],\n",
      "           [ 0.31022421,  0.18767519,  0.27521020, ...,  0.17016819,\n",
      "             0.25770321,  0.29271722],\n",
      "           ...,\n",
      "           [ 0.18767519, -0.00490182,  0.08263319, ..., -0.00490182,\n",
      "            -0.00490182, -0.00490182],\n",
      "           [ 0.18767519, -0.00490182,  0.08263319, ..., -0.00490182,\n",
      "            -0.00490182, -0.00490182],\n",
      "           [ 0.18767519, -0.00490182,  0.08263319, ..., -0.00490182,\n",
      "            -0.00490182, -0.00490182]],\n",
      "\n",
      "          [[ 1.33281064,  1.35023987,  1.38509822, ...,  1.40252745,\n",
      "             1.36766899,  1.35023987],\n",
      "           [ 1.35023987,  1.36766899,  1.40252745, ...,  1.29795229,\n",
      "             1.33281064,  1.33281064],\n",
      "           [ 1.35023987,  1.36766899,  1.40252745, ...,  1.24566460,\n",
      "             1.31538141,  1.33281064],\n",
      "           ...,\n",
      "           [ 1.17594790,  1.10623109,  1.14108944, ...,  1.07137275,\n",
      "             1.07137275,  1.07137275],\n",
      "           [ 1.17594790,  1.10623109,  1.14108944, ...,  1.07137275,\n",
      "             1.07137275,  1.07137275],\n",
      "           [ 1.17594790,  1.10623109,  1.14108944, ...,  1.07137275,\n",
      "             1.07137275,  1.07137275]]],\n",
      "\n",
      "\n",
      "         [[[ 2.24890828,  2.24890828,  2.24890828, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828],\n",
      "           [ 2.23178363,  2.18040943,  2.18040943, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828],\n",
      "           [ 2.14615989,  2.09478569,  2.11191034, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828],\n",
      "           ...,\n",
      "           [ 2.06053615,  2.11191034,  2.23178363, ...,  2.21465898,\n",
      "             2.19753432,  2.11191034],\n",
      "           [ 2.24890828,  2.24890828,  2.24890828, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828],\n",
      "           [ 2.24890828,  2.24890828,  2.24890828, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828]],\n",
      "\n",
      "          [[ 2.42857146,  2.42857146,  2.42857146, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146],\n",
      "           [ 2.39355755,  2.41106486,  2.42857146, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146],\n",
      "           [ 2.28851557,  2.39355755,  2.39355755, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146],\n",
      "           ...,\n",
      "           [ 2.35854340,  2.41106486,  2.42857146, ...,  2.41106486,\n",
      "             2.34103680,  2.41106486],\n",
      "           [ 2.42857146,  2.42857146,  2.42857146, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146],\n",
      "           [ 2.42857146,  2.42857146,  2.42857146, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146]],\n",
      "\n",
      "          [[ 2.64000010,  2.64000010,  2.64000010, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010],\n",
      "           [ 2.62257099,  2.58771276,  2.60514212, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010],\n",
      "           [ 2.55285430,  2.55285430,  2.53542542, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010],\n",
      "           ...,\n",
      "           [ 2.58771276,  2.53542542,  2.60514212, ...,  2.50056696,\n",
      "             2.57028365,  2.64000010],\n",
      "           [ 2.64000010,  2.64000010,  2.64000010, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010],\n",
      "           [ 2.64000010,  2.64000010,  2.64000010, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010]]],\n",
      "\n",
      "\n",
      "         [[[ 1.73516595,  1.73516595,  1.73516595, ...,  1.75229061,\n",
      "             1.75229061,  1.75229061],\n",
      "           [ 1.73516595,  1.73516595,  1.73516595, ...,  1.78654015,\n",
      "             1.78654015,  1.78654015],\n",
      "           [ 1.73516595,  1.73516595,  1.73516595, ...,  1.73516595,\n",
      "             1.73516595,  1.73516595],\n",
      "           ...,\n",
      "           [ 1.73516595,  1.73516595,  1.73516595, ...,  1.49541938,\n",
      "             1.44404507,  1.56391835],\n",
      "           [ 1.73516595,  1.73516595,  1.73516595, ...,  1.73516595,\n",
      "             1.73516595,  1.73516595],\n",
      "           [ 1.75229061,  1.73516595,  1.73516595, ...,  1.71804118,\n",
      "             1.71804118,  1.73516595]],\n",
      "\n",
      "          [[ 2.20098066,  2.20098066,  2.20098066, ...,  2.21848750,\n",
      "             2.21848750,  2.21848750],\n",
      "           [ 2.20098066,  2.20098066,  2.20098066, ...,  2.25350142,\n",
      "             2.25350142,  2.25350142],\n",
      "           [ 2.20098066,  2.20098066,  2.20098066, ...,  2.20098066,\n",
      "             2.20098066,  2.20098066],\n",
      "           ...,\n",
      "           [ 2.20098066,  2.20098066,  2.20098066, ...,  1.90336156,\n",
      "             1.86834753,  2.02591062],\n",
      "           [ 2.20098066,  2.20098066,  2.20098066, ...,  2.20098066,\n",
      "             2.20098066,  2.20098066],\n",
      "           [ 2.20098066,  2.20098066,  2.20098066, ...,  2.21848750,\n",
      "             2.21848750,  2.20098066]],\n",
      "\n",
      "          [[ 2.53542542,  2.53542542,  2.53542542, ...,  2.53542542,\n",
      "             2.53542542,  2.53542542],\n",
      "           [ 2.53542542,  2.53542542,  2.53542542, ...,  2.57028365,\n",
      "             2.57028365,  2.57028365],\n",
      "           [ 2.53542542,  2.53542542,  2.53542542, ...,  2.53542542,\n",
      "             2.53542542,  2.53542542],\n",
      "           ...,\n",
      "           [ 2.53542542,  2.53542542,  2.53542542, ...,  2.18684125,\n",
      "             2.15198302,  2.32627511],\n",
      "           [ 2.53542542,  2.53542542,  2.53542542, ...,  2.51799583,\n",
      "             2.51799583,  2.53542542],\n",
      "           [ 2.53542542,  2.53542542,  2.53542542, ...,  2.55285430,\n",
      "             2.55285430,  2.53542542]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.15292406,  1.06730032,  0.98167652, ...,  0.94742703,\n",
      "             0.74193001,  0.51930821],\n",
      "           [ 1.17004907,  1.08442509,  0.99880129, ...,  0.93030226,\n",
      "             0.72480524,  0.57068247],\n",
      "           [ 1.18717384,  1.10154974,  1.03305078, ...,  0.93030226,\n",
      "             0.74193001,  0.58780718],\n",
      "           ...,\n",
      "           [-0.43967795, -0.45680270, -0.45680270, ..., -1.38153958,\n",
      "            -1.38153958, -1.38153958],\n",
      "           [-0.50817710, -0.52530187, -0.50817710, ..., -1.38153958,\n",
      "            -1.38153958, -1.38153958],\n",
      "           [-0.50817710, -0.54242659, -0.52530187, ..., -1.38153958,\n",
      "            -1.38153958, -1.38153958]],\n",
      "\n",
      "          [[ 0.80042022,  0.71288526,  0.62535024, ...,  0.64285725,\n",
      "             0.48529422,  0.29271722],\n",
      "           [ 0.83543426,  0.74789923,  0.66036421, ...,  0.64285725,\n",
      "             0.48529422,  0.32773119],\n",
      "           [ 0.87044823,  0.78291327,  0.71288526, ...,  0.62535024,\n",
      "             0.45028022,  0.34523821],\n",
      "           ...,\n",
      "           [-0.68767500, -0.70518202, -0.70518202, ..., -1.59803903,\n",
      "            -1.59803903, -1.61554611],\n",
      "           [-0.75770301, -0.77521002, -0.75770301, ..., -1.59803903,\n",
      "            -1.59803903, -1.61554611],\n",
      "           [-0.75770301, -0.79271698, -0.77521002, ..., -1.59803903,\n",
      "            -1.59803903, -1.61554611]],\n",
      "\n",
      "          [[ 0.32191741,  0.23477145,  0.14762548, ...,  0.39163420,\n",
      "             0.26962984,  0.09533790],\n",
      "           [ 0.35677579,  0.26962984,  0.18248387, ...,  0.33934662,\n",
      "             0.21734224,  0.11276709],\n",
      "           [ 0.33934662,  0.25220063,  0.18248387, ...,  0.33934662,\n",
      "             0.21734224,  0.11276709],\n",
      "           ...,\n",
      "           [-1.59529412, -1.61272335, -1.61272335, ..., -1.73472762,\n",
      "            -1.71729851, -1.69986928],\n",
      "           [-1.66501093, -1.68244004, -1.66501093, ..., -1.73472762,\n",
      "            -1.71729851, -1.69986928],\n",
      "           [-1.66501093, -1.69986928, -1.68244004, ..., -1.73472762,\n",
      "            -1.71729851, -1.69986928]]],\n",
      "\n",
      "\n",
      "         [[[ 1.54679358,  0.57068247, -0.52530187, ...,  1.76941538,\n",
      "             0.36518541, -1.00479496],\n",
      "           [ 0.77617949, -0.18280666, -0.42255321, ...,  1.58104312,\n",
      "            -0.04580864, -0.67942464],\n",
      "           [ 0.63918144,  0.31381115,  0.17681314, ...,  1.54679358,\n",
      "             0.14256364, -0.01155914],\n",
      "           ...,\n",
      "           [-1.09041870, -1.07329392, -0.88492167, ..., -0.83354741,\n",
      "            -0.50817710,  0.07406463],\n",
      "           [-1.10754347, -1.07329392, -0.93629593, ..., -1.41578913,\n",
      "            -1.26166618, -0.86779690],\n",
      "           [-1.10754347, -1.17604244, -1.03904438, ..., -0.91917115,\n",
      "            -0.95342064,  0.50218344]],\n",
      "\n",
      "          [[ 1.67577052,  0.67787123, -0.44257697, ...,  1.93837559,\n",
      "             0.50280124, -0.89775902],\n",
      "           [ 0.88795525, -0.09243682, -0.33753484, ...,  1.74579859,\n",
      "             0.08263319, -0.56512600],\n",
      "           [ 0.74789923,  0.41526622,  0.27521020, ...,  1.71078455,\n",
      "             0.27521020,  0.11764719],\n",
      "           ...,\n",
      "           [-0.81022400, -0.79271698, -0.60013998, ..., -1.05532205,\n",
      "            -0.40756297,  0.34523821],\n",
      "           [-0.82773101, -0.79271698, -0.65266097, ..., -1.21288502,\n",
      "            -0.98529404, -0.61764699],\n",
      "           [-0.82773101, -0.89775902, -0.75770301, ..., -0.65266097,\n",
      "            -0.72268897,  0.66036421]],\n",
      "\n",
      "          [[ 1.90797424,  0.91451001, -0.20095852, ...,  2.15198302,\n",
      "             0.72278887, -0.67154676],\n",
      "           [ 1.12366033,  0.14762548, -0.09638323, ...,  1.96026182,\n",
      "             0.30448821, -0.34039208],\n",
      "           [ 0.98422676,  0.65307206,  0.51363856, ...,  1.92540348,\n",
      "             0.49620935,  0.33934662],\n",
      "           ...,\n",
      "           [-1.49071896, -1.47328973, -1.28156853, ..., -1.17699337,\n",
      "            -0.56697160,  0.21734224],\n",
      "           [-1.50814819, -1.47328973, -1.33385611, ..., -1.40357304,\n",
      "            -1.15956414, -0.70640510],\n",
      "           [-1.50814819, -1.57786489, -1.43843138, ..., -0.81098026,\n",
      "            -0.86326784,  0.63564289]]],\n",
      "\n",
      "\n",
      "         [[[ 1.27279758,  1.27279758,  1.27279758, ..., -0.19993141,\n",
      "            -0.23418093, -0.23418093],\n",
      "           [ 1.27279758,  1.27279758,  1.27279758, ..., -0.21705617,\n",
      "            -0.25130567, -0.25130567],\n",
      "           [ 1.27279758,  1.27279758,  1.27279758, ..., -0.21705617,\n",
      "            -0.25130567, -0.25130567],\n",
      "           ...,\n",
      "           [-1.38153958, -1.36441481, -1.34729016, ..., -0.98767018,\n",
      "            -0.98767018, -0.98767018],\n",
      "           [-1.36441481, -1.34729016, -1.33016539, ..., -0.98767018,\n",
      "            -0.98767018, -0.98767018],\n",
      "           [-1.33016539, -1.33016539, -1.33016539, ..., -0.98767018,\n",
      "            -0.98767018, -0.98767018]],\n",
      "\n",
      "          [[ 1.44817960,  1.44817960,  1.44817960, ...,  0.03011219,\n",
      "             0.04761919,  0.06512619],\n",
      "           [ 1.44817960,  1.44817960,  1.44817960, ...,  0.01260518,\n",
      "             0.03011219,  0.04761919],\n",
      "           [ 1.44817960,  1.44817960,  1.44817960, ...,  0.01260518,\n",
      "             0.03011219,  0.04761919],\n",
      "           ...,\n",
      "           [-1.23039198, -1.21288502, -1.19537807, ..., -0.82773101,\n",
      "            -0.82773101, -0.82773101],\n",
      "           [-1.19537807, -1.17787099, -1.16036403, ..., -0.82773101,\n",
      "            -0.82773101, -0.82773101],\n",
      "           [-1.16036403, -1.16036403, -1.14285707, ..., -0.82773101,\n",
      "            -0.82773101, -0.82773101]],\n",
      "\n",
      "          [[ 1.57681954,  1.57681954,  1.57681954, ..., -0.21838771,\n",
      "            -0.25324610, -0.28810447],\n",
      "           [ 1.57681954,  1.57681954,  1.57681954, ..., -0.23581691,\n",
      "            -0.27067530, -0.32296288],\n",
      "           [ 1.57681954,  1.57681954,  1.57681954, ..., -0.27067530,\n",
      "            -0.28810447, -0.32296288],\n",
      "           ...,\n",
      "           [-1.19442248, -1.19442248, -1.19442248, ..., -0.96784306,\n",
      "            -0.96784306, -0.95041382],\n",
      "           [-1.22928095, -1.22928095, -1.22928095, ..., -0.96784306,\n",
      "            -0.95041382, -0.93298465],\n",
      "           [-1.22928095, -1.22928095, -1.22928095, ..., -0.96784306,\n",
      "            -0.95041382, -0.93298465]]],\n",
      "\n",
      "\n",
      "         [[[ 0.31381115,  0.31381115,  0.31381115, ...,  0.19393790,\n",
      "             0.15968838,  0.17681314],\n",
      "           [ 0.79330426,  0.79330426,  0.79330426, ..., -0.54242659,\n",
      "            -0.43967795, -0.16568191],\n",
      "           [ 1.52966881,  1.52966881,  1.54679358, ..., -1.75828421,\n",
      "            -1.58703661, -0.85067213],\n",
      "           ...,\n",
      "           [-0.93629593, -0.69654936, -0.52530187, ..., -0.08005815,\n",
      "            -0.02868389, -0.02868389],\n",
      "           [-0.62805039, -0.62805039, -0.66229987, ..., -0.23418093,\n",
      "            -0.23418093, -0.23418093],\n",
      "           [-0.59380084, -0.64517510, -0.67942464, ..., -0.31980470,\n",
      "            -0.35405418, -0.37117895]],\n",
      "\n",
      "          [[ 0.45028022,  0.45028022,  0.45028022, ...,  0.45028022,\n",
      "             0.43277320,  0.43277320],\n",
      "           [ 0.94047624,  0.94047624,  0.94047624, ..., -0.23249283,\n",
      "            -0.14495783,  0.13515419],\n",
      "           [ 1.67577052,  1.67577052,  1.69327760, ..., -1.44047606,\n",
      "            -1.26540601, -0.49509799],\n",
      "           ...,\n",
      "           [-0.63515401, -0.39005598, -0.21498583, ..., -0.17997183,\n",
      "            -0.10994382, -0.10994382],\n",
      "           [-0.37254897, -0.37254897, -0.42506999, ..., -0.00490182,\n",
      "            -0.00490182, -0.02240882],\n",
      "           [-0.40756297, -0.46008399, -0.49509799, ...,  0.10014019,\n",
      "             0.06512619,  0.03011219]],\n",
      "\n",
      "          [[ 0.53106773,  0.53106773,  0.53106773, ...,  0.86222237,\n",
      "             0.82736403,  0.84479320],\n",
      "           [ 1.03651428,  1.03651428,  1.03651428, ...,  0.19991305,\n",
      "             0.30448821,  0.58335531],\n",
      "           [ 1.80339909,  1.80339909,  1.82082832, ..., -0.95041382,\n",
      "            -0.75869268,  0.00819193],\n",
      "           ...,\n",
      "           [-1.36871445, -1.12470579, -0.96784306, ..., -1.08984745,\n",
      "            -1.02013063, -1.02013063],\n",
      "           [-1.15956414, -1.15956414, -1.22928095, ..., -1.28156853,\n",
      "            -1.28156853, -1.24671006],\n",
      "           [-1.22928095, -1.28156853, -1.31642687, ..., -1.38614368,\n",
      "            -1.40357304, -1.42100215]]],\n",
      "\n",
      "\n",
      "         [[[ 1.52966881,  0.58780718, -0.49105233, ...,  1.78654015,\n",
      "             0.41655967, -1.03904438],\n",
      "           [ 0.77617949, -0.21705617, -0.38830370, ...,  1.58104312,\n",
      "            -0.01155914, -0.64517510],\n",
      "           [ 0.62205672,  0.22818740,  0.17681314, ...,  1.54679358,\n",
      "             0.14256364, -0.01155914],\n",
      "           ...,\n",
      "           [-1.14179289, -1.10754347, -0.90204638, ..., -0.90204638,\n",
      "            -0.55955136,  0.09118938],\n",
      "           [-1.14179289, -1.12466824, -0.98767018, ..., -1.27879095,\n",
      "            -1.21029198, -0.78217316],\n",
      "           [-1.12466824, -1.14179289, -1.05616915, ..., -0.81642264,\n",
      "            -0.91917115,  0.50218344]],\n",
      "\n",
      "          [[ 1.65826356,  0.67787123, -0.40756297, ...,  1.95588255,\n",
      "             0.55532223, -0.93277299],\n",
      "           [ 0.88795525, -0.14495783, -0.32002783, ...,  1.74579859,\n",
      "             0.11764719, -0.54761899],\n",
      "           [ 0.71288526,  0.32773119,  0.27521020, ...,  1.71078455,\n",
      "             0.25770321,  0.11764719],\n",
      "           ...,\n",
      "           [-0.81022400, -0.77521002, -0.56512600, ..., -1.00280106,\n",
      "            -0.42506999,  0.24019620],\n",
      "           [-0.81022400, -0.79271698, -0.65266097, ..., -1.21288502,\n",
      "            -1.00280106, -0.63515401],\n",
      "           [-0.82773101, -0.84523803, -0.72268897, ..., -0.70518202,\n",
      "            -0.75770301,  0.67787123]],\n",
      "\n",
      "          [[ 1.89054513,  0.91451001, -0.18352933, ...,  2.16941214,\n",
      "             0.80993479, -0.67154676],\n",
      "           [ 1.12366033,  0.09533790, -0.07895403, ...,  1.97769105,\n",
      "             0.37420499, -0.27067530],\n",
      "           [ 0.94936836,  0.54849690,  0.51363856, ...,  1.94283271,\n",
      "             0.53106773,  0.37420499],\n",
      "           ...,\n",
      "           [-1.49071896, -1.45586061, -1.26413929, ..., -1.15956414,\n",
      "            -0.63668835,  0.14762548],\n",
      "           [-1.49071896, -1.49071896, -1.35128534, ..., -1.36871445,\n",
      "            -1.21185172, -0.72383434],\n",
      "           [-1.49071896, -1.52557731, -1.42100215, ..., -0.81098026,\n",
      "            -0.88069707,  0.61821371]]],\n",
      "\n",
      "\n",
      "         [[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]]]]]), [\"Peru's embattled president announces plans to dissolve Congress and rewrite the constitution,\", 'Goodnight ', 'New Details and Analysis of the Tax Cuts and Jobs Act', '太心酸了一车500后的白菜才卖30块钱近日河南商丘因白菜滞销大爷一车500斤白菜才卖30元妻子知道后责怪大爷卖便宜了大爷崩溃大喊我不想多卖点钱'], Tensor(shape=[4, 3, 224, 224], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[[[-0.19993141, -0.19993141, -0.21705617, ..., -1.00479496,\n",
      "           -1.02191973, -1.02191973],\n",
      "          [-0.25130567, -0.25130567, -0.25130567, ..., -1.02191973,\n",
      "           -1.02191973, -1.03904438],\n",
      "          [-0.26843041, -0.25130567, -0.25130567, ..., -1.00479496,\n",
      "           -1.00479496, -1.02191973],\n",
      "          ...,\n",
      "          [-1.77540886, -1.77540886, -1.77540886, ..., -1.75828421,\n",
      "           -1.75828421, -1.74115944],\n",
      "          [-1.77540886, -1.77540886, -1.77540886, ..., -1.75828421,\n",
      "           -1.75828421, -1.75828421],\n",
      "          [-1.75828421, -1.75828421, -1.75828421, ..., -1.77540886,\n",
      "           -1.77540886, -1.77540886]],\n",
      "\n",
      "         [[-0.24999984, -0.26750684, -0.24999984, ..., -0.72268897,\n",
      "           -0.74019599, -0.74019599],\n",
      "          [-0.28501382, -0.28501382, -0.28501382, ..., -0.74019599,\n",
      "           -0.74019599, -0.75770301],\n",
      "          [-0.30252084, -0.28501382, -0.28501382, ..., -0.75770301,\n",
      "           -0.75770301, -0.77521002],\n",
      "          ...,\n",
      "          [-1.58053207, -1.58053207, -1.59803903, ..., -1.51050401,\n",
      "           -1.51050401, -1.51050401],\n",
      "          [-1.58053207, -1.58053207, -1.59803903, ..., -1.52801108,\n",
      "           -1.52801108, -1.52801108],\n",
      "          [-1.56302512, -1.56302512, -1.58053207, ..., -1.54551804,\n",
      "           -1.54551804, -1.54551804]],\n",
      "\n",
      "         [[-0.16610013, -0.14867094, -0.14867094, ..., -0.46239641,\n",
      "           -0.47982562, -0.47982562],\n",
      "          [-0.20095852, -0.18352933, -0.18352933, ..., -0.47982562,\n",
      "           -0.47982562, -0.49725482],\n",
      "          [-0.21838771, -0.18352933, -0.18352933, ..., -0.47982562,\n",
      "           -0.47982562, -0.49725482],\n",
      "          ...,\n",
      "          [-1.35128534, -1.35128534, -1.31642687, ..., -1.24671006,\n",
      "           -1.24671006, -1.22928095],\n",
      "          [-1.35128534, -1.35128534, -1.31642687, ..., -1.24671006,\n",
      "           -1.24671006, -1.24671006],\n",
      "          [-1.33385611, -1.33385611, -1.29899776, ..., -1.26413929,\n",
      "           -1.26413929, -1.26413929]]],\n",
      "\n",
      "\n",
      "        [[[-1.27879095, -1.43291390, -1.43291390, ..., -1.51853764,\n",
      "           -1.60416138, -1.65553570],\n",
      "          [-1.36441481, -1.56991184, -1.58703661, ..., -1.55278718,\n",
      "           -1.60416138, -1.67266035],\n",
      "          [-1.41578913, -1.46716332, -1.51853764, ..., -1.48428810,\n",
      "           -1.55278718, -1.63841093],\n",
      "          ...,\n",
      "          [ 0.69055575,  0.94742703,  0.96455175, ..., -0.81642264,\n",
      "           -0.85067213, -0.88492167],\n",
      "          [ 0.67343098,  0.94742703,  1.01592600, ..., -0.83354741,\n",
      "           -0.88492167, -0.90204638],\n",
      "          [ 0.60493195,  0.84467852,  0.94742703, ..., -0.85067213,\n",
      "           -0.90204638, -0.97054541]],\n",
      "\n",
      "         [[-1.19537807, -1.35294104, -1.31792700, ..., -1.44047606,\n",
      "           -1.49299705, -1.54551804],\n",
      "          [-1.28291309, -1.49299705, -1.47549009, ..., -1.45798302,\n",
      "           -1.49299705, -1.51050401],\n",
      "          [-1.33543408, -1.38795507, -1.40546203, ..., -1.38795507,\n",
      "           -1.44047606, -1.51050401],\n",
      "          ...,\n",
      "          [ 0.73039222,  0.99299723,  1.01050425, ..., -0.89775902,\n",
      "           -0.93277299, -0.96778703],\n",
      "          [ 0.71288526,  0.99299723,  1.06302524, ..., -0.91526604,\n",
      "           -0.96778703, -0.98529404],\n",
      "          [ 0.60784322,  0.85294122,  0.97549027, ..., -0.93277299,\n",
      "           -0.98529404, -1.02030802]],\n",
      "\n",
      "         [[-0.91555548, -1.05498910, -1.02013063, ..., -1.12470579,\n",
      "           -1.17699337, -1.26413929],\n",
      "          [-1.00270152, -1.17699337, -1.15956414, ..., -1.15956414,\n",
      "           -1.17699337, -1.22928095],\n",
      "          [-1.02013063, -1.05498910, -1.08984745, ..., -1.12470579,\n",
      "           -1.17699337, -1.22928095],\n",
      "          ...,\n",
      "          [ 0.74021804,  1.00165594,  1.01908517, ..., -0.98527229,\n",
      "           -1.02013063, -1.05498910],\n",
      "          [ 0.72278887,  1.00165594,  1.07137275, ..., -1.00270152,\n",
      "           -1.05498910, -1.07241821],\n",
      "          [ 0.63564289,  0.87965161,  0.98422676, ..., -1.02013063,\n",
      "           -1.05498910, -1.08984745]]],\n",
      "\n",
      "\n",
      "        [[[ 2.23178363,  2.24890828,  2.21465898, ...,  2.19753432,\n",
      "            1.99203718,  1.23854804],\n",
      "          [ 2.18040943,  2.23178363,  2.07766104, ...,  1.90641344,\n",
      "            1.58104312,  1.01592600],\n",
      "          [ 1.97491241,  2.12903523,  1.47829461, ...,  0.94742703,\n",
      "           -0.14855716, -0.47392747],\n",
      "          ...,\n",
      "          [ 0.63918144,  1.44404507,  2.07766104, ...,  2.23178363,\n",
      "            2.23178363,  2.23178363],\n",
      "          [ 0.63918144,  1.37554610,  2.04341149, ...,  2.23178363,\n",
      "            2.23178363,  2.23178363],\n",
      "          [ 0.45080918,  1.39267087,  2.09478569, ...,  2.23178363,\n",
      "            2.23178363,  2.23178363]],\n",
      "\n",
      "         [[ 2.41106486,  2.42857146,  2.39355755, ...,  2.35854340,\n",
      "            2.16596651,  1.39565849],\n",
      "          [ 2.35854340,  2.41106486,  2.25350142, ...,  2.06092453,\n",
      "            1.74579859,  1.16806722],\n",
      "          [ 2.13095260,  2.30602264,  1.64075661, ...,  1.06302524,\n",
      "           -0.02240882, -0.35504183],\n",
      "          ...,\n",
      "          [ 0.85294122,  1.67577052,  2.32352948, ...,  2.41106486,\n",
      "            2.41106486,  2.41106486],\n",
      "          [ 0.85294122,  1.62324953,  2.28851557, ...,  2.41106486,\n",
      "            2.41106486,  2.41106486],\n",
      "          [ 0.66036421,  1.62324953,  2.35854340, ...,  2.41106486,\n",
      "            2.41106486,  2.41106486]],\n",
      "\n",
      "         [[ 2.60514212,  2.55285430,  2.43085027, ...,  2.53542542,\n",
      "            2.36113334,  1.61167800],\n",
      "          [ 2.57028365,  2.53542542,  2.30884552, ...,  2.23912883,\n",
      "            1.94283271,  1.38509822],\n",
      "          [ 2.34370399,  2.41342068,  1.68139470, ...,  1.24566460,\n",
      "            0.18248387, -0.13124162],\n",
      "          ...,\n",
      "          [ 1.12366033,  1.94283271,  2.58771276, ...,  2.62257099,\n",
      "            2.62257099,  2.62257099],\n",
      "          [ 1.12366033,  1.89054513,  2.53542542, ...,  2.62257099,\n",
      "            2.62257099,  2.62257099],\n",
      "          [ 0.93193918,  1.90797424,  2.60514212, ...,  2.62257099,\n",
      "            2.62257099,  2.62257099]]],\n",
      "\n",
      "\n",
      "        [[[ 1.94066298,  1.20429862,  1.82078969, ...,  2.19753432,\n",
      "            2.23178363,  1.37554610],\n",
      "          [ 1.34129655,  1.28992236,  2.11191034, ...,  2.02628660,\n",
      "            2.21465898,  1.32417178],\n",
      "          [ 0.98167652,  1.90641344,  2.18040943, ...,  1.94066298,\n",
      "            2.19753432,  1.39267087],\n",
      "          ...,\n",
      "          [ 1.22142327,  0.67343098,  0.31381115, ..., -0.73079890,\n",
      "           -0.79929787, -0.85067213],\n",
      "          [ 1.22142327,  0.65630621,  0.21106265, ..., -0.61092561,\n",
      "           -0.76504838, -0.83354741],\n",
      "          [ 1.22142327,  0.60493195,  0.10831413, ..., -0.18280666,\n",
      "           -0.67942464, -0.78217316]],\n",
      "\n",
      "         [[ 1.06302524, -0.65266097,  0.80042022, ...,  2.07843161,\n",
      "            2.16596651,  0.66036421],\n",
      "          [-0.02240882, -0.17997183,  1.78081262, ...,  1.85084057,\n",
      "            2.18347359,  0.67787123],\n",
      "          [-0.63515401,  1.04551828,  2.21848750, ...,  1.79831958,\n",
      "            2.20098066,  0.62535024],\n",
      "          ...,\n",
      "          [ 0.27521020, -0.26750684, -0.63515401, ..., -0.74019599,\n",
      "           -0.79271698, -0.82773101],\n",
      "          [ 0.27521020, -0.30252084, -0.72268897, ..., -0.67016798,\n",
      "           -0.81022400, -0.82773101],\n",
      "          [ 0.25770321, -0.37254897, -0.84523803, ..., -0.28501382,\n",
      "           -0.75770301, -0.81022400]],\n",
      "\n",
      "         [[ 0.89708078, -0.23581691,  1.33281064, ...,  2.37856245,\n",
      "            2.44827914,  1.07137275],\n",
      "          [-0.14867094,  0.06047951,  2.16941214, ...,  2.16941214,\n",
      "            2.46570849,  1.07137275],\n",
      "          [-0.68897593,  1.14108944,  2.48313761, ...,  2.08226609,\n",
      "            2.50056696,  1.07137275],\n",
      "          ...,\n",
      "          [-0.42753804, -0.96784306, -1.33385611, ..., -1.59529412,\n",
      "           -1.69986928, -1.76958609],\n",
      "          [-0.37525046, -0.96784306, -1.40357304, ..., -1.52557731,\n",
      "           -1.68244004, -1.75215685],\n",
      "          [-0.32296288, -0.96784306, -1.43843138, ..., -1.22928095,\n",
      "           -1.68244004, -1.78701520]]]])]\n"
     ]
    }
   ],
   "source": [
    "# 打印数据\n",
    "for step, batch in enumerate(train_dataloader, start=1):\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四、模型构建\n",
    "**本次赛题为一个NLP与多模态的分类赛题，整体建模采用特征提取、特征交互、预测分类三个阶段**\n",
    "\n",
    "**特征提取：** 对于图像数据，使用ResNet模型进行特征提取、对于文本数据，使用预训练模型Ernie-m多语言模型对中文和英文同时处理，qCap,qImg,（需要验证的标题或图像材料）、caps,imgs（支持验证的文本、图像证据材料）\n",
    "\n",
    "**特征交互**：使用多头自注意力机制，将标题与文本证据材料交互、图像与图像证据材料交互，输出与需要验证的标题和图像的相关证据特征caps_feature、imgs_features\n",
    "\n",
    "**预测分类：** 最后使用全连接层将标题特征、图像特征、相关的文本证据特征、相关的图像证据特征拼接输入到分类器得到最终结果\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/3f29e3f853b9445fbeb24189103cdbbcb8364498dc484593a891839994dadbd6)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多语言预训练模型ERNIE-M\n",
    "2021年，百度发布多语言预训练模型ERNIE-M。ERNIE-M通过对96门语言的学习，使得一个模型能同时理解96种语言，该项技术在5类典型跨语言理解任务上刷新世界最好效果。\n",
    "\n",
    "## ERNIE-M原理\n",
    "ERNIE-M基于飞桨PaddlePaddle框架训练，该模型构建了大小为25万的多语言词表，涵盖了96种语言的大多数常见词汇，训练语料包含了汉语、英语、法语、南非语、阿尔巴尼亚语、阿姆哈拉语、梵语、阿拉伯语、亚美尼亚语、阿萨姆语、阿塞拜疆语等96种语言，约1.5万亿字符。\n",
    "\n",
    "ERNIE-M的学习过程由两阶段组成。第一阶段从少量的双语语料中学习跨语言理解能力，使模型学到初步的语言对齐关系；第二阶段使用回译的思想，通过大量的单语语料学习，增强模型的跨语言理解能力。\n",
    "\n",
    "[百度NLP知乎介绍](https://zhuanlan.zhihu.com/p/344810337)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:10:37.880597Z",
     "iopub.status.busy": "2023-07-26T11:10:37.880109Z",
     "iopub.status.idle": "2023-07-26T11:10:38.802885Z",
     "shell.execute_reply": "2023-07-26T11:10:38.801219Z",
     "shell.execute_reply.started": "2023-07-26T11:10:37.880565Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from paddle.vision import models\n",
    "import paddle\n",
    "from paddlenlp.transformers import ErnieMModel,ErnieMTokenizer\n",
    "from paddle.nn import functional as F\n",
    "from paddle import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "class EncoderCNN(nn.Layer):\n",
    "    def __init__(self, resnet_arch = 'resnet101'):\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        if resnet_arch == 'resnet101':\n",
    "            resnet = models.resnet101(pretrained=True)\n",
    "        modules = list(resnet.children())[:-2]\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2D((1, 1))\n",
    "    def forward(self, images, features='pool'):\n",
    "        out = self.resnet(images)\n",
    "        if features == 'pool':\n",
    "            out = self.adaptive_pool(out)\n",
    "            out = paddle.reshape(out, (out.shape[0],out.shape[1]))\n",
    "        return out\n",
    "\n",
    "class NetWork(nn.Layer):\n",
    "    def __init__(self, mode):\n",
    "        super(NetWork, self).__init__()\n",
    "        self.mode = mode           \n",
    "        self.ernie = ErnieMModel.from_pretrained('ernie-m-base')\n",
    "        self.tokenizer = ErnieMTokenizer.from_pretrained('ernie-m-base')\n",
    "        self.resnet = EncoderCNN()\n",
    "        self.classifier1 = nn.Linear(2*(768+2048),1024)\n",
    "        self.classifier2 = nn.Linear(1024,3)\n",
    "        self.attention_text = nn.MultiHeadAttention(768,16)\n",
    "        self.attention_image = nn.MultiHeadAttention(2048,16)\n",
    "        if self.mode == 'text':\n",
    "            self.classifier = nn.Linear(768,3)\n",
    "        self.resnet.eval()\n",
    "\n",
    "    def forward(self,qCap,qImg,caps,imgs):\n",
    "        self.resnet.eval()\n",
    "        encode_dict_qcap = self.tokenizer(text = qCap ,max_length = 128 ,truncation=True, padding='max_length')\n",
    "        input_ids_qcap = encode_dict_qcap['input_ids']\n",
    "        input_ids_qcap = paddle.to_tensor(input_ids_qcap)\n",
    "        qcap_feature, pooled_output= self.ernie(input_ids_qcap) #(b,length,dim)\n",
    "        if self.mode == 'text':\n",
    "            logits = self.classifier(qcap_feature[:,0,:].squeeze(1))\n",
    "            return logits\n",
    "        caps_feature = []\n",
    "        for i,caption in enumerate (caps):\n",
    "            encode_dict_cap = self.tokenizer(text = caption ,max_length = 128 ,truncation=True, padding='max_length')\n",
    "            input_ids_caps = encode_dict_cap['input_ids']\n",
    "            input_ids_caps = paddle.to_tensor(input_ids_caps)\n",
    "            cap_feature, pooled_output= self.ernie(input_ids_caps) #(b,length,dim)\n",
    "            caps_feature.append(cap_feature)\n",
    "        caps_feature = paddle.stack(caps_feature,axis=0) #(b,num,length,dim)\n",
    "        caps_feature = caps_feature.mean(axis=1)#(b,length,dim)\n",
    "        caps_feature = self.attention_text(qcap_feature,caps_feature,caps_feature) #(b,length,dim)\n",
    "        imgs_features = []\n",
    "        for img in imgs:\n",
    "            imgs_feature = self.resnet(img) #(length,dim)\n",
    "            imgs_features.append(imgs_feature)\n",
    "        imgs_features = paddle.stack(imgs_features,axis=0) #(b,length,dim)\n",
    "        qImg_features = []\n",
    "        for qImage in qImg:\n",
    "            qImg_feature = self.resnet(qImage.unsqueeze(axis=0)) #(1,dim)\n",
    "            qImg_features.append(qImg_feature)\n",
    "        qImg_feature = paddle.stack(qImg_features,axis=0) #(b,1,dim)\n",
    "        imgs_features = self.attention_image(qImg_feature,imgs_features,imgs_features) #(b,1,dim)\n",
    "        # [1, 128, 768] [1, 128, 768] [1, 1, 2048] [1, 1, 2048] origin\n",
    "        # print(qcap_feature.shape,caps_feature.shape,qImg_feature.shape,imgs_features.shape)\n",
    "        # print((qcap_feature[:,0,:].shape,caps_feature[:,0,:].shape,qImg_feature.squeeze(1).shape,imgs_features.squeeze(1).shape))\n",
    "        # ([1,768], [1 , 768], [1, 2048], [1,  2048])\n",
    "        feature = paddle.concat(x=[qcap_feature[:,0,:], caps_feature[:,0,:], qImg_feature.squeeze(1), imgs_features.squeeze(1)], axis=-1) \n",
    "        logits = self.classifier1(feature)\n",
    "        logits = self.classifier2(logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:10:38.805643Z",
     "iopub.status.busy": "2023-07-26T11:10:38.804526Z",
     "iopub.status.idle": "2023-07-26T11:11:44.041344Z",
     "shell.execute_reply": "2023-07-26T11:11:44.040328Z",
     "shell.execute_reply.started": "2023-07-26T11:10:38.805603Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-07-26 21:34:20,784] [    INFO]\u001b[0m - Model config ErnieMConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"ernie_m\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"paddlenlp_version\": null,\n",
      "  \"type_vocab_size\": 16,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\u001b[0m\n",
      "\u001b[33m[2023-07-26 21:34:22,472] [ WARNING]\u001b[0m - Some weights of the model checkpoint at ernie-m-base were not used when initializing ErnieMModel: ['cls.predictions.layer_norm.bias', 'cls.predictions.transform.bias', 'cls.predictions.transform.weight', 'cls.predictions.decoder_bias', 'cls.predictions.layer_norm.weight']\n",
      "- This IS expected if you are initializing ErnieMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ErnieMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[33m[2023-07-26 21:34:22,473] [ WARNING]\u001b[0m - Some weights of ErnieMModel were not initialized from the model checkpoint at ernie-m-base and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[32m[2023-07-26 21:34:22,473] [    INFO]\u001b[0m - Already cached C:\\Users\\lins\\.paddlenlp\\models\\ernie-m-base\\ernie_m.vocab.txt\u001b[0m\n",
      "\u001b[32m[2023-07-26 21:34:22,474] [    INFO]\u001b[0m - Already cached C:\\Users\\lins\\.paddlenlp\\models\\ernie-m-base\\ernie_m.sentencepiece.bpe.model\u001b[0m\n",
      "\u001b[32m[2023-07-26 21:34:23,073] [    INFO]\u001b[0m - tokenizer config file saved in C:\\Users\\lins\\.paddlenlp\\models\\ernie-m-base\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-07-26 21:34:23,074] [    INFO]\u001b[0m - Special tokens file saved in C:\\Users\\lins\\.paddlenlp\\models\\ernie-m-base\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetWork(\n",
      "  (ernie): ErnieMModel(\n",
      "    (embeddings): ErnieMEmbeddings(\n",
      "      (word_embeddings): Embedding(250002, 768, sparse=False)\n",
      "      (position_embeddings): Embedding(514, 768, sparse=False)\n",
      "      (layer_norm): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "      (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "    )\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): LayerList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (6): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (7): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (8): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (9): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (10): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (11): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): ErnieMPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (resnet): EncoderCNN(\n",
      "    (resnet): Sequential(\n",
      "      (0): Conv2D(3, 64, kernel_size=[7, 7], stride=[2, 2], padding=3, data_format=NCHW)\n",
      "      (1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool2D(kernel_size=3, stride=2, padding=1)\n",
      "      (4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (conv1): Conv2D(64, 64, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2D(256, 64, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2D(256, 64, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (conv1): Conv2D(256, 128, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(128, 128, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2D(256, 512, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)\n",
      "            (1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (conv1): Conv2D(512, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2D(512, 1024, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)\n",
      "            (1): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (7): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 512, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(512, 512, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2D(1024, 2048, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)\n",
      "            (1): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2D(2048, 512, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2D(2048, 512, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (adaptive_pool): AdaptiveAvgPool2D(output_size=(1, 1))\n",
      "  )\n",
      "  (classifier1): Linear(in_features=5632, out_features=1024, dtype=float32)\n",
      "  (classifier2): Linear(in_features=1024, out_features=3, dtype=float32)\n",
      "  (attention_text): MultiHeadAttention(\n",
      "    (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "    (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "  )\n",
      "  (attention_image): MultiHeadAttention(\n",
      "    (q_proj): Linear(in_features=2048, out_features=2048, dtype=float32)\n",
      "    (k_proj): Linear(in_features=2048, out_features=2048, dtype=float32)\n",
      "    (v_proj): Linear(in_features=2048, out_features=2048, dtype=float32)\n",
      "    (out_proj): Linear(in_features=2048, out_features=2048, dtype=float32)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 声明模型\n",
    "model = NetWork(\"image\")\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 六、训练配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:11:44.043510Z",
     "iopub.status.busy": "2023-07-26T11:11:44.042884Z",
     "iopub.status.idle": "2023-07-26T11:11:44.089142Z",
     "shell.execute_reply": "2023-07-26T11:11:44.088273Z",
     "shell.execute_reply.started": "2023-07-26T11:11:44.043472Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5592 559\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "num_training_steps = len(train_dataloader) * epochs\n",
    "warmup_steps = int(num_training_steps*0.1)\n",
    "print(num_training_steps,warmup_steps)\n",
    "# 定义 learning_rate_scheduler，负责在训练过程中对 lr 进行调度\n",
    "lr_scheduler = LinearDecayWithWarmup(1e-6, num_training_steps, warmup_steps)\n",
    "# 训练结束后，存储模型参数\n",
    "save_dir =\"checkpoint/\"\n",
    "best_dir = \"best_model\"\n",
    "# 创建保存的文件夹\n",
    "os.makedirs(save_dir,exist_ok=True)\n",
    "os.makedirs(best_dir,exist_ok=True)\n",
    "\n",
    "decay_params = [\n",
    "    p.name for n, p in model.named_parameters()\n",
    "    if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "]\n",
    "\n",
    "# 定义 Optimizer\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "    learning_rate=lr_scheduler,\n",
    "    parameters=model.parameters(),\n",
    "    weight_decay=1.2e-4,\n",
    "    apply_decay_param_fun=lambda x: x in decay_params)\n",
    "\n",
    "# 交叉熵损失\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "\n",
    "# 评估的时候采用准确率指标\n",
    "metric = paddle.metric.Accuracy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 七、模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:11:44.090806Z",
     "iopub.status.busy": "2023-07-26T11:11:44.090378Z",
     "iopub.status.idle": "2023-07-26T11:11:44.103547Z",
     "shell.execute_reply": "2023-07-26T11:11:44.102756Z",
     "shell.execute_reply.started": "2023-07-26T11:11:44.090776Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 定义线下评估 评价指标为acc 线上评估是f1score\n",
    "@paddle.no_grad()\n",
    "def evaluate(model, criterion, metric, data_loader):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    losses = []\n",
    "    for batch in data_loader:      \n",
    "        labels, cap_batch, img_batch, qCap_batch, qImg_batch = batch\n",
    "        logits = model(qCap=qCap_batch,qImg=qImg_batch,caps=cap_batch,imgs=img_batch)\n",
    "        loss = criterion(logits, labels)\n",
    "        losses.append(loss.numpy())\n",
    "        correct = metric.compute(logits, labels)\n",
    "        metric.update(correct)\n",
    "        accu = metric.accumulate()\n",
    "    print(\"eval loss: %.5f, accu: %.5f\" % (np.mean(losses), accu))\n",
    "    model.train()\n",
    "    metric.reset()\n",
    "    return np.mean(losses), accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:11:44.107830Z",
     "iopub.status.busy": "2023-07-26T11:11:44.107431Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train run start\n",
      "global step 1, epoch: 1, batch: 1, loss: 1.42092, accu: 0.25000, speed: 1.11 step/s\n",
      "global step 2, epoch: 1, batch: 2, loss: 1.62623, accu: 0.25000, speed: 0.87 step/s\n",
      "global step 3, epoch: 1, batch: 3, loss: 1.46933, accu: 0.16667, speed: 0.66 step/s\n",
      "global step 4, epoch: 1, batch: 4, loss: 1.02845, accu: 0.25000, speed: 0.75 step/s\n",
      "global step 5, epoch: 1, batch: 5, loss: 1.09967, accu: 0.25000, speed: 0.67 step/s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14432\\744471085.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m                     \u001b[0msave_param_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model_best.pdparams'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                     \u001b[0mpaddle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_param_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mdo_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14432\\744471085.py\u001b[0m in \u001b[0;36mdo_train\u001b[1;34m(model, criterion, metric, val_dataloader, train_dataloader)\u001b[0m\n\u001b[0;32m     22\u001b[0m                         10 / (time.time() - tic_train)))\n\u001b[0;32m     23\u001b[0m                 \u001b[0mtic_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mlr_scheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\decorator.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\wrapped_decorator.py\u001b[0m in \u001b[0;36m__impl__\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mwrapped_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecorator_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\framework.py\u001b[0m in \u001b[0;36m__impl__\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         )\n\u001b[1;32m--> 449\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\dygraph\\tensor_patch_methods.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, grad_tensor, retain_graph)\u001b[0m\n\u001b[0;32m    296\u001b[0m                 \u001b[0mself\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_grad_scalar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m             \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0min_profiler_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 定义训练\n",
    "def do_train(model, criterion, metric, val_dataloader,train_dataloader):\n",
    "    print(\"train run start\")\n",
    "    global_step = 0\n",
    "    tic_train = time.time()\n",
    "    best_accuracy=0.0\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for step, batch in enumerate(train_dataloader, start=1):\n",
    "            labels, cap_batch, img_batch, qCap_batch, qImg_batch = batch\n",
    "            probs = model(qCap=qCap_batch,qImg=qImg_batch,caps=cap_batch,imgs=img_batch)\n",
    "            loss = criterion(probs, labels)\n",
    "            correct = metric.compute(probs, labels)\n",
    "            metric.update(correct)\n",
    "            acc = metric.accumulate()\n",
    "\n",
    "            global_step += 1 \n",
    "            # 每间隔 100 step 输出训练指标\n",
    "            if global_step % 1 == 0:\n",
    "                print(\n",
    "                    \"global step %d, epoch: %d, batch: %d, loss: %.5f, accu: %.5f, speed: %.2f step/s\"\n",
    "                    % (global_step, epoch, step, loss, acc,\n",
    "                        10 / (time.time() - tic_train)))\n",
    "                tic_train = time.time()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.clear_grad()\n",
    "\n",
    "            # 每间隔一个epoch 在验证集进行评估\n",
    "            if global_step % len(train_dataloader) == 0:\n",
    "                eval_loss,eval_accu=evaluate(model, criterion, metric, val_dataloader)\n",
    "                save_param_path = os.path.join(save_dir+str(epoch), 'model_state.pdparams')\n",
    "                paddle.save(model.state_dict(), save_param_path)\n",
    "                if(best_accuracy<eval_accu):\n",
    "                    best_accuracy=eval_accu\n",
    "                    # 保存模型\n",
    "                    save_param_path = os.path.join(best_dir, 'model_best.pdparams')\n",
    "                    paddle.save(model.state_dict(), save_param_path)\n",
    "do_train(model, criterion, metric, val_dataloader,train_dataloader) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 八、模型预测\n",
    "**模型预测前，请重启内核，清空占用的显存**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 根据实际运行情况，更换加载的参数路径\n",
    "import os\n",
    "import paddle\n",
    "\n",
    "params_path = 'checkpoint/model_best.pdparams'\n",
    "if params_path and os.path.isfile(params_path):\n",
    "    # 加载模型参数\n",
    "    state_dict = paddle.load(params_path)\n",
    "    model.set_dict(state_dict)\n",
    "    print(\"Loaded parameters from %s\" % params_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14432\\611238623.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mcount\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcap_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqCap_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqImg_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqCap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mqCap_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mqImg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mqImg_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcaps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcap_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;31m# 预测分类\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\layers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1252\u001b[0m         ):\n\u001b[0;32m   1253\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dygraph_call_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14432\\3173593307.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, qCap, qImg, caps, imgs)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mqImg_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mqImage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mqImg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m             \u001b[0mqImg_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#(1,dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m             \u001b[0mqImg_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqImg_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mqImg_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqImg_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#(b,1,dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\layers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1252\u001b[0m         ):\n\u001b[0;32m   1253\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dygraph_call_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14432\\3173593307.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, images, features)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madaptive_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdaptiveAvgPool2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pool'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'pool'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madaptive_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\layers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1252\u001b[0m         ):\n\u001b[0;32m   1253\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dygraph_call_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sub_layers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    607\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\layers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1252\u001b[0m         ):\n\u001b[0;32m   1253\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dygraph_call_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sub_layers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    607\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\layers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1252\u001b[0m         ):\n\u001b[0;32m   1253\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dygraph_call_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\vision\\models\\resnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\layers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1252\u001b[0m         ):\n\u001b[0;32m   1253\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dygraph_call_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\norm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_epsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m             \u001b[0muse_global_stats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_use_global_stats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    792\u001b[0m         )\n\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\functional\\norm.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(x, running_mean, running_var, weight, bias, training, momentum, epsilon, data_format, use_global_stats, name)\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0muse_global_stats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m             \u001b[0mtrainable_statistics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbatch_norm_out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "# 切换model模型为评估模式，关闭dropout等随机因素\n",
    "model.eval()\n",
    "count=0\n",
    "for batch in test_dataloader:\n",
    "    count+=1\n",
    "    cap_batch, img_batch, qCap_batch, qImg_batch = batch\n",
    "    logits = model(qCap=qCap_batch,qImg=qImg_batch,caps=cap_batch,imgs=img_batch)\n",
    "    # 预测分类\n",
    "    probs = F.softmax(logits, axis=-1)\n",
    "    label = paddle.argmax(probs, axis=1).numpy()\n",
    "    results += label.tolist()\n",
    "    print(count)\n",
    "print(results[:5])\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 50)\n"
     ]
    }
   ],
   "source": [
    "# 输出结果\n",
    "import pandas as pd\n",
    "#id/label\n",
    "#字典中的key值即为csv中的列名\n",
    "id_list=range(len(results))\n",
    "print(id_list)\n",
    "frame = pd.DataFrame({'id':id_list,'label':results})\n",
    "frame.to_csv(\"result.csv\",index=False,sep=',')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 九、后续优化\n",
    "\n",
    "baseline分数只有65分，还有很大的改进地方，大家多多尝试，下面是一些想法\n",
    "\n",
    "参数调优：学习率、优化器以及其他超参数等\n",
    "\n",
    "特征提取：更换预训练权重更大的图像特征提取器or文本特征提取器（Ernie or Bert系列）\n",
    "\n",
    "特征交互：目前使用多头自注意力机制对文本与文本证据交互、图像与图像证据交互，可以尝试文本与图像之间的跨模态交互\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
