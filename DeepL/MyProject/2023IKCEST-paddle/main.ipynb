{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2023IKCEST第五届“一带一路”国际大数据竞赛\n",
    "# 一、背景介绍\n",
    "\n",
    "本届大数据竞赛在中国工程院、教育部高等学校大学计算机课程教学指导委员会及丝绸之路大学联盟的指导下由联合国教科文组织国际工程科技知识中心（IKCEST）、中国工程科技知识中心（CKCEST）、百度公司及西安交通大学共同主办，旨在放眼“一带一路”倡议沿线国家，通过竞赛方式挖掘全球大数据人工智能尖端人才，实现政府—产业—高校合力推动大数据产业研究、应用、发展的目标，进一步夯实赛事的理论基础与实践基础，加快拔尖AI创新人才培养。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、赛题介绍\n",
    "随着新媒体时代信息媒介的多元化发展，各种内容大量活跃在媒体内中，与此同时各类虚假信息也充斥着社交媒体，影响着公众的判断和决策。如何在大量的文本、图像等多模态信息中，通过大数据与人工智能技术，纠正和消除虚假错误信息，对于网络舆情及社会治理有着重大意义。\n",
    "\n",
    "本次赛题要求选手基于官方指定数据集，通过建模同一事实跨模态数据之间的关系 （主要是文本和图像），实现对任一模态信息能够进行虚假和真实性的检测。鼓励参赛选手通过大模型解决问题，进行技术探索。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:10:32.137835Z",
     "iopub.status.busy": "2023-07-26T11:10:32.137090Z",
     "iopub.status.idle": "2023-07-26T11:10:35.711652Z",
     "shell.execute_reply": "2023-07-26T11:10:35.710258Z",
     "shell.execute_reply.started": "2023-07-26T11:10:32.137794Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: paddlenlp==2.5.2 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (2.5.2)\n",
      "Requirement already satisfied: seqeval in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (1.2.2)\n",
      "Requirement already satisfied: fastapi in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (0.100.0)\n",
      "Requirement already satisfied: colorama in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (0.4.6)\n",
      "Requirement already satisfied: colorlog in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (6.7.0)\n",
      "Requirement already satisfied: typer in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (0.9.0)\n",
      "Requirement already satisfied: visualdl in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (2.4.2)\n",
      "Requirement already satisfied: uvicorn in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (0.22.0)\n",
      "Requirement already satisfied: sentencepiece in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (0.1.99)\n",
      "Requirement already satisfied: dill<0.3.5 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (0.3.4)\n",
      "Requirement already satisfied: datasets>=2.0.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (2.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.11.1 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (0.16.4)\n",
      "Requirement already satisfied: multiprocess<=0.70.12.2 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (0.70.12.2)\n",
      "Requirement already satisfied: paddle2onnx in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (1.0.6)\n",
      "Requirement already satisfied: Flask-Babel<3.0.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (2.0.0)\n",
      "Requirement already satisfied: jieba in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (0.42.1)\n",
      "Requirement already satisfied: tqdm in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (4.65.0)\n",
      "Requirement already satisfied: paddlefsl in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (1.1.0)\n",
      "Requirement already satisfied: rich in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddlenlp==2.5.2) (13.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from datasets>=2.0.0->paddlenlp==2.5.2) (6.0.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from datasets>=2.0.0->paddlenlp==2.5.2) (12.0.1)\n",
      "Requirement already satisfied: pandas in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from datasets>=2.0.0->paddlenlp==2.5.2) (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from datasets>=2.0.0->paddlenlp==2.5.2) (1.21.6)\n",
      "Requirement already satisfied: packaging in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from datasets>=2.0.0->paddlenlp==2.5.2) (23.1)\n",
      "Requirement already satisfied: importlib-metadata in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from datasets>=2.0.0->paddlenlp==2.5.2) (6.7.0)\n",
      "Requirement already satisfied: aiohttp in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from datasets>=2.0.0->paddlenlp==2.5.2) (3.8.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from datasets>=2.0.0->paddlenlp==2.5.2) (2.31.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from datasets>=2.0.0->paddlenlp==2.5.2) (2023.1.0)\n",
      "Requirement already satisfied: xxhash in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from datasets>=2.0.0->paddlenlp==2.5.2) (3.2.0)\n",
      "Requirement already satisfied: Jinja2>=2.5 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from Flask-Babel<3.0.0->paddlenlp==2.5.2) (3.1.2)\n",
      "Requirement already satisfied: Babel>=2.3 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from Flask-Babel<3.0.0->paddlenlp==2.5.2) (2.12.1)\n",
      "Requirement already satisfied: pytz in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from Flask-Babel<3.0.0->paddlenlp==2.5.2) (2023.3)\n",
      "Requirement already satisfied: Flask in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from Flask-Babel<3.0.0->paddlenlp==2.5.2) (2.2.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from huggingface-hub>=0.11.1->paddlenlp==2.5.2) (4.7.1)\n",
      "Requirement already satisfied: filelock in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from huggingface-hub>=0.11.1->paddlenlp==2.5.2) (3.12.2)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from fastapi->paddlenlp==2.5.2) (0.27.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from fastapi->paddlenlp==2.5.2) (2.1.1)\n",
      "Requirement already satisfied: six in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from paddle2onnx->paddlenlp==2.5.2) (1.16.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from rich->paddlenlp==2.5.2) (2.15.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from rich->paddlenlp==2.5.2) (2.2.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from seqeval->paddlenlp==2.5.2) (1.0.2)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from typer->paddlenlp==2.5.2) (8.1.6)\n",
      "Requirement already satisfied: h11>=0.8 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from uvicorn->paddlenlp==2.5.2) (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.11.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from visualdl->paddlenlp==2.5.2) (3.20.0)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from visualdl->paddlenlp==2.5.2) (9.2.0)\n",
      "Requirement already satisfied: bce-python-sdk in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from visualdl->paddlenlp==2.5.2) (0.8.87)\n",
      "Requirement already satisfied: matplotlib in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from visualdl->paddlenlp==2.5.2) (3.5.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from Flask->Flask-Babel<3.0.0->paddlenlp==2.5.2) (2.1.2)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from Flask->Flask-Babel<3.0.0->paddlenlp==2.5.2) (2.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.5.2) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.5.2) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.5.2) (6.0.4)\n",
      "Requirement already satisfied: asynctest==0.13.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.5.2) (0.13.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.5.2) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.5.2) (1.9.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.5.2) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.5.2) (1.3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from importlib-metadata->datasets>=2.0.0->paddlenlp==2.5.2) (3.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from Jinja2>=2.5->Flask-Babel<3.0.0->paddlenlp==2.5.2) (2.1.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->paddlenlp==2.5.2) (0.1.2)\n",
      "Requirement already satisfied: pydantic-core==2.4.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->fastapi->paddlenlp==2.5.2) (2.4.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->fastapi->paddlenlp==2.5.2) (0.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp==2.5.2) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp==2.5.2) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp==2.5.2) (2.0.4)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp==2.5.2) (1.3.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp==2.5.2) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp==2.5.2) (3.1.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from starlette<0.28.0,>=0.27.0->fastapi->paddlenlp==2.5.2) (3.7.1)\n",
      "Requirement already satisfied: future>=0.6.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from bce-python-sdk->visualdl->paddlenlp==2.5.2) (0.18.3)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from bce-python-sdk->visualdl->paddlenlp==2.5.2) (3.18.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from matplotlib->visualdl->paddlenlp==2.5.2) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from matplotlib->visualdl->paddlenlp==2.5.2) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from matplotlib->visualdl->paddlenlp==2.5.2) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from matplotlib->visualdl->paddlenlp==2.5.2) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from matplotlib->visualdl->paddlenlp==2.5.2) (3.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi->paddlenlp==2.5.2) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in d:\\software\\codeapp\\anaconda\\envs\\paddle\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi->paddlenlp==2.5.2) (1.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "#环境安装\n",
    "!pip install paddlenlp==2.5.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、数据集介绍\n",
    "本次比赛提供从国内外主流社交媒体平台上爬取的含有不同领域声明的数据集。\n",
    "\n",
    "初赛：训练集与验证集： 提供中文训练集5694条以及英文数据4893条，同时公开英文验证集611条与中文验证集711条供选手优化模型。\n",
    "\n",
    "初赛评测数据： 提供文娱、经济、健康领域的测试数据，这些领域的数据较容易区分。英文与中文数据集的测试集各600条。参赛队伍上传的结果文本的每一行就是对应的分类结果，该数据不公布，用于评测。\n",
    "\n",
    "\n",
    "| 0 | 1 | 2 |\n",
    "| -------- | -------- | -------- |\n",
    "| non-rumor | rumor  | unverified |\n",
    "\n",
    "\n",
    "\n",
    "[复赛数据后续见官网通知](https://aistudio.baidu.com/aistudio/competition/detail/1030/0/task-definition)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四、数据预处理\n",
    "**数据集过大，右键选择解压/home/aistudio/data/data229919/data.zip数据集，耐心等待30分钟，直到出现以下文件夹和文件,解压之后硬盘达到约80g（压缩包27g、解压文件之后50g，可以将项目挂载的数据集取消，空余出27g）**\n",
    "* test\n",
    "* train\n",
    "* val\n",
    "* dataset_items_test.json\n",
    "* dataset_items_train.json\n",
    "* dataset_items_val.json\n",
    "\n",
    "此处将数据集已经放置在queries_dataset_merge文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-26T11:10:35.715139Z",
     "iopub.status.busy": "2023-07-26T11:10:35.714521Z",
     "iopub.status.idle": "2023-07-26T11:10:35.721636Z",
     "shell.execute_reply": "2023-07-26T11:10:35.720702Z",
     "shell.execute_reply.started": "2023-07-26T11:10:35.715100Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import time\n",
    "import os \n",
    "import copy\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm \n",
    "\n",
    "import paddle\n",
    "from paddlenlp.datasets import load_dataset\n",
    "import paddle.nn.functional as F\n",
    "import paddle.nn as nn\n",
    "import paddlenlp as ppnlp\n",
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:10:35.723060Z",
     "iopub.status.busy": "2023-07-26T11:10:35.722761Z",
     "iopub.status.idle": "2023-07-26T11:10:35.806019Z",
     "shell.execute_reply": "2023-07-26T11:10:35.804860Z",
     "shell.execute_reply.started": "2023-07-26T11:10:35.723034Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#读取数据\n",
    "import json\n",
    "data_items_train = json.load(open(\"E:/Document/CodeSpace/Data_set/Paddle2023IKCEST/queries_dataset_merge/dataset_items_train.json\"))\n",
    "data_items_val = json.load(open(\"E:/Document/CodeSpace/Data_set/Paddle2023IKCEST/queries_dataset_merge/dataset_items_val.json\"))\n",
    "data_items_test = json.load(open(\"E:/Document/CodeSpace/Data_set/Paddle2023IKCEST/queries_dataset_merge/dataset_items_test.json\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据中的每一个样本：图像img、文本caption、对应的img_html_news、inverse_search为支持图像img和文本caption的证据材料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:10:35.808211Z",
     "iopub.status.busy": "2023-07-26T11:10:35.807864Z",
     "iopub.status.idle": "2023-07-26T11:10:35.841452Z",
     "shell.execute_reply": "2023-07-26T11:10:35.840479Z",
     "shell.execute_reply.started": "2023-07-26T11:10:35.808180Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "读取数据中的每一个样本：图像img、文本caption、\n",
    "对应的img_html_news、inverse_search为支持图像img和文本caption的证据材料\n",
    "'''\n",
    "import paddle\n",
    "from paddle.vision import transforms as T\n",
    "from paddle.io import Dataset\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "from PIL import Image\n",
    "import os \n",
    "import imghdr\n",
    "\n",
    "def process_string(input_str):\n",
    "    input_str = input_str.replace('&#39;', ' ')\n",
    "    input_str = input_str.replace('<b>','')\n",
    "    input_str = input_str.replace('</b>','')\n",
    "    #input_str = unidecode(input_str)  \n",
    "    return input_str\n",
    "    \n",
    "class NewsContextDatasetEmbs(Dataset):\n",
    "    # 初始化方法\n",
    "    # 实例化对象的时候，会调用 __init__\n",
    "    # self类的方法中第一个形参，指代当前的实例\n",
    "    # 你实例化对象的时候，有对象的具体属性，但定义类的时候还没有，就用self来指代\n",
    "    # 类内部使用self获取属性值\n",
    "    def __init__(self, context_data_items_dict, queries_root_dir, split):\n",
    "        self.context_data_items_dict = context_data_items_dict\n",
    "        self.queries_root_dir = queries_root_dir\n",
    "        self.idx_to_keys = list(context_data_items_dict.keys())\n",
    "        self.transform =T.Compose([\n",
    "                        T.Resize(256),\n",
    "                        T.CenterCrop(224),\n",
    "                        T.ToTensor(),\n",
    "                        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                    ])\n",
    "        self.split=split\n",
    "    def __len__(self):\n",
    "        return len(self.context_data_items_dict)   \n",
    "\n",
    "    # 从给定路径加载图像，并进行转RGB格式处理\n",
    "    def load_img_pil(self,image_path):\n",
    "        # imghdr.what获取图片的类型\n",
    "        if imghdr.what(image_path) == 'gif': \n",
    "            try:\n",
    "                # 当时gif时，用image.open打开图像，因为他支持rgb、png、gif等。\n",
    "                # 这里gif可能需要特殊处理下吧,不成功则要返回none\n",
    "                with open(image_path, 'rb') as f:\n",
    "                    img = Image.open(f)\n",
    "                    return img.convert('RGB')\n",
    "            except:\n",
    "                return None \n",
    "        with open(image_path, 'rb') as f:\n",
    "            img = Image.open(f)\n",
    "            return img.convert('RGB')\n",
    "    # 加载文件夹中的图像，将其转换为张量\n",
    "    def load_imgs_direct_search(self,item_folder_path,\n",
    "                                direct_dict):   # 字典，包含了需要处理的图像数据的信息\n",
    "        list_imgs_tensors = [] # 空列表存储转换后的图像张量\n",
    "        count = 0   # 记录处理的图像数量\n",
    "        # 键列表\n",
    "        keys_to_check = ['images_with_captions','images_with_no_captions','images_with_caption_matched_tags']\n",
    "        for key1 in keys_to_check:\n",
    "            if key1 in direct_dict.keys():\n",
    "                # 遍历该key1，对应的图像页面列表。从中提取图像路径\n",
    "                for page in direct_dict[key1]:\n",
    "                    image_path = os.path.join(item_folder_path,page['image_path'].split('/')[-1])\n",
    "                    try:\n",
    "                        pil_img = self.load_img_pil(image_path)\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        print(image_path)\n",
    "                    if pil_img == None: continue\n",
    "                    # 按照init里面定义的处理下的图像，并ToTensor\n",
    "                    transform_img = self.transform(pil_img)\n",
    "                    count = count + 1 \n",
    "                    list_imgs_tensors.append(transform_img)\n",
    "        # 所有图像张量堆叠在第0维，并返回\n",
    "        stacked_tensors = paddle.stack(list_imgs_tensors, axis=0)\n",
    "        return stacked_tensors\n",
    "    # 和上面逻辑类似，取caption对应的证据\n",
    "    def load_captions(self,inv_dict):\n",
    "        captions = ['']\n",
    "        pages_with_captions_keys = ['all_fully_matched_captions','all_partially_matched_captions']\n",
    "        for key1 in pages_with_captions_keys:\n",
    "            if key1 in inv_dict.keys():\n",
    "                for page in inv_dict[key1]:\n",
    "                    # 就拿caption中title和caption\n",
    "                    if 'title' in page.keys():\n",
    "                        item = page['title']\n",
    "                        item = process_string(item)\n",
    "                        captions.append(item)\n",
    "                    \n",
    "                    if 'caption' in page.keys():\n",
    "                        sub_captions_list = []\n",
    "                        unfiltered_captions = []\n",
    "                        for key2 in page['caption']:\n",
    "                            sub_caption = page['caption'][key2]\n",
    "                            sub_caption_filter = process_string(sub_caption)\n",
    "                            if sub_caption in unfiltered_captions: continue \n",
    "                            sub_captions_list.append(sub_caption_filter) \n",
    "                            unfiltered_captions.append(sub_caption) \n",
    "                        captions = captions + sub_captions_list \n",
    "                    \n",
    "        pages_with_title_only_keys = ['partially_matched_no_text','fully_matched_no_text']\n",
    "        for key1 in pages_with_title_only_keys:\n",
    "            if key1 in inv_dict.keys():\n",
    "                for page in inv_dict[key1]:\n",
    "                    if 'title' in page.keys():\n",
    "                        title = process_string(page['title'])\n",
    "                        captions.append(title)\n",
    "        return captions\n",
    "\n",
    "    def load_captions_weibo(self,direct_dict):\n",
    "        captions = ['']\n",
    "        keys = ['images_with_captions','images_with_no_captions','images_with_caption_matched_tags']\n",
    "        for key1 in keys:\n",
    "            if key1 in direct_dict.keys():\n",
    "                for page in direct_dict[key1]:\n",
    "                    if 'page_title' in page.keys():\n",
    "                        item = page['page_title']\n",
    "                        item = process_string(item)\n",
    "                        captions.append(item)\n",
    "                    if 'caption' in page.keys():\n",
    "                        sub_captions_list = []\n",
    "                        unfiltered_captions = []\n",
    "                        for key2 in page['caption']:\n",
    "                            sub_caption = page['caption'][key2]\n",
    "                            sub_caption_filter = process_string(sub_caption)\n",
    "                            if sub_caption in unfiltered_captions: continue \n",
    "                            sub_captions_list.append(sub_caption_filter) \n",
    "                            unfiltered_captions.append(sub_caption) \n",
    "                        captions = captions + sub_captions_list \n",
    "        #print(captions)\n",
    "        return captions\n",
    "        #加载img文件夹\n",
    "    def load_queries(self,key):\n",
    "        caption = self.context_data_items_dict[key]['caption']\n",
    "        image_path = os.path.join(self.queries_root_dir,self.context_data_items_dict[key]['image_path'])\n",
    "        pil_img = self.load_img_pil(image_path)\n",
    "        transform_img = self.transform(pil_img)\n",
    "        return transform_img, caption\n",
    "    # 魔法方法，用来重载类的索引操作符[]\n",
    "    # 当使用instance[idx]的形式访问对象时，会自动调用该方法\n",
    "    # enumerate会返回索引和对应的值的元组，使用值，也会调用这个方法\n",
    "    # 返回sample。通过enumerate产生迭代器\n",
    "    def __getitem__(self, idx):\n",
    "        #print(idx)\n",
    "        #print(self.context_data_items_dict)      \n",
    "        #idx = idx.tolist()               \n",
    "        key = self.idx_to_keys[idx]\n",
    "        #print(key)\n",
    "        item=self.context_data_items_dict.get(str(key))\n",
    "        #print(item)\n",
    "        # 如果为test没有label属性\n",
    "        #print(self.split)\n",
    "        if self.split=='train' or self.split=='val':\n",
    "            label = paddle.to_tensor(int(item['label']))\n",
    "            direct_path_item = os.path.join(self.queries_root_dir,item['direct_path'])\n",
    "            inverse_path_item = os.path.join(self.queries_root_dir,item['inv_path'])\n",
    "            inv_ann_dict = json.load(open(os.path.join(inverse_path_item, 'inverse_annotation.json')))\n",
    "            direct_dict = json.load(open(os.path.join(direct_path_item, 'direct_annotation.json')))\n",
    "            captions= self.load_captions(inv_ann_dict)\n",
    "            captions += self.load_captions_weibo(direct_dict)\n",
    "            imgs = self.load_imgs_direct_search(direct_path_item,direct_dict)     \n",
    "            qImg,qCap =  self.load_queries(key)\n",
    "            sample = {'label': label, 'caption': captions,'imgs': imgs,  'qImg': qImg, 'qCap': qCap}\n",
    "        else:\n",
    "            direct_path_item = os.path.join(self.queries_root_dir,item['direct_path'])\n",
    "            inverse_path_item = os.path.join(self.queries_root_dir,item['inv_path'])\n",
    "            inv_ann_dict = json.load(open(os.path.join(inverse_path_item, 'inverse_annotation.json')))\n",
    "            direct_dict = json.load(open(os.path.join(direct_path_item, 'direct_annotation.json')))\n",
    "            captions= self.load_captions(inv_ann_dict)\n",
    "            captions += self.load_captions_weibo(direct_dict)\n",
    "            imgs = self.load_imgs_direct_search(direct_path_item,direct_dict)     \n",
    "            qImg,qCap =  self.load_queries(key)\n",
    "            sample = {'caption': captions,'imgs': imgs,  'qImg': qImg, 'qCap': qCap}\n",
    "        # print(\"================sample=======================\")\n",
    "        # print(sample)\n",
    "        # print(\"================len(captions)=======================\")\n",
    "        # print(len(captions)) \n",
    "        # print(\"================type(imgs)=======================\")\n",
    "        # print(type(imgs))\n",
    "        # print(\"================imgs.size=======================\")\n",
    "        # print(imgs.size)\n",
    "        # print(\"================imgs.shape=======================\")\n",
    "        # print(imgs.shape) \n",
    "        # 所以batch的样子是 (sample,5,3) \n",
    "        # item[0]是sample\n",
    "        # item[1]是5这样的数字\n",
    "        return sample,  len(captions), imgs.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:10:35.844701Z",
     "iopub.status.busy": "2023-07-26T11:10:35.844245Z",
     "iopub.status.idle": "2023-07-26T11:10:35.849617Z",
     "shell.execute_reply": "2023-07-26T11:10:35.848733Z",
     "shell.execute_reply.started": "2023-07-26T11:10:35.844671Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### load Datasets ####\n",
    "train_dataset = NewsContextDatasetEmbs(data_items_train, 'E:/Document/CodeSpace/Data_set/Paddle2023IKCEST/queries_dataset_merge','train')\n",
    "val_dataset = NewsContextDatasetEmbs(data_items_val,'E:/Document/CodeSpace/Data_set/Paddle2023IKCEST/queries_dataset_merge','val')\n",
    "test_dataset = NewsContextDatasetEmbs(data_items_test,'E:/Document/CodeSpace/Data_set/Paddle2023IKCEST/queries_dataset_merge','test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:10:35.851023Z",
     "iopub.status.busy": "2023-07-26T11:10:35.850724Z",
     "iopub.status.idle": "2023-07-26T11:10:36.138303Z",
     "shell.execute_reply": "2023-07-26T11:10:36.137122Z",
     "shell.execute_reply.started": "2023-07-26T11:10:35.850996Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'caption': ['', '', 'Boston Orange  波士頓菊子: 朱学渊  - 為中國史學的實證化而努力', '新华每日电讯-微报纸-2022年01月28日', '新华每日电讯-微报纸-2021年11月19日'], 'imgs': Tensor(shape=[3, 3, 224, 224], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[[[ 1.71804118,  1.47829461,  1.51254416, ..., -1.07329392,\n",
      "           -1.03904438, -1.05616915],\n",
      "          [ 1.39267087,  1.37554610,  1.58104312, ..., -1.03904438,\n",
      "           -1.05616915, -1.07329392],\n",
      "          [ 1.42692029,  1.47829461,  1.66666687, ..., -1.00479496,\n",
      "           -1.02191973, -1.02191973],\n",
      "          ...,\n",
      "          [-1.72403467, -1.74115944, -1.77540886, ...,  0.57068247,\n",
      "            0.50218344,  0.38231018],\n",
      "          [-1.74115944, -1.65553570, -1.63841093, ...,  0.51930821,\n",
      "            0.43368444,  0.21106265],\n",
      "          [-1.75828421, -1.75828421, -1.70690989, ...,  0.51930821,\n",
      "            0.41655967,  0.12543888]],\n",
      "\n",
      "         [[ 1.58823562,  1.36064458,  1.37815154, ..., -1.09033608,\n",
      "           -1.09033608, -1.12535000],\n",
      "          [ 1.22058833,  1.23809528,  1.44817960, ..., -1.09033608,\n",
      "           -1.10784304, -1.12535000],\n",
      "          [ 1.20308125,  1.30812323,  1.53571451, ..., -1.05532205,\n",
      "           -1.07282901, -1.09033608],\n",
      "          ...,\n",
      "          [-1.65056014, -1.66806722, -1.68557417, ...,  1.02801120,\n",
      "            0.87044823,  0.62535024],\n",
      "          [-1.68557417, -1.58053207, -1.56302512, ...,  0.97549027,\n",
      "            0.80042022,  0.45028022],\n",
      "          [-1.72058821, -1.68557417, -1.63305318, ...,  0.97549027,\n",
      "            0.78291327,  0.36274520]],\n",
      "\n",
      "         [[ 1.35023987,  1.12366033,  1.14108944, ..., -0.77612191,\n",
      "           -0.75869268, -0.79355109],\n",
      "          [ 1.00165594,  1.00165594,  1.21080625, ..., -0.77612191,\n",
      "           -0.79355109, -0.81098026],\n",
      "          [ 1.00165594,  1.08880186,  1.29795229, ..., -0.74126351,\n",
      "           -0.75869268, -0.77612191],\n",
      "          ...,\n",
      "          [-1.49071896, -1.49071896, -1.52557731, ...,  1.10623109,\n",
      "            0.96679759,  0.74021804],\n",
      "          [-1.50814819, -1.42100215, -1.40357304, ...,  1.05394351,\n",
      "            0.89708078,  0.60078448],\n",
      "          [-1.54300654, -1.52557731, -1.47328973, ...,  1.03651428,\n",
      "            0.87965161,  0.51363856]]],\n",
      "\n",
      "\n",
      "        [[[ 2.24890828,  2.24890828,  2.24890828, ...,  2.19753432,\n",
      "            2.24890828,  2.24890828],\n",
      "          [ 2.24890828,  2.24890828,  2.24890828, ...,  2.21465898,\n",
      "            2.24890828,  2.24890828],\n",
      "          [ 2.24890828,  2.24890828,  2.24890828, ...,  2.19753432,\n",
      "            2.24890828,  2.24890828],\n",
      "          ...,\n",
      "          [-1.39866436, -1.39866436, -1.39866436, ...,  1.94066298,\n",
      "            1.68379164,  1.75229061],\n",
      "          [ 1.28992236,  1.28992236,  1.28992236, ...,  1.78654015,\n",
      "            2.14615989,  1.83791447],\n",
      "          [ 2.19753432,  2.19753432,  2.19753432, ...,  1.52966881,\n",
      "            1.76941538,  1.59816790]],\n",
      "\n",
      "         [[ 2.42857146,  2.42857146,  2.42857146, ...,  2.37605071,\n",
      "            2.42857146,  2.42857146],\n",
      "          [ 2.42857146,  2.42857146,  2.42857146, ...,  2.39355755,\n",
      "            2.42857146,  2.42857146],\n",
      "          [ 2.42857146,  2.42857146,  2.42857146, ...,  2.37605071,\n",
      "            2.42857146,  2.42857146],\n",
      "          ...,\n",
      "          [ 0.03011219,  0.03011219,  0.03011219, ...,  2.11344552,\n",
      "            1.85084057,  1.92086864],\n",
      "          [ 1.78081262,  1.78081262,  1.78081262, ...,  1.95588255,\n",
      "            2.32352948,  2.00840354],\n",
      "          [ 2.41106486,  2.41106486,  2.41106486, ...,  1.69327760,\n",
      "            1.93837559,  1.76330554]],\n",
      "\n",
      "         [[ 2.64000010,  2.64000010,  2.64000010, ...,  2.58771276,\n",
      "            2.64000010,  2.64000010],\n",
      "          [ 2.64000010,  2.64000010,  2.64000010, ...,  2.60514212,\n",
      "            2.64000010,  2.64000010],\n",
      "          [ 2.64000010,  2.64000010,  2.64000010, ...,  2.58771276,\n",
      "            2.64000010,  2.64000010],\n",
      "          ...,\n",
      "          [ 1.31538141,  1.29795229,  1.33281064, ...,  2.32627511,\n",
      "            2.06483698,  2.13455367],\n",
      "          [ 2.23912883,  2.23912883,  2.23912883, ...,  2.16941214,\n",
      "            2.53542542,  2.22169971],\n",
      "          [ 2.55285430,  2.55285430,  2.55285430, ...,  1.90797424,\n",
      "            2.15198302,  1.97769105]]],\n",
      "\n",
      "\n",
      "        [[[ 2.24890828,  2.24890828,  2.24890828, ...,  1.47829461,\n",
      "            1.85503912,  1.63241732],\n",
      "          [ 2.24890828,  2.24890828,  2.24890828, ...,  1.97491241,\n",
      "            2.00916195,  2.07766104],\n",
      "          [ 2.24890828,  2.24890828,  2.24890828, ...,  1.54679358,\n",
      "            1.47829461,  1.71804118],\n",
      "          ...,\n",
      "          [ 1.75229061,  1.82078969,  1.75229061, ...,  2.23178363,\n",
      "            2.23178363,  2.23178363],\n",
      "          [ 2.14615989,  2.02628660,  2.00916195, ...,  1.85503912,\n",
      "            1.82078969,  1.82078969],\n",
      "          [ 1.95778763,  1.61529267,  1.64954209, ...,  1.37554610,\n",
      "            1.42692029,  1.39267087]],\n",
      "\n",
      "         [[ 2.42857146,  2.42857146,  2.42857146, ...,  1.64075661,\n",
      "            2.02591062,  1.79831958],\n",
      "          [ 2.42857146,  2.42857146,  2.42857146, ...,  2.14845967,\n",
      "            2.18347359,  2.25350142],\n",
      "          [ 2.42857146,  2.42857146,  2.42857146, ...,  1.71078455,\n",
      "            1.64075661,  1.88585460],\n",
      "          ...,\n",
      "          [ 1.92086864,  1.99089658,  1.92086864, ...,  2.41106486,\n",
      "            2.41106486,  2.41106486],\n",
      "          [ 2.32352948,  2.20098066,  2.18347359, ...,  2.02591062,\n",
      "            1.99089658,  1.99089658],\n",
      "          [ 2.13095260,  1.78081262,  1.81582654, ...,  1.53571451,\n",
      "            1.58823562,  1.55322158]],\n",
      "\n",
      "         [[ 2.64000010,  2.64000010,  2.64000010, ...,  1.85568666,\n",
      "            2.23912883,  2.01254940],\n",
      "          [ 2.64000010,  2.64000010,  2.64000010, ...,  2.36113334,\n",
      "            2.39599180,  2.46570849],\n",
      "          [ 2.64000010,  2.64000010,  2.64000010, ...,  1.92540348,\n",
      "            1.85568666,  2.09969544],\n",
      "          ...,\n",
      "          [ 2.13455367,  2.20427060,  2.13455367, ...,  2.62257099,\n",
      "            2.62257099,  2.62257099],\n",
      "          [ 2.53542542,  2.41342068,  2.39599180, ...,  2.23912883,\n",
      "            2.20427060,  2.20427060],\n",
      "          [ 2.34370399,  1.99512029,  2.02997851, ...,  1.75111151,\n",
      "            1.80339909,  1.76854074]]]]), 'qImg': Tensor(shape=[3, 224, 224], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[[ 2.23178363,  1.68379164,  1.85503912, ...,  2.24890828,\n",
      "           2.24890828,  2.24890828],\n",
      "         [ 2.11191034,  1.66666687,  1.88928866, ...,  2.24890828,\n",
      "           2.24890828,  2.24890828],\n",
      "         [ 1.94066298,  1.68379164,  1.87216389, ...,  2.24890828,\n",
      "           2.24890828,  2.24890828],\n",
      "         ...,\n",
      "         [ 0.36518541,  1.99203718,  0.09118938, ...,  0.43368444,\n",
      "           1.10154974,  0.67343098],\n",
      "         [ 0.36518541,  1.80366492,  0.02269037, ...,  1.63241732,\n",
      "           1.76941538, -0.02868389],\n",
      "         [ 0.29668641,  0.63918144,  0.38231018, ...,  0.58780718,\n",
      "           1.49541938, -0.26843041]],\n",
      "\n",
      "        [[ 2.09593868, -0.47759098, -1.96568620, ...,  2.42857146,\n",
      "           2.42857146,  2.42857146],\n",
      "         [ 1.58823562, -1.33543408, -1.98319328, ...,  2.42857146,\n",
      "           2.42857146,  2.42857146],\n",
      "         [ 0.69537824, -1.77310920, -1.98319328, ...,  2.42857146,\n",
      "           2.42857146,  2.42857146],\n",
      "         ...,\n",
      "         [ 0.50280124,  2.16596651,  0.22268920, ...,  0.57282925,\n",
      "           1.25560224,  0.81792724],\n",
      "         [ 0.50280124,  1.97338963,  0.15266119, ...,  1.79831958,\n",
      "           1.93837559,  0.10014019],\n",
      "         [ 0.43277320,  0.78291327,  0.52030820, ...,  0.73039222,\n",
      "           1.65826356, -0.14495783]],\n",
      "\n",
      "        [[ 2.44827914, -0.06152484, -1.40357304, ...,  2.64000010,\n",
      "           2.64000010,  2.64000010],\n",
      "         [ 2.02997851, -0.88069707, -1.47328973, ...,  2.64000010,\n",
      "           2.64000010,  2.64000010],\n",
      "         [ 1.10623109, -1.29899776, -1.47328973, ...,  2.64000010,\n",
      "           2.64000010,  2.64000010],\n",
      "         ...,\n",
      "         [ 0.72278887,  2.37856245,  0.44392177, ...,  0.79250562,\n",
      "           1.47224414,  1.03651428],\n",
      "         [ 0.72278887,  2.18684125,  0.37420499, ...,  2.01254940,\n",
      "           2.15198302,  0.32191741],\n",
      "         [ 0.65307206,  1.00165594,  0.74021804, ...,  0.94936836,\n",
      "           1.87311590,  0.07790870]]]), 'qCap': '看到有人说 这老头说了句话 不是我退休了 要是没退休 你早就在牢里了 说是某地政法系统的前领导 正局级干部退休的 我想问这种人敢说出这种话 在职间到底'}, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "# 打印数据\n",
    "for step, batch in enumerate(test_dataset, start=1):\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  collate函数通常作为DataLoader函数的参数,用来处理数据得到数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:10:36.140472Z",
     "iopub.status.busy": "2023-07-26T11:10:36.139797Z",
     "iopub.status.idle": "2023-07-26T11:10:36.159168Z",
     "shell.execute_reply": "2023-07-26T11:10:36.158224Z",
     "shell.execute_reply.started": "2023-07-26T11:10:36.140436Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddle \n",
    "# collate函数通常与DataLoader（数据加载器）关联\n",
    "# 接受一个列表作为输入，该列表包含多个样本，然后根据指定的规则将这些样本组合成一个批次\n",
    "# 作为DataLoader函数的参数\n",
    "# 处理批量训练数据 batch，返回labels, cap_batch, img_batch, qCap_batch, qImg_batch\n",
    "def collate_context_bert_train(batch):\n",
    "    #print(batch)\n",
    "    # item[0]是sample，所有sample存里面\n",
    "    samples = [item[0] for item in batch]\n",
    "    # 将caption中最大值的得到。\n",
    "    max_captions_len = max([item[1] for item in batch])\n",
    "    max_images_len = max([item[2] for item in batch])\n",
    "    qCap_batch = []\n",
    "    qImg_batch = []\n",
    "    img_batch = []\n",
    "    cap_batch = []\n",
    "    labels = [] \n",
    "    for j in range(0,len(samples)):  \n",
    "        sample = samples[j]    \n",
    "        # 是字典形式。所以sample['label']得到值\n",
    "        labels.append(sample['label'])\n",
    "        captions = sample['caption']\n",
    "        cap_len = len(captions)\n",
    "        for i in range(0,max_captions_len-cap_len):\n",
    "            captions.append(\"\")\n",
    "        if len(sample['imgs'].shape) > 2:\n",
    "            padding_size = (max_images_len-sample['imgs'].shape[0], sample['imgs'].shape[1], sample['imgs'].shape[2], sample['imgs'].shape[3])\n",
    "        else:\n",
    "            padding_size = (max_images_len-sample['imgs'].shape[0],sample['imgs'].shape[1])\n",
    "        padded_mem_img = paddle.concat((sample['imgs'], paddle.zeros(padding_size)),axis=0)\n",
    "        #print(1)\n",
    "        img_batch.append(padded_mem_img)#pad证据图片\n",
    "        cap_batch.append(captions)\n",
    "        qImg_batch.append(sample['qImg'])#[3, 224, 224]\n",
    "        qCap_batch.append(sample['qCap'])     \n",
    "    #print(labels)   \n",
    "    #print(img_batch)\n",
    "    img_batch = paddle.stack(img_batch, axis=0)\n",
    "    qImg_batch = paddle.stack(qImg_batch, axis=0)\n",
    "    labels = paddle.stack(labels, axis=0) \n",
    "    #print(3)  \n",
    "    return labels, cap_batch, img_batch, qCap_batch, qImg_batch\n",
    "\n",
    "def collate_context_bert_test(batch):\n",
    "    samples = [item[0] for item in batch]\n",
    "    max_captions_len = max([item[1] for item in batch])\n",
    "    max_images_len = max([item[2] for item in batch])\n",
    "    qCap_batch = []\n",
    "    qImg_batch = []\n",
    "    img_batch = []\n",
    "    cap_batch = []\n",
    "    for j in range(0,len(samples)):  \n",
    "        sample = samples[j]    \n",
    "        captions = sample['caption']\n",
    "        cap_len = len(captions)\n",
    "        for i in range(0,max_captions_len-cap_len):\n",
    "            captions.append(\"\")\n",
    "        if len(sample['imgs'].shape) > 2:\n",
    "            padding_size = (max_images_len-sample['imgs'].shape[0],sample['imgs'].shape[1],sample['imgs'].shape[2],sample['imgs'].shape[3])\n",
    "        else:\n",
    "            padding_size = (max_images_len-sample['imgs'].shape[0],sample['imgs'].shape[1])\n",
    "        padded_mem_img = paddle.concat((sample['imgs'], paddle.zeros(padding_size)),axis=0)\n",
    "        img_batch.append(padded_mem_img)\n",
    "        cap_batch.append(captions)\n",
    "        qImg_batch.append(sample['qImg'])\n",
    "        qCap_batch.append(sample['qCap'])        \n",
    "    img_batch = paddle.stack(img_batch, axis=0)\n",
    "    qImg_batch = paddle.stack(qImg_batch, axis=0)\n",
    "    return cap_batch, img_batch, qCap_batch, qImg_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:10:36.160770Z",
     "iopub.status.busy": "2023-07-26T11:10:36.160362Z",
     "iopub.status.idle": "2023-07-26T11:10:36.167522Z",
     "shell.execute_reply": "2023-07-26T11:10:36.166543Z",
     "shell.execute_reply.started": "2023-07-26T11:10:36.160742Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load DataLoader\n",
    "from paddle.io import DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn = collate_context_bert_train, return_list=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn = collate_context_bert_train,  return_list=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=False, collate_fn = collate_context_bert_test, return_list=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:10:36.168934Z",
     "iopub.status.busy": "2023-07-26T11:10:36.168616Z",
     "iopub.status.idle": "2023-07-26T11:10:37.878559Z",
     "shell.execute_reply": "2023-07-26T11:10:37.877474Z",
     "shell.execute_reply.started": "2023-07-26T11:10:36.168893Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tensor(shape=[4], dtype=int64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [2, 0, 0, 2]), [['', '', \"Foot Queen with 50% Off for the Weekend Only... Let's get naughty ...\", \"r/OnlyFans101 - Foot Queen with 50% Off for the Weekend Only... Let's get naughty together!\", \"Foot Queen with 50% Off for the Weekend Only... Let's get naughty ...\", \"r/onlyfansgirls101 - Foot Queen with 50% Off for the Weekend Only... Let's get naughty together!\", \"Foot Queen with 50% Off for the Weekend Only... Let's get naughty ...\", \"r/OnlyFans101 - Foot Queen with 50% Off for the Weekend Only... Let's get naughty together!\", 'Amazon.com: GoldFinger Limited Edition Snow Queen Press On ...', 'Amazon.com: GoldFinger Limited Edition Snow Queen Press On ...', ''], ['', '', '【#全国新冠疫苗接种超33亿剂次#... - @美东侨报 的微博精选 - 微博国际站', '全国新冠疫苗接种剂次超33亿', '全国新冠疫苗接种剂次超33亿_老年人_卫健_总方针', '全国新冠疫苗接种剂次超33亿', '全国新冠疫苗接种剂次超33亿 - 21财经', '#全国新冠疫苗接种超33亿剂次#国... - @TechWeb 的微博精选 - 微博国际站', '全国完成新冠疫苗全程接种人数超12亿-新华网', '【#全国新冠疫苗接种剂次超33亿#... - @21世纪经济报道 的微博精选 - 微博马来西亚站', '【权威快报|#全国新冠疫苗接种剂... - @成都商报 的微博精选 - 微博马来西亚站'], ['', '', '网传疑似精神病母亲虐待孩子，官方通报。-24小时-虎嗅网', '回应来了', '网传疑似精神病母亲虐待孩子，官方通报__财经头条', '网传疑似精神病母亲虐待孩子？广西岑溪官方通报：正在调查！|精神病|诚谏镇|母亲_新浪新闻', '官方通报网传疑似精神病母亲虐待孩子：相关调查工作正进行中_直击现场_澎湃新闻-The Paper', '官方通报网传疑似精神病母亲虐待孩子：相关调查工作正进行中|岑溪市_ ...', '', '', ''], ['', '', 'A Life in Stitches: Knitting My Way Through Love, Loss, and ...', 'Another Wolverine Declares For NFL - Sports Illustrated Michigan ...', 'Mo🏁 on Twitter: \"Forever Thankful. Seven Out!!! https://t.co ...', '', '', '', '', '', '']], Tensor(shape=[4, 9, 3, 224, 224], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[[[[ 0.72480524,  0.14256364, -0.61092561, ...,  0.38231018,\n",
      "             0.34806067,  0.34806067],\n",
      "           [ 0.63918144, -0.02868389, -0.61092561, ...,  0.41655967,\n",
      "             0.38231018,  0.38231018],\n",
      "           [ 0.60493195, -0.09718290, -0.69654936, ...,  0.45080918,\n",
      "             0.41655967,  0.41655967],\n",
      "           ...,\n",
      "           [-0.74792361, -0.74792361, -0.78217316, ...,  0.05693987,\n",
      "             0.02269037, -0.01155914],\n",
      "           [-0.76504838, -0.79929787, -0.81642264, ...,  0.09118938,\n",
      "             0.02269037,  0.02269037],\n",
      "           [-0.79929787, -0.86779690, -0.86779690, ...,  0.10831413,\n",
      "             0.02269037,  0.02269037]],\n",
      "\n",
      "          [[ 1.39565849,  0.41526622, -0.67016798, ...,  0.62535024,\n",
      "             0.59033620,  0.59033620],\n",
      "           [ 1.30812323,  0.24019620, -0.67016798, ...,  0.62535024,\n",
      "             0.59033620,  0.59033620],\n",
      "           [ 1.25560224,  0.15266119, -0.77521002, ...,  0.59033620,\n",
      "             0.57282925,  0.57282925],\n",
      "           ...,\n",
      "           [-0.63515401, -0.63515401, -0.67016798, ...,  0.18767519,\n",
      "             0.15266119,  0.11764719],\n",
      "           [-0.65266097, -0.68767500, -0.70518202, ...,  0.22268920,\n",
      "             0.15266119,  0.15266119],\n",
      "           [-0.68767500, -0.75770301, -0.75770301, ...,  0.24019620,\n",
      "             0.15266119,  0.15266119]],\n",
      "\n",
      "          [[ 2.02997851,  0.80993479, -0.35782126, ...,  0.77507645,\n",
      "             0.74021804,  0.74021804],\n",
      "           [ 1.92540348,  0.61821371, -0.37525046, ...,  0.77507645,\n",
      "             0.74021804,  0.74021804],\n",
      "           [ 1.83825755,  0.49620935, -0.51468402, ...,  0.77507645,\n",
      "             0.74021804,  0.74021804],\n",
      "           ...,\n",
      "           [-0.44496724, -0.44496724, -0.47982562, ...,  0.37420499,\n",
      "             0.33934662,  0.30448821],\n",
      "           [-0.46239641, -0.49725482, -0.51468402, ...,  0.40906337,\n",
      "             0.33934662,  0.33934662],\n",
      "           [-0.49725482, -0.56697160, -0.56697160, ...,  0.42649257,\n",
      "             0.33934662,  0.33934662]]],\n",
      "\n",
      "\n",
      "         [[[ 2.16328478,  1.80366492,  2.02628660, ..., -1.63841093,\n",
      "            -1.80965841, -1.75828421],\n",
      "           [ 2.16328478,  1.78654015,  2.02628660, ..., -1.72403467,\n",
      "            -1.74115944, -1.82678318],\n",
      "           [ 2.14615989,  1.80366492,  2.00916195, ..., -1.72403467,\n",
      "            -1.74115944, -1.82678318],\n",
      "           ...,\n",
      "           [-0.85067213, -0.88492167, -0.88492167, ...,  0.26243690,\n",
      "             0.33093593,  0.29668641],\n",
      "           [-0.88492167, -0.91917115, -0.86779690, ...,  0.24531215,\n",
      "             0.10831413,  0.27956167],\n",
      "           [-0.86779690, -0.95342064, -0.98767018, ...,  0.14256364,\n",
      "             0.17681314,  0.29668641]],\n",
      "\n",
      "          [[ 2.07843161,  1.72829151,  1.97338963, ..., -1.58053207,\n",
      "            -1.73809516, -1.70308125],\n",
      "           [ 2.07843161,  1.72829151,  1.97338963, ..., -1.65056014,\n",
      "            -1.63305318, -1.72058821],\n",
      "           [ 2.06092453,  1.72829151,  1.97338963, ..., -1.63305318,\n",
      "            -1.63305318, -1.72058821],\n",
      "           ...,\n",
      "           [-1.28291309, -1.31792700, -1.26540601, ..., -0.14495783,\n",
      "            -0.07492982, -0.10994382],\n",
      "           [-1.31792700, -1.35294104, -1.30042005, ..., -0.16246483,\n",
      "            -0.30252084, -0.12745082],\n",
      "           [-1.30042005, -1.38795507, -1.42296910, ..., -0.26750684,\n",
      "            -0.23249283, -0.10994382]],\n",
      "\n",
      "          [[ 1.71625316,  1.55939043,  1.92540348, ..., -1.45586061,\n",
      "            -1.59529412, -1.56043577],\n",
      "           [ 1.73368227,  1.54196119,  1.90797424, ..., -1.50814819,\n",
      "            -1.50814819, -1.57786489],\n",
      "           [ 1.73368227,  1.54196119,  1.89054513, ..., -1.50814819,\n",
      "            -1.50814819, -1.59529412],\n",
      "           ...,\n",
      "           [-1.40357304, -1.43843138, -1.43843138, ..., -0.27067530,\n",
      "            -0.20095852, -0.23581691],\n",
      "           [-1.43843138, -1.47328973, -1.42100215, ..., -0.28810447,\n",
      "            -0.42753804, -0.25324610],\n",
      "           [-1.42100215, -1.50814819, -1.54300654, ..., -0.39267966,\n",
      "            -0.35782126, -0.23581691]]],\n",
      "\n",
      "\n",
      "         [[[ 0.74193001,  0.07406463, -0.61092561, ...,  0.38231018,\n",
      "             0.38231018,  0.38231018],\n",
      "           [ 0.67343098, -0.01155914, -0.59380084, ...,  0.43368444,\n",
      "             0.39943492,  0.41655967],\n",
      "           [ 0.62205672, -0.09718290, -0.67942464, ...,  0.43368444,\n",
      "             0.41655967,  0.41655967],\n",
      "           ...,\n",
      "           [-0.74792361, -0.76504838, -0.76504838, ...,  0.03981512,\n",
      "             0.00556562,  0.00556562],\n",
      "           [-0.76504838, -0.81642264, -0.81642264, ...,  0.10831413,\n",
      "             0.03981512,  0.00556562],\n",
      "           [-0.81642264, -0.85067213, -0.86779690, ...,  0.10831413,\n",
      "             0.03981512,  0.02269037]],\n",
      "\n",
      "          [[ 1.41316557,  0.41526622, -0.68767500, ...,  0.60784322,\n",
      "             0.59033620,  0.59033620],\n",
      "           [ 1.30812323,  0.22268920, -0.67016798, ...,  0.60784322,\n",
      "             0.57282925,  0.59033620],\n",
      "           [ 1.27310932,  0.13515419, -0.77521002, ...,  0.60784322,\n",
      "             0.59033620,  0.59033620],\n",
      "           ...,\n",
      "           [-0.63515401, -0.65266097, -0.65266097, ...,  0.17016819,\n",
      "             0.13515419,  0.13515419],\n",
      "           [-0.65266097, -0.70518202, -0.70518202, ...,  0.24019620,\n",
      "             0.17016819,  0.13515419],\n",
      "           [-0.70518202, -0.74019599, -0.75770301, ...,  0.24019620,\n",
      "             0.17016819,  0.15266119]],\n",
      "\n",
      "          [[ 2.01254940,  0.75764722, -0.37525046, ...,  0.77507645,\n",
      "             0.77507645,  0.77507645],\n",
      "           [ 1.90797424,  0.60078448, -0.42753804, ...,  0.77507645,\n",
      "             0.74021804,  0.75764722],\n",
      "           [ 1.85568666,  0.51363856, -0.53211319, ...,  0.77507645,\n",
      "             0.75764722,  0.75764722],\n",
      "           ...,\n",
      "           [-0.44496724, -0.46239641, -0.46239641, ...,  0.37420499,\n",
      "             0.32191741,  0.32191741],\n",
      "           [-0.46239641, -0.51468402, -0.51468402, ...,  0.42649257,\n",
      "             0.35677579,  0.32191741],\n",
      "           [-0.51468402, -0.54954237, -0.56697160, ...,  0.44392177,\n",
      "             0.35677579,  0.33934662]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]]],\n",
      "\n",
      "\n",
      "         [[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]]],\n",
      "\n",
      "\n",
      "         [[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.00916195,  2.00916195,  2.00916195, ...,  1.22142327,\n",
      "             1.22142327,  1.22142327],\n",
      "           [ 2.00916195,  2.00916195,  2.00916195, ...,  1.22142327,\n",
      "             1.22142327,  1.22142327],\n",
      "           [ 2.00916195,  2.00916195,  2.00916195, ...,  1.20429862,\n",
      "             1.20429862,  1.20429862],\n",
      "           ...,\n",
      "           [ 0.75905472,  0.74193001,  0.72480524, ...,  0.75905472,\n",
      "             0.74193001,  0.72480524],\n",
      "           [ 0.77617949,  0.75905472,  0.72480524, ...,  0.74193001,\n",
      "             0.72480524,  0.70768046],\n",
      "           [ 0.77617949,  0.75905472,  0.72480524, ...,  0.75905472,\n",
      "             0.74193001,  0.72480524]],\n",
      "\n",
      "          [[ 2.20098066,  2.20098066,  2.20098066, ...,  1.48319352,\n",
      "             1.46568656,  1.46568656],\n",
      "           [ 2.20098066,  2.20098066,  2.20098066, ...,  1.44817960,\n",
      "             1.44817960,  1.44817960],\n",
      "           [ 2.20098066,  2.20098066,  2.20098066, ...,  1.43067253,\n",
      "             1.43067253,  1.43067253],\n",
      "           ...,\n",
      "           [ 0.94047624,  0.94047624,  0.90546227, ...,  1.09803927,\n",
      "             1.06302524,  1.04551828],\n",
      "           [ 0.97549027,  0.94047624,  0.92296922, ...,  1.08053231,\n",
      "             1.04551828,  1.01050425],\n",
      "           [ 0.97549027,  0.95798326,  0.94047624, ...,  1.08053231,\n",
      "             1.04551828,  1.02801120]],\n",
      "\n",
      "          [[ 2.48313761,  2.48313761,  2.46570849, ...,  2.13455367,\n",
      "             2.18684125,  2.18684125],\n",
      "           [ 2.48313761,  2.48313761,  2.46570849, ...,  2.09969544,\n",
      "             2.13455367,  2.13455367],\n",
      "           [ 2.48313761,  2.48313761,  2.44827914, ...,  2.06483698,\n",
      "             2.06483698,  2.06483698],\n",
      "           ...,\n",
      "           [ 1.36766899,  1.33281064,  1.31538141, ...,  1.87311590,\n",
      "             1.89054513,  1.89054513],\n",
      "           [ 1.38509822,  1.38509822,  1.33281064, ...,  1.83825755,\n",
      "             1.89054513,  1.92540348],\n",
      "           [ 1.41995656,  1.41995656,  1.36766899, ...,  1.85568666,\n",
      "             1.90797424,  1.92540348]]],\n",
      "\n",
      "\n",
      "         [[[-0.71367413, -0.71367413, -0.71367413, ..., -0.69654936,\n",
      "            -0.71367413, -0.71367413],\n",
      "           [-0.71367413, -0.71367413, -0.71367413, ..., -0.69654936,\n",
      "            -0.71367413, -0.71367413],\n",
      "           [-0.71367413, -0.71367413, -0.71367413, ..., -0.69654936,\n",
      "            -0.71367413, -0.71367413],\n",
      "           ...,\n",
      "           [ 1.23854804,  1.23854804,  1.22142327, ...,  0.09118938,\n",
      "             0.10831413,  0.14256364],\n",
      "           [ 1.23854804,  1.23854804,  1.20429862, ...,  0.12543888,\n",
      "             0.09118938,  0.12543888],\n",
      "           [ 1.23854804,  1.23854804,  1.20429862, ...,  0.12543888,\n",
      "             0.12543888,  0.15968838]],\n",
      "\n",
      "          [[ 0.53781521,  0.55532223,  0.55532223, ...,  0.55532223,\n",
      "             0.55532223,  0.55532223],\n",
      "           [ 0.53781521,  0.55532223,  0.55532223, ...,  0.55532223,\n",
      "             0.55532223,  0.55532223],\n",
      "           [ 0.55532223,  0.55532223,  0.55532223, ...,  0.57282925,\n",
      "             0.55532223,  0.55532223],\n",
      "           ...,\n",
      "           [ 1.83333361,  1.83333361,  1.83333361, ...,  1.65826356,\n",
      "             1.65826356,  1.65826356],\n",
      "           [ 1.83333361,  1.83333361,  1.83333361, ...,  1.64075661,\n",
      "             1.65826356,  1.65826356],\n",
      "           [ 1.83333361,  1.83333361,  1.83333361, ...,  1.64075661,\n",
      "             1.65826356,  1.65826356]],\n",
      "\n",
      "          [[ 2.29141665,  2.27398729,  2.29141665, ...,  2.32627511,\n",
      "             2.30884552,  2.29141665],\n",
      "           [ 2.29141665,  2.27398729,  2.29141665, ...,  2.32627511,\n",
      "             2.30884552,  2.29141665],\n",
      "           [ 2.29141665,  2.29141665,  2.29141665, ...,  2.30884552,\n",
      "             2.29141665,  2.29141665],\n",
      "           ...,\n",
      "           [ 2.43085027,  2.43085027,  2.41342068, ...,  2.39599180,\n",
      "             2.39599180,  2.41342068],\n",
      "           [ 2.43085027,  2.43085027,  2.41342068, ...,  2.39599180,\n",
      "             2.37856245,  2.39599180],\n",
      "           [ 2.43085027,  2.43085027,  2.41342068, ...,  2.39599180,\n",
      "             2.39599180,  2.39599180]]],\n",
      "\n",
      "\n",
      "         [[[-0.71367413, -0.69654936, -0.71367413, ..., -0.69654936,\n",
      "            -0.71367413, -0.71367413],\n",
      "           [-0.71367413, -0.69654936, -0.71367413, ..., -0.69654936,\n",
      "            -0.71367413, -0.71367413],\n",
      "           [-0.71367413, -0.69654936, -0.71367413, ..., -0.69654936,\n",
      "            -0.71367413, -0.71367413],\n",
      "           ...,\n",
      "           [ 1.28992236,  1.25567281,  1.22142327, ...,  0.09118938,\n",
      "             0.12543888,  0.14256364],\n",
      "           [ 1.28992236,  1.25567281,  1.22142327, ...,  0.12543888,\n",
      "             0.10831413,  0.12543888],\n",
      "           [ 1.28992236,  1.25567281,  1.22142327, ...,  0.14256364,\n",
      "             0.12543888,  0.12543888]],\n",
      "\n",
      "          [[ 0.55532223,  0.57282925,  0.55532223, ...,  0.57282925,\n",
      "             0.55532223,  0.55532223],\n",
      "           [ 0.55532223,  0.57282925,  0.55532223, ...,  0.57282925,\n",
      "             0.55532223,  0.55532223],\n",
      "           [ 0.55532223,  0.57282925,  0.55532223, ...,  0.57282925,\n",
      "             0.55532223,  0.55532223],\n",
      "           ...,\n",
      "           [ 1.79831958,  1.81582654,  1.83333361, ...,  1.69327760,\n",
      "             1.65826356,  1.65826356],\n",
      "           [ 1.79831958,  1.81582654,  1.83333361, ...,  1.67577052,\n",
      "             1.65826356,  1.65826356],\n",
      "           [ 1.79831958,  1.81582654,  1.81582654, ...,  1.65826356,\n",
      "             1.64075661,  1.65826356]],\n",
      "\n",
      "          [[ 2.29141665,  2.30884552,  2.29141665, ...,  2.30884552,\n",
      "             2.29141665,  2.29141665],\n",
      "           [ 2.29141665,  2.30884552,  2.29141665, ...,  2.30884552,\n",
      "             2.29141665,  2.29141665],\n",
      "           [ 2.29141665,  2.30884552,  2.29141665, ...,  2.30884552,\n",
      "             2.29141665,  2.29141665],\n",
      "           ...,\n",
      "           [ 2.43085027,  2.43085027,  2.43085027, ...,  2.39599180,\n",
      "             2.39599180,  2.41342068],\n",
      "           [ 2.43085027,  2.43085027,  2.41342068, ...,  2.39599180,\n",
      "             2.37856245,  2.37856245],\n",
      "           [ 2.43085027,  2.43085027,  2.41342068, ...,  2.39599180,\n",
      "             2.37856245,  2.39599180]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.72403467, -1.72403467, -1.74115944, ..., -2.11790395,\n",
      "            -2.11790395, -2.11790395],\n",
      "           [-1.72403467, -1.75828421, -1.74115944, ..., -2.11790395,\n",
      "            -2.11790395, -2.11790395],\n",
      "           [-1.74115944, -1.75828421, -1.74115944, ..., -2.11790395,\n",
      "            -2.11790395, -2.11790395],\n",
      "           ...,\n",
      "           [-1.99803066, -1.99803066, -1.96378124, ..., -1.62128615,\n",
      "            -1.74115944, -1.72403467],\n",
      "           [-1.99803066, -1.99803066, -1.82678318, ..., -1.72403467,\n",
      "            -1.72403467, -1.72403467],\n",
      "           [-1.98090601, -1.92953169, -1.70690989, ..., -1.74115944,\n",
      "            -1.72403467, -1.72403467]],\n",
      "\n",
      "          [[-0.40756297, -0.40756297, -0.44257697, ..., -0.77521002,\n",
      "            -0.81022400, -0.86274499],\n",
      "           [-0.39005598, -0.44257697, -0.40756297, ..., -0.77521002,\n",
      "            -0.82773101, -0.82773101],\n",
      "           [-0.40756297, -0.42506999, -0.37254897, ..., -0.77521002,\n",
      "            -0.82773101, -0.79271698],\n",
      "           ...,\n",
      "           [-0.58263302, -0.56512600, -0.54761899, ..., -0.47759098,\n",
      "            -0.53011197, -0.56512600],\n",
      "           [-0.58263302, -0.58263302, -0.49509799, ..., -0.54761899,\n",
      "            -0.53011197, -0.56512600],\n",
      "           [-0.58263302, -0.56512600, -0.39005598, ..., -0.53011197,\n",
      "            -0.54761899, -0.58263302]],\n",
      "\n",
      "          [[ 0.96679759,  0.94936836,  0.93193918, ...,  0.74021804,\n",
      "             0.67050129,  0.60078448],\n",
      "           [ 0.96679759,  0.91451001,  0.96679759, ...,  0.74021804,\n",
      "             0.63564289,  0.63564289],\n",
      "           [ 0.94936836,  0.93193918,  1.03651428, ...,  0.70535964,\n",
      "             0.65307206,  0.72278887],\n",
      "           ...,\n",
      "           [ 0.87965161,  0.91451001,  0.91451001, ...,  0.82736403,\n",
      "             0.80993479,  0.79250562],\n",
      "           [ 0.87965161,  0.89708078,  0.91451001, ...,  0.79250562,\n",
      "             0.82736403,  0.79250562],\n",
      "           [ 0.87965161,  0.86222237,  0.96679759, ...,  0.82736403,\n",
      "             0.80993479,  0.75764722]]],\n",
      "\n",
      "\n",
      "         [[[-0.73079890, -0.69654936, -0.69654936, ..., -0.69654936,\n",
      "            -0.71367413, -0.71367413],\n",
      "           [-0.73079890, -0.69654936, -0.69654936, ..., -0.69654936,\n",
      "            -0.71367413, -0.71367413],\n",
      "           [-0.73079890, -0.69654936, -0.71367413, ..., -0.67942464,\n",
      "            -0.69654936, -0.69654936],\n",
      "           ...,\n",
      "           [ 1.23854804,  1.23854804,  1.22142327, ...,  0.07406463,\n",
      "             0.10831413,  0.12543888],\n",
      "           [ 1.23854804,  1.23854804,  1.20429862, ...,  0.10831413,\n",
      "             0.10831413,  0.15968838],\n",
      "           [ 1.23854804,  1.23854804,  1.22142327, ...,  0.10831413,\n",
      "             0.14256364,  0.19393790]],\n",
      "\n",
      "          [[ 0.53781521,  0.57282925,  0.57282925, ...,  0.57282925,\n",
      "             0.55532223,  0.55532223],\n",
      "           [ 0.53781521,  0.57282925,  0.57282925, ...,  0.57282925,\n",
      "             0.55532223,  0.55532223],\n",
      "           [ 0.53781521,  0.55532223,  0.53781521, ...,  0.59033620,\n",
      "             0.57282925,  0.57282925],\n",
      "           ...,\n",
      "           [ 1.81582654,  1.81582654,  1.81582654, ...,  1.65826356,\n",
      "             1.67577052,  1.67577052],\n",
      "           [ 1.81582654,  1.81582654,  1.83333361, ...,  1.65826356,\n",
      "             1.67577052,  1.65826356],\n",
      "           [ 1.81582654,  1.83333361,  1.83333361, ...,  1.65826356,\n",
      "             1.67577052,  1.64075661]],\n",
      "\n",
      "          [[ 2.30884552,  2.27398729,  2.25655818, ...,  2.30884552,\n",
      "             2.29141665,  2.27398729],\n",
      "           [ 2.30884552,  2.29141665,  2.27398729, ...,  2.30884552,\n",
      "             2.29141665,  2.27398729],\n",
      "           [ 2.27398729,  2.32627511,  2.32627511, ...,  2.32627511,\n",
      "             2.30884552,  2.29141665],\n",
      "           ...,\n",
      "           [ 2.50056696,  2.46570849,  2.43085027, ...,  2.43085027,\n",
      "             2.34370399,  2.36113334],\n",
      "           [ 2.46570849,  2.43085027,  2.41342068, ...,  2.36113334,\n",
      "             2.32627511,  2.37856245],\n",
      "           [ 2.44827914,  2.43085027,  2.41342068, ...,  2.39599180,\n",
      "             2.36113334,  2.37856245]]],\n",
      "\n",
      "\n",
      "         [[[-0.71367413, -0.71367413, -0.69654936, ..., -0.69654936,\n",
      "            -0.71367413, -0.71367413],\n",
      "           [-0.71367413, -0.71367413, -0.69654936, ..., -0.67942464,\n",
      "            -0.69654936, -0.71367413],\n",
      "           [-0.71367413, -0.71367413, -0.71367413, ..., -0.67942464,\n",
      "            -0.69654936, -0.69654936],\n",
      "           ...,\n",
      "           [ 1.23854804,  1.23854804,  1.22142327, ...,  0.07406463,\n",
      "             0.10831413,  0.14256364],\n",
      "           [ 1.23854804,  1.23854804,  1.22142327, ...,  0.10831413,\n",
      "             0.12543888,  0.14256364],\n",
      "           [ 1.23854804,  1.23854804,  1.22142327, ...,  0.10831413,\n",
      "             0.12543888,  0.15968838]],\n",
      "\n",
      "          [[ 0.55532223,  0.55532223,  0.57282925, ...,  0.57282925,\n",
      "             0.55532223,  0.53781521],\n",
      "           [ 0.55532223,  0.55532223,  0.57282925, ...,  0.57282925,\n",
      "             0.57282925,  0.55532223],\n",
      "           [ 0.53781521,  0.53781521,  0.53781521, ...,  0.57282925,\n",
      "             0.59033620,  0.57282925],\n",
      "           ...,\n",
      "           [ 1.81582654,  1.81582654,  1.81582654, ...,  1.65826356,\n",
      "             1.65826356,  1.65826356],\n",
      "           [ 1.81582654,  1.81582654,  1.83333361, ...,  1.64075661,\n",
      "             1.65826356,  1.65826356],\n",
      "           [ 1.81582654,  1.83333361,  1.85084057, ...,  1.64075661,\n",
      "             1.65826356,  1.65826356]],\n",
      "\n",
      "          [[ 2.27398729,  2.25655818,  2.25655818, ...,  2.32627511,\n",
      "             2.30884552,  2.29141665],\n",
      "           [ 2.29141665,  2.29141665,  2.29141665, ...,  2.34370399,\n",
      "             2.29141665,  2.27398729],\n",
      "           [ 2.30884552,  2.34370399,  2.32627511, ...,  2.34370399,\n",
      "             2.25655818,  2.25655818],\n",
      "           ...,\n",
      "           [ 2.48313761,  2.46570849,  2.43085027, ...,  2.44827914,\n",
      "             2.39599180,  2.39599180],\n",
      "           [ 2.46570849,  2.46570849,  2.43085027, ...,  2.43085027,\n",
      "             2.41342068,  2.39599180],\n",
      "           [ 2.44827914,  2.43085027,  2.39599180, ...,  2.39599180,\n",
      "             2.39599180,  2.39599180]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.09478569,  2.19753432,  2.23178363, ...,  1.40979564,\n",
      "             1.42692029,  1.46116984],\n",
      "           [ 2.24890828,  2.24890828,  2.24890828, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828],\n",
      "           [ 2.24890828,  2.24890828,  2.24890828, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828],\n",
      "           ...,\n",
      "           [ 2.24890828,  2.24890828,  2.24890828, ...,  1.56391835,\n",
      "             1.95778763,  1.25567281],\n",
      "           [ 2.24890828,  2.24890828,  2.24890828, ...,  1.30704713,\n",
      "             2.14615989,  2.12903523],\n",
      "           [ 2.24890828,  2.24890828,  2.24890828, ...,  1.82078969,\n",
      "             2.12903523,  1.06730032]],\n",
      "\n",
      "          [[ 2.25350142,  2.41106486,  2.39355755, ...,  1.58823562,\n",
      "             1.55322158,  1.57072854],\n",
      "           [ 2.42857146,  2.42857146,  2.42857146, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146],\n",
      "           [ 2.42857146,  2.42857146,  2.42857146, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146],\n",
      "           ...,\n",
      "           [ 2.42857146,  2.42857146,  2.42857146, ...,  1.71078455,\n",
      "             2.16596651,  1.36064458],\n",
      "           [ 2.42857146,  2.42857146,  2.42857146, ...,  1.44817960,\n",
      "             2.37605071,  2.28851557],\n",
      "           [ 2.42857146,  2.42857146,  2.42857146, ...,  1.97338963,\n",
      "             2.34103680,  1.20308125]],\n",
      "\n",
      "          [[ 2.53542542,  2.57028365,  2.60514212, ...,  1.80339909,\n",
      "             1.76854074,  1.76854074],\n",
      "           [ 2.64000010,  2.64000010,  2.64000010, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010],\n",
      "           [ 2.64000010,  2.64000010,  2.64000010, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010],\n",
      "           ...,\n",
      "           [ 2.64000010,  2.64000010,  2.64000010, ...,  2.06483698,\n",
      "             2.34370399,  1.54196119],\n",
      "           [ 2.64000010,  2.64000010,  2.64000010, ...,  1.78596997,\n",
      "             2.55285430,  2.46570849],\n",
      "           [ 2.64000010,  2.64000010,  2.64000010, ...,  2.29141665,\n",
      "             2.50056696,  1.36766899]]],\n",
      "\n",
      "\n",
      "         [[[ 2.09478569,  2.19753432,  2.23178363, ...,  1.40979564,\n",
      "             1.42692029,  1.46116984],\n",
      "           [ 2.24890828,  2.24890828,  2.24890828, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828],\n",
      "           [ 2.24890828,  2.24890828,  2.24890828, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828],\n",
      "           ...,\n",
      "           [ 2.24890828,  2.24890828,  2.24890828, ...,  1.56391835,\n",
      "             1.95778763,  1.25567281],\n",
      "           [ 2.24890828,  2.24890828,  2.24890828, ...,  1.30704713,\n",
      "             2.14615989,  2.12903523],\n",
      "           [ 2.24890828,  2.24890828,  2.24890828, ...,  1.82078969,\n",
      "             2.12903523,  1.06730032]],\n",
      "\n",
      "          [[ 2.25350142,  2.41106486,  2.39355755, ...,  1.58823562,\n",
      "             1.55322158,  1.57072854],\n",
      "           [ 2.42857146,  2.42857146,  2.42857146, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146],\n",
      "           [ 2.42857146,  2.42857146,  2.42857146, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146],\n",
      "           ...,\n",
      "           [ 2.42857146,  2.42857146,  2.42857146, ...,  1.71078455,\n",
      "             2.16596651,  1.36064458],\n",
      "           [ 2.42857146,  2.42857146,  2.42857146, ...,  1.44817960,\n",
      "             2.37605071,  2.28851557],\n",
      "           [ 2.42857146,  2.42857146,  2.42857146, ...,  1.97338963,\n",
      "             2.34103680,  1.20308125]],\n",
      "\n",
      "          [[ 2.53542542,  2.57028365,  2.60514212, ...,  1.80339909,\n",
      "             1.76854074,  1.76854074],\n",
      "           [ 2.64000010,  2.64000010,  2.64000010, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010],\n",
      "           [ 2.64000010,  2.64000010,  2.64000010, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010],\n",
      "           ...,\n",
      "           [ 2.64000010,  2.64000010,  2.64000010, ...,  2.06483698,\n",
      "             2.34370399,  1.54196119],\n",
      "           [ 2.64000010,  2.64000010,  2.64000010, ...,  1.78596997,\n",
      "             2.55285430,  2.46570849],\n",
      "           [ 2.64000010,  2.64000010,  2.64000010, ...,  2.29141665,\n",
      "             2.50056696,  1.36766899]]],\n",
      "\n",
      "\n",
      "         [[[ 2.24890828,  2.24890828,  2.24890828, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828],\n",
      "           [ 2.24890828,  2.24890828,  2.24890828, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828],\n",
      "           [ 2.24890828,  2.24890828,  2.24890828, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828],\n",
      "           ...,\n",
      "           [ 2.24890828,  2.24890828,  2.24890828, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828],\n",
      "           [ 2.24890828,  2.24890828,  2.24890828, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828],\n",
      "           [ 2.24890828,  2.24890828,  2.24890828, ...,  2.24890828,\n",
      "             2.24890828,  2.24890828]],\n",
      "\n",
      "          [[ 2.42857146,  2.42857146,  2.42857146, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146],\n",
      "           [ 2.42857146,  2.42857146,  2.42857146, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146],\n",
      "           [ 2.42857146,  2.42857146,  2.42857146, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146],\n",
      "           ...,\n",
      "           [ 2.42857146,  2.42857146,  2.42857146, ...,  2.41106486,\n",
      "             2.41106486,  2.41106486],\n",
      "           [ 2.42857146,  2.42857146,  2.42857146, ...,  2.41106486,\n",
      "             2.41106486,  2.41106486],\n",
      "           [ 2.42857146,  2.42857146,  2.42857146, ...,  2.42857146,\n",
      "             2.42857146,  2.42857146]],\n",
      "\n",
      "          [[ 2.64000010,  2.64000010,  2.64000010, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010],\n",
      "           [ 2.64000010,  2.64000010,  2.64000010, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010],\n",
      "           [ 2.64000010,  2.64000010,  2.64000010, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010],\n",
      "           ...,\n",
      "           [ 2.64000010,  2.64000010,  2.64000010, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010],\n",
      "           [ 2.64000010,  2.64000010,  2.64000010, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010],\n",
      "           [ 2.64000010,  2.64000010,  2.64000010, ...,  2.64000010,\n",
      "             2.64000010,  2.64000010]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]]],\n",
      "\n",
      "\n",
      "         [[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]]],\n",
      "\n",
      "\n",
      "         [[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.58703661, -1.58703661, -1.58703661, ..., -1.58703661,\n",
      "            -1.58703661, -1.58703661],\n",
      "           [-1.58703661, -1.58703661, -1.58703661, ..., -1.58703661,\n",
      "            -1.58703661, -1.58703661],\n",
      "           [-1.58703661, -1.58703661, -1.58703661, ..., -1.58703661,\n",
      "            -1.58703661, -1.58703661],\n",
      "           ...,\n",
      "           [-1.58703661, -1.58703661, -1.58703661, ..., -1.58703661,\n",
      "            -1.58703661, -1.58703661],\n",
      "           [-1.58703661, -1.58703661, -1.58703661, ..., -1.58703661,\n",
      "            -1.58703661, -1.58703661],\n",
      "           [-1.58703661, -1.58703661, -1.58703661, ..., -1.58703661,\n",
      "            -1.58703661, -1.58703661]],\n",
      "\n",
      "          [[-0.96778703, -0.96778703, -0.96778703, ..., -0.96778703,\n",
      "            -0.96778703, -0.96778703],\n",
      "           [-0.96778703, -0.96778703, -0.96778703, ..., -0.96778703,\n",
      "            -0.96778703, -0.96778703],\n",
      "           [-0.96778703, -0.96778703, -0.96778703, ..., -0.96778703,\n",
      "            -0.96778703, -0.96778703],\n",
      "           ...,\n",
      "           [-0.96778703, -0.96778703, -0.96778703, ..., -0.96778703,\n",
      "            -0.96778703, -0.96778703],\n",
      "           [-0.96778703, -0.96778703, -0.96778703, ..., -0.96778703,\n",
      "            -0.96778703, -0.96778703],\n",
      "           [-0.96778703, -0.96778703, -0.96778703, ..., -0.96778703,\n",
      "            -0.96778703, -0.96778703]],\n",
      "\n",
      "          [[-0.28810447, -0.28810447, -0.28810447, ..., -0.28810447,\n",
      "            -0.28810447, -0.28810447],\n",
      "           [-0.28810447, -0.28810447, -0.28810447, ..., -0.28810447,\n",
      "            -0.28810447, -0.28810447],\n",
      "           [-0.28810447, -0.28810447, -0.28810447, ..., -0.28810447,\n",
      "            -0.28810447, -0.28810447],\n",
      "           ...,\n",
      "           [-0.28810447, -0.28810447, -0.28810447, ..., -0.28810447,\n",
      "            -0.28810447, -0.28810447],\n",
      "           [-0.28810447, -0.28810447, -0.28810447, ..., -0.28810447,\n",
      "            -0.28810447, -0.28810447],\n",
      "           [-0.28810447, -0.28810447, -0.28810447, ..., -0.28810447,\n",
      "            -0.28810447, -0.28810447]]],\n",
      "\n",
      "\n",
      "         [[[-1.82678318, -1.84390795, -1.84390795, ...,  1.82078969,\n",
      "             1.88928866,  1.94066298],\n",
      "           [-1.82678318, -1.86103272, -1.84390795, ...,  1.85503912,\n",
      "             1.95778763,  1.94066298],\n",
      "           [-1.82678318, -1.84390795, -1.84390795, ...,  1.87216389,\n",
      "             1.95778763,  1.95778763],\n",
      "           ...,\n",
      "           [-2.08365440, -2.08365440, -2.10077929, ...,  2.14615989,\n",
      "             2.16328478,  2.12903523],\n",
      "           [-2.04940486, -2.06652975, -2.08365440, ...,  2.14615989,\n",
      "             2.18040943,  2.16328478],\n",
      "           [-2.10077929, -2.10077929, -2.08365440, ...,  2.14615989,\n",
      "             2.16328478,  2.16328478]],\n",
      "\n",
      "          [[-0.88025200, -0.89775902, -0.89775902, ...,  1.20308125,\n",
      "             1.25560224,  1.30812323],\n",
      "           [-0.86274499, -0.89775902, -0.89775902, ...,  1.20308125,\n",
      "             1.27310932,  1.29061627],\n",
      "           [-0.86274499, -0.88025200, -0.89775902, ...,  1.23809528,\n",
      "             1.32563055,  1.34313750],\n",
      "           ...,\n",
      "           [-1.12535000, -1.14285707, -1.16036403, ...,  1.48319352,\n",
      "             1.57072854,  1.55322158],\n",
      "           [-1.14285707, -1.16036403, -1.19537807, ...,  1.48319352,\n",
      "             1.55322158,  1.58823562],\n",
      "           [-1.19537807, -1.23039198, -1.23039198, ...,  1.46568656,\n",
      "             1.53571451,  1.58823562]],\n",
      "\n",
      "          [[-0.13124162, -0.13124162, -0.13124162, ..., -1.03755987,\n",
      "            -0.93298465, -0.95041382],\n",
      "           [-0.14867094, -0.18352933, -0.14867094, ..., -1.12470579,\n",
      "            -1.03755987, -0.95041382],\n",
      "           [-0.14867094, -0.16610013, -0.16610013, ..., -1.07241821,\n",
      "            -0.98527229, -0.96784306],\n",
      "           ...,\n",
      "           [-0.42753804, -0.41010883, -0.41010883, ..., -1.19442248,\n",
      "            -1.10727668, -1.10727668],\n",
      "           [-0.41010883, -0.39267966, -0.39267966, ..., -1.21185172,\n",
      "            -1.14213490, -1.10727668],\n",
      "           [-0.44496724, -0.42753804, -0.41010883, ..., -1.22928095,\n",
      "            -1.15956414, -1.10727668]]],\n",
      "\n",
      "\n",
      "         [[[-1.36441481, -1.43291390, -1.50141287, ..., -1.14179289,\n",
      "            -1.12466824, -1.12466824],\n",
      "           [-1.45003867, -1.46716332, -1.45003867, ..., -1.15891767,\n",
      "            -1.14179289, -1.15891767],\n",
      "           [-1.45003867, -1.48428810, -1.46716332, ..., -1.15891767,\n",
      "            -1.12466824, -1.14179289],\n",
      "           ...,\n",
      "           [-1.48428810, -1.48428810, -1.51853764, ..., -1.53566241,\n",
      "            -1.50141287, -1.50141287],\n",
      "           [-1.51853764, -1.51853764, -1.46716332, ..., -1.53566241,\n",
      "            -1.55278718, -1.58703661],\n",
      "           [-1.46716332, -1.50141287, -1.48428810, ..., -1.48428810,\n",
      "            -1.50141287, -1.53566241]],\n",
      "\n",
      "          [[ 0.25770321,  0.20518219,  0.15266119, ...,  1.16806722,\n",
      "             1.18557429,  1.18557429],\n",
      "           [ 0.15266119,  0.17016819,  0.18767519, ...,  1.18557429,\n",
      "             1.18557429,  1.16806722],\n",
      "           [ 0.15266119,  0.13515419,  0.17016819, ...,  1.18557429,\n",
      "             1.22058833,  1.20308125],\n",
      "           ...,\n",
      "           [-0.61764699, -0.61764699, -0.65266097, ...,  0.43277320,\n",
      "             0.43277320,  0.45028022],\n",
      "           [-0.63515401, -0.63515401, -0.58263302, ...,  0.41526622,\n",
      "             0.43277320,  0.45028022],\n",
      "           [-0.58263302, -0.61764699, -0.60013998, ...,  0.43277320,\n",
      "             0.45028022,  0.46778721]],\n",
      "\n",
      "          [[ 1.78596997,  1.76854074,  1.71625316, ...,  2.25655818,\n",
      "             2.27398729,  2.27398729],\n",
      "           [ 1.71625316,  1.71625316,  1.75111151, ...,  2.25655818,\n",
      "             2.25655818,  2.23912883],\n",
      "           [ 1.71625316,  1.69882393,  1.73368227, ...,  2.25655818,\n",
      "             2.29141665,  2.27398729],\n",
      "           ...,\n",
      "           [ 1.24566460,  1.24566460,  1.19337702, ...,  1.92540348,\n",
      "             1.94283271,  1.96026182],\n",
      "           [ 1.21080625,  1.21080625,  1.26309383, ...,  1.92540348,\n",
      "             1.94283271,  1.94283271],\n",
      "           [ 1.26309383,  1.22823548,  1.24566460, ...,  1.90797424,\n",
      "             1.94283271,  1.94283271]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]]],\n",
      "\n",
      "\n",
      "         [[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]]],\n",
      "\n",
      "\n",
      "         [[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]],\n",
      "\n",
      "          [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           ...,\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ],\n",
      "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "             0.        ,  0.        ]]]]]), [\"Foot Queen with Off for the Weekend Only... Let's get naughty together! \", '国家卫健委4月12日通报全国新冠疫苗接种剂次超33亿', ' 2023年4月11日网上流传一则疑似精神病母亲虐待自家孩子的信息', \"I'm honored to be featured among most Influential Women Egypt . After my recognition as African Woman of the year one of most Influential Africans , . Thank you for the recognitions. Senator Dr. Rasha Kelej CEO Merck Foundation \"], Tensor(shape=[4, 3, 224, 224], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[[[-0.13143240, -0.14855716, -0.14855716, ..., -0.11430765,\n",
      "           -0.11430765, -0.11430765],\n",
      "          [-0.14855716, -0.16568191, -0.16568191, ..., -0.11430765,\n",
      "           -0.11430765, -0.11430765],\n",
      "          [-0.14855716, -0.16568191, -0.16568191, ..., -0.11430765,\n",
      "           -0.11430765, -0.11430765],\n",
      "          ...,\n",
      "          [ 0.58780718,  0.98167652,  0.91317749, ..., -1.50141287,\n",
      "           -1.50141287, -1.26166618],\n",
      "          [ 0.96455175,  0.93030226,  0.96455175, ..., -1.22741675,\n",
      "           -0.85067213, -0.31980470],\n",
      "          [ 0.94742703,  0.94742703,  0.96455175, ...,  0.03981512,\n",
      "            0.50218344,  0.67343098]],\n",
      "\n",
      "         [[-0.17997183, -0.17997183, -0.19747883, ..., -0.33753484,\n",
      "           -0.33753484, -0.33753484],\n",
      "          [-0.17997183, -0.19747883, -0.19747883, ..., -0.33753484,\n",
      "           -0.33753484, -0.33753484],\n",
      "          [-0.17997183, -0.19747883, -0.19747883, ..., -0.33753484,\n",
      "           -0.33753484, -0.33753484],\n",
      "          ...,\n",
      "          [ 0.46778721,  0.88795525,  0.83543426, ..., -1.79061615,\n",
      "           -1.77310920, -1.51050401],\n",
      "          [ 0.87044823,  0.83543426,  0.88795525, ..., -1.51050401,\n",
      "           -1.10784304, -0.56512600],\n",
      "          [ 0.85294122,  0.85294122,  0.87044823, ..., -0.23249283,\n",
      "            0.25770321,  0.46778721]],\n",
      "\n",
      "         [[-0.04409565, -0.04409565, -0.04409565, ..., -0.30553368,\n",
      "           -0.30553368, -0.30553368],\n",
      "          [-0.04409565, -0.06152484, -0.06152484, ..., -0.30553368,\n",
      "           -0.30553368, -0.30553368],\n",
      "          [-0.04409565, -0.06152484, -0.06152484, ..., -0.30553368,\n",
      "           -0.30553368, -0.30553368],\n",
      "          ...,\n",
      "          [ 0.53106773,  0.94936836,  0.93193918, ..., -1.54300654,\n",
      "           -1.56043577, -1.35128534],\n",
      "          [ 0.87965161,  0.82736403,  0.89708078, ..., -1.35128534,\n",
      "           -0.95041382, -0.44496724],\n",
      "          [ 0.89708078,  0.89708078,  0.89708078, ..., -0.11381242,\n",
      "            0.33934662,  0.51363856]]],\n",
      "\n",
      "\n",
      "        [[[-0.71367413, -0.71367413, -0.69654936, ..., -0.69654936,\n",
      "           -0.71367413, -0.71367413],\n",
      "          [-0.71367413, -0.71367413, -0.69654936, ..., -0.67942464,\n",
      "           -0.69654936, -0.71367413],\n",
      "          [-0.71367413, -0.71367413, -0.71367413, ..., -0.67942464,\n",
      "           -0.69654936, -0.69654936],\n",
      "          ...,\n",
      "          [ 1.23854804,  1.23854804,  1.22142327, ...,  0.07406463,\n",
      "            0.10831413,  0.14256364],\n",
      "          [ 1.23854804,  1.23854804,  1.22142327, ...,  0.10831413,\n",
      "            0.12543888,  0.14256364],\n",
      "          [ 1.23854804,  1.23854804,  1.22142327, ...,  0.10831413,\n",
      "            0.12543888,  0.15968838]],\n",
      "\n",
      "         [[ 0.55532223,  0.55532223,  0.57282925, ...,  0.57282925,\n",
      "            0.55532223,  0.53781521],\n",
      "          [ 0.55532223,  0.55532223,  0.57282925, ...,  0.57282925,\n",
      "            0.57282925,  0.55532223],\n",
      "          [ 0.53781521,  0.53781521,  0.53781521, ...,  0.57282925,\n",
      "            0.59033620,  0.57282925],\n",
      "          ...,\n",
      "          [ 1.81582654,  1.81582654,  1.81582654, ...,  1.65826356,\n",
      "            1.65826356,  1.65826356],\n",
      "          [ 1.81582654,  1.81582654,  1.83333361, ...,  1.64075661,\n",
      "            1.65826356,  1.65826356],\n",
      "          [ 1.81582654,  1.83333361,  1.85084057, ...,  1.64075661,\n",
      "            1.65826356,  1.65826356]],\n",
      "\n",
      "         [[ 2.27398729,  2.25655818,  2.25655818, ...,  2.32627511,\n",
      "            2.30884552,  2.29141665],\n",
      "          [ 2.29141665,  2.29141665,  2.29141665, ...,  2.34370399,\n",
      "            2.29141665,  2.27398729],\n",
      "          [ 2.30884552,  2.34370399,  2.32627511, ...,  2.34370399,\n",
      "            2.25655818,  2.25655818],\n",
      "          ...,\n",
      "          [ 2.48313761,  2.46570849,  2.43085027, ...,  2.44827914,\n",
      "            2.39599180,  2.39599180],\n",
      "          [ 2.46570849,  2.46570849,  2.43085027, ...,  2.43085027,\n",
      "            2.41342068,  2.39599180],\n",
      "          [ 2.44827914,  2.43085027,  2.39599180, ...,  2.39599180,\n",
      "            2.39599180,  2.39599180]]],\n",
      "\n",
      "\n",
      "        [[[-1.03904438, -1.03904438, -1.03904438, ..., -0.69654936,\n",
      "           -0.69654936, -0.69654936],\n",
      "          [-1.03904438, -1.03904438, -1.03904438, ..., -0.66229987,\n",
      "           -0.67942464, -0.71367413],\n",
      "          [-1.05616915, -1.05616915, -1.05616915, ..., -0.69654936,\n",
      "           -0.67942464, -0.69654936],\n",
      "          ...,\n",
      "          [-1.56991184, -1.56991184, -1.56991184, ..., -1.12466824,\n",
      "           -1.12466824, -1.10754347],\n",
      "          [-1.58703661, -1.56991184, -1.58703661, ..., -1.12466824,\n",
      "           -1.12466824, -1.12466824],\n",
      "          [-1.58703661, -1.58703661, -1.58703661, ..., -1.14179289,\n",
      "           -1.15891767, -1.14179289]],\n",
      "\n",
      "         [[-0.09243682, -0.09243682, -0.09243682, ...,  0.34523821,\n",
      "            0.34523821,  0.34523821],\n",
      "          [-0.10994382, -0.10994382, -0.10994382, ...,  0.34523821,\n",
      "            0.36274520,  0.36274520],\n",
      "          [-0.12745082, -0.12745082, -0.12745082, ...,  0.32773119,\n",
      "            0.34523821,  0.32773119],\n",
      "          ...,\n",
      "          [-0.79271698, -0.81022400, -0.81022400, ..., -0.19747883,\n",
      "           -0.19747883, -0.19747883],\n",
      "          [-0.79271698, -0.77521002, -0.79271698, ..., -0.21498583,\n",
      "           -0.21498583, -0.19747883],\n",
      "          [-0.79271698, -0.77521002, -0.81022400, ..., -0.21498583,\n",
      "           -0.21498583, -0.21498583]],\n",
      "\n",
      "         [[ 1.50710261,  1.52453172,  1.48967338, ...,  2.13455367,\n",
      "            2.06483698,  2.06483698],\n",
      "          [ 1.50710261,  1.52453172,  1.48967338, ...,  2.09969544,\n",
      "            2.04740787,  2.02997851],\n",
      "          [ 1.47224414,  1.47224414,  1.45481503, ...,  2.06483698,\n",
      "            2.04740787,  2.04740787],\n",
      "          ...,\n",
      "          [ 0.61821371,  0.63564289,  0.65307206, ...,  1.36766899,\n",
      "            1.36766899,  1.38509822],\n",
      "          [ 0.54849690,  0.54849690,  0.60078448, ...,  1.35023987,\n",
      "            1.36766899,  1.40252745],\n",
      "          [ 0.54849690,  0.53106773,  0.56592613, ...,  1.31538141,\n",
      "            1.36766899,  1.38509822]]],\n",
      "\n",
      "\n",
      "        [[[ 0.79330426,  0.77617949,  0.75905472, ..., -1.45003867,\n",
      "           -1.46716332, -1.38153958],\n",
      "          [ 0.75905472,  0.75905472,  0.74193001, ..., -1.48428810,\n",
      "           -1.48428810, -1.36441481],\n",
      "          [ 0.74193001,  0.75905472,  0.72480524, ..., -1.51853764,\n",
      "           -1.46716332, -1.33016539],\n",
      "          ...,\n",
      "          [-2.06652975, -2.01515555, -2.03228021, ..., -0.79929787,\n",
      "           -0.85067213, -0.86779690],\n",
      "          [-2.04940486, -2.01515555, -2.06652975, ..., -0.81642264,\n",
      "           -0.85067213, -0.86779690],\n",
      "          [-2.03228021, -2.01515555, -2.04940486, ..., -0.81642264,\n",
      "           -0.86779690, -0.88492167]],\n",
      "\n",
      "         [[ 2.04341769,  2.06092453,  2.06092453, ..., -0.37254897,\n",
      "           -0.60013998, -0.63515401],\n",
      "          [ 2.04341769,  2.06092453,  2.04341769, ..., -0.42506999,\n",
      "           -0.60013998, -0.61764699],\n",
      "          [ 2.04341769,  2.07843161,  2.07843161, ..., -0.47759098,\n",
      "           -0.61764699, -0.61764699],\n",
      "          ...,\n",
      "          [-1.93067217, -1.87815118, -1.89565825, ...,  1.44817960,\n",
      "            1.41316557,  1.39565849],\n",
      "          [-1.91316521, -1.87815118, -1.93067217, ...,  1.43067253,\n",
      "            1.41316557,  1.39565849],\n",
      "          [-1.89565825, -1.87815118, -1.91316521, ...,  1.43067253,\n",
      "            1.39565849,  1.37815154]],\n",
      "\n",
      "         [[ 2.11712456,  2.13455367,  2.11712456, ..., -0.13124162,\n",
      "           -0.35782126, -0.42753804],\n",
      "          [ 2.09969544,  2.11712456,  2.09969544, ..., -0.18352933,\n",
      "           -0.37525046, -0.44496724],\n",
      "          [ 2.11712456,  2.13455367,  2.11712456, ..., -0.23581691,\n",
      "           -0.39267966, -0.44496724],\n",
      "          ...,\n",
      "          [-1.54300654, -1.49071896, -1.54300654, ...,  1.54196119,\n",
      "            1.52453172,  1.52453172],\n",
      "          [-1.52557731, -1.49071896, -1.56043577, ...,  1.52453172,\n",
      "            1.52453172,  1.52453172],\n",
      "          [-1.50814819, -1.49071896, -1.54300654, ...,  1.52453172,\n",
      "            1.50710261,  1.50710261]]]])]\n"
     ]
    }
   ],
   "source": [
    "# 打印数据\n",
    "for step, batch in enumerate(train_dataloader, start=1):\n",
    "    print(batch)\n",
    "    input_test = batch\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四、模型构建\n",
    "**本次赛题为一个NLP与多模态的分类赛题，整体建模采用特征提取、特征交互、预测分类三个阶段**\n",
    "\n",
    "**特征提取：** 对于图像数据，使用ResNet模型进行特征提取、对于文本数据，使用预训练模型Ernie-m多语言模型对中文和英文同时处理，qCap,qImg,（需要验证的标题或图像材料）、caps,imgs（支持验证的文本、图像证据材料）\n",
    "\n",
    "**特征交互**：使用多头自注意力机制，将标题与文本证据材料交互、图像与图像证据材料交互，输出与需要验证的标题和图像的相关证据特征caps_feature、imgs_features\n",
    "\n",
    "**预测分类：** 最后使用全连接层将标题特征、图像特征、相关的文本证据特征、相关的图像证据特征拼接输入到分类器得到最终结果\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/3f29e3f853b9445fbeb24189103cdbbcb8364498dc484593a891839994dadbd6)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多语言预训练模型ERNIE-M\n",
    "2021年，百度发布多语言预训练模型ERNIE-M。ERNIE-M通过对96门语言的学习，使得一个模型能同时理解96种语言，该项技术在5类典型跨语言理解任务上刷新世界最好效果。\n",
    "\n",
    "## ERNIE-M原理\n",
    "ERNIE-M基于飞桨PaddlePaddle框架训练，该模型构建了大小为25万的多语言词表，涵盖了96种语言的大多数常见词汇，训练语料包含了汉语、英语、法语、南非语、阿尔巴尼亚语、阿姆哈拉语、梵语、阿拉伯语、亚美尼亚语、阿萨姆语、阿塞拜疆语等96种语言，约1.5万亿字符。\n",
    "\n",
    "ERNIE-M的学习过程由两阶段组成。第一阶段从少量的双语语料中学习跨语言理解能力，使模型学到初步的语言对齐关系；第二阶段使用回译的思想，通过大量的单语语料学习，增强模型的跨语言理解能力。\n",
    "\n",
    "[百度NLP知乎介绍](https://zhuanlan.zhihu.com/p/344810337)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:10:37.880597Z",
     "iopub.status.busy": "2023-07-26T11:10:37.880109Z",
     "iopub.status.idle": "2023-07-26T11:10:38.802885Z",
     "shell.execute_reply": "2023-07-26T11:10:38.801219Z",
     "shell.execute_reply.started": "2023-07-26T11:10:37.880565Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from paddle.vision import models\n",
    "import paddle\n",
    "from paddlenlp.transformers import ErnieMModel,ErnieMTokenizer\n",
    "from paddle.nn import functional as F\n",
    "from paddle import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from visualdl import LogWriter\n",
    "\n",
    "class EncoderCNN(nn.Layer):\n",
    "    def __init__(self, resnet_arch = 'resnet101'):\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        if resnet_arch == 'resnet101':\n",
    "            resnet = models.resnet101(pretrained=True)\n",
    "        modules = list(resnet.children())[:-2]\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2D((1, 1))\n",
    "    def forward(self, images, features='pool'):\n",
    "        out = self.resnet(images)\n",
    "        if features == 'pool':\n",
    "            out = self.adaptive_pool(out)\n",
    "            out = paddle.reshape(out, (out.shape[0],out.shape[1]))\n",
    "        return out\n",
    "\n",
    "class NetWork(nn.Layer):\n",
    "    def __init__(self, mode):\n",
    "        super(NetWork, self).__init__()\n",
    "        self.mode = mode           \n",
    "        self.ernie = ErnieMModel.from_pretrained('ernie-m-base')\n",
    "        self.tokenizer = ErnieMTokenizer.from_pretrained('ernie-m-base')\n",
    "        self.resnet = EncoderCNN()\n",
    "        self.classifier1 = nn.Linear(2*(768+2048),1024)\n",
    "        self.classifier2 = nn.Linear(1024,3)\n",
    "        self.attention_text = nn.MultiHeadAttention(768,16)\n",
    "        self.attention_image = nn.MultiHeadAttention(2048,16)\n",
    "        if self.mode == 'text':\n",
    "            self.classifier = nn.Linear(768,3)\n",
    "        self.resnet.eval()\n",
    "\n",
    "    def forward(self,qCap,qImg,caps,imgs):\n",
    "        self.resnet.eval()\n",
    "        encode_dict_qcap = self.tokenizer(text = qCap ,max_length = 128 ,truncation=True, padding='max_length')\n",
    "        input_ids_qcap = encode_dict_qcap['input_ids']\n",
    "        input_ids_qcap = paddle.to_tensor(input_ids_qcap)\n",
    "        qcap_feature, pooled_output= self.ernie(input_ids_qcap) #(b,length,dim)\n",
    "        if self.mode == 'text':\n",
    "            logits = self.classifier(qcap_feature[:,0,:].squeeze(1))\n",
    "            return logits\n",
    "        caps_feature = []\n",
    "        for i,caption in enumerate (caps):\n",
    "            encode_dict_cap = self.tokenizer(text = caption ,max_length = 128 ,truncation=True, padding='max_length')\n",
    "            input_ids_caps = encode_dict_cap['input_ids']\n",
    "            input_ids_caps = paddle.to_tensor(input_ids_caps)\n",
    "            cap_feature, pooled_output= self.ernie(input_ids_caps) #(b,length,dim)\n",
    "            caps_feature.append(cap_feature)\n",
    "        caps_feature = paddle.stack(caps_feature,axis=0) #(b,num,length,dim)\n",
    "        caps_feature = caps_feature.mean(axis=1)#(b,length,dim)\n",
    "        caps_feature = self.attention_text(qcap_feature,caps_feature,caps_feature) #(b,length,dim)\n",
    "        imgs_features = []\n",
    "        for img in imgs:\n",
    "            imgs_feature = self.resnet(img) #(length,dim)\n",
    "            imgs_features.append(imgs_feature)\n",
    "        imgs_features = paddle.stack(imgs_features,axis=0) #(b,length,dim)\n",
    "        qImg_features = []\n",
    "        for qImage in qImg:\n",
    "            qImg_feature = self.resnet(qImage.unsqueeze(axis=0)) #(1,dim)\n",
    "            qImg_features.append(qImg_feature)\n",
    "        qImg_feature = paddle.stack(qImg_features,axis=0) #(b,1,dim)\n",
    "        imgs_features = self.attention_image(qImg_feature,imgs_features,imgs_features) #(b,1,dim)\n",
    "        # [1, 128, 768] [1, 128, 768] [1, 1, 2048] [1, 1, 2048] origin\n",
    "        # print(qcap_feature.shape,caps_feature.shape,qImg_feature.shape,imgs_features.shape)\n",
    "        # print((qcap_feature[:,0,:].shape,caps_feature[:,0,:].shape,qImg_feature.squeeze(1).shape,imgs_features.squeeze(1).shape))\n",
    "        # ([1,768], [1 , 768], [1, 2048], [1,  2048])\n",
    "        feature = paddle.concat(x=[qcap_feature[:,0,:], caps_feature[:,0,:], qImg_feature.squeeze(1), imgs_features.squeeze(1)], axis=-1) \n",
    "        logits = self.classifier1(feature)\n",
    "        logits = self.classifier2(logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:10:38.805643Z",
     "iopub.status.busy": "2023-07-26T11:10:38.804526Z",
     "iopub.status.idle": "2023-07-26T11:11:44.041344Z",
     "shell.execute_reply": "2023-07-26T11:11:44.040328Z",
     "shell.execute_reply.started": "2023-07-26T11:10:38.805603Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-08-23 15:37:14,264] [    INFO]\u001b[0m - Model config ErnieMConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"ernie_m\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"paddlenlp_version\": null,\n",
      "  \"type_vocab_size\": 16,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\u001b[0m\n",
      "\u001b[33m[2023-08-23 15:37:33,066] [ WARNING]\u001b[0m - Some weights of the model checkpoint at ernie-m-base were not used when initializing ErnieMModel: ['cls.predictions.transform.bias', 'cls.predictions.layer_norm.weight', 'cls.predictions.layer_norm.bias', 'cls.predictions.transform.weight', 'cls.predictions.decoder_bias']\n",
      "- This IS expected if you are initializing ErnieMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ErnieMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[33m[2023-08-23 15:37:33,067] [ WARNING]\u001b[0m - Some weights of ErnieMModel were not initialized from the model checkpoint at ernie-m-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[32m[2023-08-23 15:37:33,069] [    INFO]\u001b[0m - Already cached C:\\Users\\lins\\.paddlenlp\\models\\ernie-m-base\\ernie_m.vocab.txt\u001b[0m\n",
      "\u001b[32m[2023-08-23 15:37:33,069] [    INFO]\u001b[0m - Already cached C:\\Users\\lins\\.paddlenlp\\models\\ernie-m-base\\ernie_m.sentencepiece.bpe.model\u001b[0m\n",
      "\u001b[32m[2023-08-23 15:37:33,802] [    INFO]\u001b[0m - tokenizer config file saved in C:\\Users\\lins\\.paddlenlp\\models\\ernie-m-base\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-08-23 15:37:33,803] [    INFO]\u001b[0m - Special tokens file saved in C:\\Users\\lins\\.paddlenlp\\models\\ernie-m-base\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetWork(\n",
      "  (ernie): ErnieMModel(\n",
      "    (embeddings): ErnieMEmbeddings(\n",
      "      (word_embeddings): Embedding(250002, 768, sparse=False)\n",
      "      (position_embeddings): Embedding(514, 768, sparse=False)\n",
      "      (layer_norm): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "      (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "    )\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): LayerList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (6): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (7): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (8): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (9): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (10): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (11): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): ErnieMPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (resnet): EncoderCNN(\n",
      "    (resnet): Sequential(\n",
      "      (0): Conv2D(3, 64, kernel_size=[7, 7], stride=[2, 2], padding=3, data_format=NCHW)\n",
      "      (1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool2D(kernel_size=3, stride=2, padding=1)\n",
      "      (4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (conv1): Conv2D(64, 64, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2D(256, 64, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2D(256, 64, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (conv1): Conv2D(256, 128, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(128, 128, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2D(256, 512, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)\n",
      "            (1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (conv1): Conv2D(512, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2D(512, 1024, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)\n",
      "            (1): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (7): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (conv1): Conv2D(1024, 512, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(512, 512, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2D(1024, 2048, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)\n",
      "            (1): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2D(2048, 512, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2D(2048, 512, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)\n",
      "          (conv2): Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)\n",
      "          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)\n",
      "          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (adaptive_pool): AdaptiveAvgPool2D(output_size=(1, 1))\n",
      "  )\n",
      "  (classifier1): Linear(in_features=5632, out_features=1024, dtype=float32)\n",
      "  (classifier2): Linear(in_features=1024, out_features=3, dtype=float32)\n",
      "  (attention_text): MultiHeadAttention(\n",
      "    (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "    (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "  )\n",
      "  (attention_image): MultiHeadAttention(\n",
      "    (q_proj): Linear(in_features=2048, out_features=2048, dtype=float32)\n",
      "    (k_proj): Linear(in_features=2048, out_features=2048, dtype=float32)\n",
      "    (v_proj): Linear(in_features=2048, out_features=2048, dtype=float32)\n",
      "    (out_proj): Linear(in_features=2048, out_features=2048, dtype=float32)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 声明模型\n",
    "model = NetWork(\"image\")\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 六、训练配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:11:44.043510Z",
     "iopub.status.busy": "2023-07-26T11:11:44.042884Z",
     "iopub.status.idle": "2023-07-26T11:11:44.089142Z",
     "shell.execute_reply": "2023-07-26T11:11:44.088273Z",
     "shell.execute_reply.started": "2023-07-26T11:11:44.043472Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5592 559\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "num_training_steps = len(train_dataloader) * epochs\n",
    "warmup_steps = int(num_training_steps*0.1)\n",
    "print(num_training_steps,warmup_steps)\n",
    "# 定义 learning_rate_scheduler，负责在训练过程中对 lr 进行调度\n",
    "lr_scheduler = LinearDecayWithWarmup(1e-6, num_training_steps, warmup_steps)\n",
    "# 训练结束后，存储模型参数\n",
    "save_dir =\"checkpoint/\"\n",
    "best_dir = \"best_model\"\n",
    "# 创建保存的文件夹\n",
    "os.makedirs(save_dir,exist_ok=True)\n",
    "os.makedirs(best_dir,exist_ok=True)\n",
    "\n",
    "decay_params = [\n",
    "    p.name for n, p in model.named_parameters()\n",
    "    if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "]\n",
    "\n",
    "# 定义 Optimizer\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "    learning_rate=lr_scheduler,\n",
    "    parameters=model.parameters(),\n",
    "    weight_decay=1.2e-4,\n",
    "    apply_decay_param_fun=lambda x: x in decay_params)\n",
    "\n",
    "# 交叉熵损失\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "\n",
    "# 评估的时候采用准确率指标\n",
    "metric = paddle.metric.Accuracy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 七、模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:11:44.090806Z",
     "iopub.status.busy": "2023-07-26T11:11:44.090378Z",
     "iopub.status.idle": "2023-07-26T11:11:44.103547Z",
     "shell.execute_reply": "2023-07-26T11:11:44.102756Z",
     "shell.execute_reply.started": "2023-07-26T11:11:44.090776Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 定义线下评估 评价指标为acc 线上评估是f1score\n",
    "@paddle.no_grad()\n",
    "def evaluate(model, criterion, metric, data_loader):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    losses = []\n",
    "    for batch in data_loader:      \n",
    "        labels, cap_batch, img_batch, qCap_batch, qImg_batch = batch\n",
    "        logits = model(qCap=qCap_batch,qImg=qImg_batch,caps=cap_batch,imgs=img_batch)\n",
    "        loss = criterion(logits, labels)\n",
    "        losses.append(loss.numpy())\n",
    "        correct = metric.compute(logits, labels)\n",
    "        metric.update(correct)\n",
    "        accu = metric.accumulate()\n",
    "    print(\"eval loss: %.5f, accu: %.5f\" % (np.mean(losses), accu))\n",
    "    model.train()\n",
    "    metric.reset()\n",
    "    return np.mean(losses), accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:11:44.107830Z",
     "iopub.status.busy": "2023-07-26T11:11:44.107431Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train run start\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20788\\610113224.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m                     \u001b[0msave_param_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model_best.pdparams'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                     \u001b[0mpaddle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_param_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0mdo_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20788\\610113224.py\u001b[0m in \u001b[0;36mdo_train\u001b[1;34m(model, criterion, metric, val_dataloader, train_dataloader)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcap_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqCap_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqImg_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqCap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mqCap_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mqImg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mqImg_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcaps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcap_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;31m# 16GB显存崩了。\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\layers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1252\u001b[0m         ):\n\u001b[0;32m   1253\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dygraph_call_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20788\\2088623279.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, qCap, qImg, caps, imgs)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0minput_ids_caps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencode_dict_cap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_ids'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0minput_ids_caps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids_caps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[0mcap_feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpooled_output\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mernie\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids_caps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#(b,length,dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m             \u001b[0mcaps_feature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcap_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mcaps_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaps_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#(b,num,length,dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\layers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1252\u001b[0m         ):\n\u001b[0;32m   1253\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dygraph_call_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddlenlp\\transformers\\ernie_m\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, position_ids, attention_mask, inputs_embeds, past_key_values, use_cache, output_hidden_states, output_attentions, return_dict)\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m         )\n\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\layers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1252\u001b[0m         ):\n\u001b[0;32m   1253\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dygraph_call_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddlenlp\\transformers\\model_outputs.py\u001b[0m in \u001b[0;36m_transformer_encoder_fwd\u001b[1;34m(self, src, src_mask, cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    301\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiHeadAttention\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                 \u001b[1;32melse\u001b[0m \u001b[0mMultiHeadAttention\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m                 \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m             )\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\layers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1252\u001b[0m         ):\n\u001b[0;32m   1253\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dygraph_call_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddlenlp\\transformers\\model_outputs.py\u001b[0m in \u001b[0;36m_transformer_encoder_layer_fwd\u001b[1;34m(self, src, src_mask, cache, output_attentions)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[0mattn_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattn_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattn_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\layers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1252\u001b[0m         ):\n\u001b[0;32m   1253\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dygraph_call_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\transformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, query, key, value, attn_mask, cache)\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;31m# compute q ,k ,v\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m             \u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_qkv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m             \u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_qkv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\transformer.py\u001b[0m in \u001b[0;36m_prepare_qkv\u001b[1;34m(self, query, key, value, cache)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[1;32mand\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mtypes\u001b[0m \u001b[0mare\u001b[0m \u001b[0msame\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \"\"\"\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq_proj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m         \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\layers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1252\u001b[0m         ):\n\u001b[0;32m   1253\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dygraph_call_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\common.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         out = F.linear(\n\u001b[1;32m--> 175\u001b[1;33m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         )\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\functional\\common.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(x, weight, bias, name)\u001b[0m\n\u001b[0;32m   1840\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0min_dynamic_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m         \u001b[1;31m# TODO(jiabin): using addmm for fast forward route\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1842\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_C_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1843\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1844\u001b[0m         \u001b[0mhelper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLayerHelper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 定义训练\n",
    "def do_train(model, criterion, metric, val_dataloader,train_dataloader):\n",
    "    print(\"train run start\")\n",
    "    global_step = 0\n",
    "    tic_train = time.time()\n",
    "    best_accuracy=0.0\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for step, batch in enumerate(train_dataloader, start=1):\n",
    "            labels, cap_batch, img_batch, qCap_batch, qImg_batch = batch\n",
    "            probs = model(qCap=qCap_batch,qImg=qImg_batch,caps=cap_batch,imgs=img_batch)\n",
    "            \n",
    "            # 16GB显存崩了。\n",
    "            # # 用visualDL，绘制模型图\n",
    "            # net=model()\n",
    "            # with LogWriter(logdir=\"./log/graph_test/\") as writer:\n",
    "            #     writer.add_graph(\n",
    "            #         model=net,\n",
    "            #         input_spec=[qCap_batch,qImg_batch,cap_batch,img_batch],\n",
    "            #         verbose=True)\n",
    "            # break\n",
    "            loss = criterion(probs, labels)\n",
    "            correct = metric.compute(probs, labels)\n",
    "            metric.update(correct)\n",
    "            acc = metric.accumulate()\n",
    "\n",
    "            global_step += 1 \n",
    "            # 每间隔 100 step 输出训练指标\n",
    "            if global_step % 1 == 0:\n",
    "                print(\n",
    "                    \"global step %d, epoch: %d, batch: %d, loss: %.5f, accu: %.5f, speed: %.2f step/s\"\n",
    "                    % (global_step, epoch, step, loss, acc,\n",
    "                        10 / (time.time() - tic_train)))\n",
    "                tic_train = time.time()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.clear_grad()\n",
    "\n",
    "            # 每间隔一个epoch 在验证集进行评估\n",
    "            if global_step % len(train_dataloader) == 0:\n",
    "                eval_loss,eval_accu=evaluate(model, criterion, metric, val_dataloader)\n",
    "                save_param_path = os.path.join(save_dir+str(epoch), 'model_state.pdparams')\n",
    "                paddle.save(model.state_dict(), save_param_path)\n",
    "                if(best_accuracy<eval_accu):\n",
    "                    best_accuracy=eval_accu\n",
    "                    # 保存模型\n",
    "                    save_param_path = os.path.join(best_dir, 'model_best.pdparams')\n",
    "                    paddle.save(model.state_dict(), save_param_path)\n",
    "do_train(model, criterion, metric, val_dataloader,train_dataloader) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 八、模型预测\n",
    "**模型预测前，请重启内核，清空占用的显存**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 根据实际运行情况，更换加载的参数路径\n",
    "import os\n",
    "import paddle\n",
    "\n",
    "params_path = 'checkpoint/model_best.pdparams'\n",
    "if params_path and os.path.isfile(params_path):\n",
    "    # 加载模型参数\n",
    "    state_dict = paddle.load(params_path)\n",
    "    model.set_dict(state_dict)\n",
    "    print(\"Loaded parameters from %s\" % params_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to save model graph, error: 'Tensor' object has no attribute '_full_name'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute '_full_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20788\\2875716181.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0minput_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mqCap_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mqImg_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcap_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_batch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             verbose=True)\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\visualdl\\writer\\writer.py\u001b[0m in \u001b[0;36madd_graph\u001b[1;34m(self, model, input_spec, verbose)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Failed to save model graph, error: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         graph_file_name = bfile.join(\n\u001b[0;32m    670\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\visualdl\\writer\\writer.py\u001b[0m in \u001b[0;36madd_graph\u001b[1;34m(self, model, input_spec, verbose)\u001b[0m\n\u001b[0;32m    663\u001b[0m         \"\"\"\n\u001b[0;32m    664\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 665\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtranslate_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    666\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Failed to save model graph, error: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Software\\CodeApp\\Anaconda\\envs\\paddle\\lib\\site-packages\\visualdl\\component\\graph\\exporter.py\u001b[0m in \u001b[0;36mtranslate_graph\u001b[1;34m(model, input_spec, verbose)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTemporaryDirectory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_full_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'{}[{}]'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mcreate_opname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_static\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute '_full_name'"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "# 切换model模型为评估模式，关闭dropout等随机因素\n",
    "model.eval()\n",
    "count=0\n",
    "for batch in test_dataloader:\n",
    "    count+=1\n",
    "    cap_batch, img_batch, qCap_batch, qImg_batch = batch\n",
    "    logits = model(qCap=qCap_batch,qImg=qImg_batch,caps=cap_batch,imgs=img_batch)\n",
    "    \n",
    "                \n",
    "    # 报错AttributeError: 'Tensor' object has no attribute '_full_name'，先不管了\n",
    "    # 用visualDL，绘制模型图\n",
    "    # net=model(qCap_batch,qImg_batch,cap_batch,img_batch)\n",
    "    # with LogWriter(logdir=\"./log/graph_test/\") as writer:\n",
    "    #     writer.add_graph(\n",
    "    #         model=net,\n",
    "    #         input_spec=[qCap_batch,qImg_batch,cap_batch,img_batch],\n",
    "    #         verbose=True)\n",
    "    # break\n",
    "    \n",
    "    # 预测分类\n",
    "    probs = F.softmax(logits, axis=-1)\n",
    "    label = paddle.argmax(probs, axis=1).numpy()\n",
    "    results += label.tolist()\n",
    "    print(count)\n",
    "print(results[:5])\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 50)\n"
     ]
    }
   ],
   "source": [
    "# 输出结果\n",
    "import pandas as pd\n",
    "#id/label\n",
    "#字典中的key值即为csv中的列名\n",
    "id_list=range(len(results))\n",
    "print(id_list)\n",
    "frame = pd.DataFrame({'id':id_list,'label':results})\n",
    "frame.to_csv(\"result.csv\",index=False,sep=',')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 九、后续优化\n",
    "\n",
    "baseline分数只有65分，还有很大的改进地方，大家多多尝试，下面是一些想法\n",
    "\n",
    "参数调优：学习率、优化器以及其他超参数等\n",
    "\n",
    "特征提取：更换预训练权重更大的图像特征提取器or文本特征提取器（Ernie or Bert系列）\n",
    "\n",
    "特征交互：目前使用多头自注意力机制对文本与文本证据交互、图像与图像证据交互，可以尝试文本与图像之间的跨模态交互\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
